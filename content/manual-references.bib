

@article{Perrinet02stdp,
	Abstract = {It is generally assumed that neurons in the central nervous system communicate through temporal firing patterns. As a first step, we will study the learning of a layer of realistic neurons in the particular case where the relevant messages are formed by temporally correlated patterns, or synfire patterns. The model is a layer of Integrate-and-Fire (IF) neurons with synaptic current dynamics that adapts by minimizing a cost according to a gradient descent scheme. This leads to a rule similar to Spike-Time Dependent Hebbian Plasticity (STDHP). Our results show that the rule that we derive is biologically plausible and leads to the detection of the coherence in the input in an unsupervised way. An application to shape recognition is shown as an illustration.},
	Author = {Perrinet, Laurent U and Samuelides, Manuel},
	Date = {2002-06},
	Date-Added = {2020-07-06 17:20:45 +0200},
	Date-Modified = {2020-07-06 17:20:45 +0200},
	Doi = {10.1016/S0925-2312(02)00374-0},
	Journal = {Neurocomputing},
	Keywords = {coding decoding,rank-order-coding,sparse hebbian learning,spike,stdp},
	Number = {C},
	Pages = {817--22},
	Title = {Coherence detection in a spiking neuron via Hebbian learning},
	Url = {http://dx.doi.org/10.1016/S0925-2312(02)00374-0},
	Volume = {44--46},
	Year = {2002},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/S0925-2312(02)00374-0}}

@article{Kaplan13,
	Abstract = {Predictive coding hypothesizes that the brain explicitly infers upcoming sensory input to establish a coherent representation of the world. Although it is becoming generally accepted, it is not clear on which level spiking neural networks may implement predictive coding and what function their connectivity may have. We present a network model of conductance-based integrate-and-fire neurons inspired by the architecture of retinotopic cortical areas that assumes predictive coding is implemented through network connectivity, namely in the connection delays and in selectiveness for the tuning properties of source and target cells. We show that the applied connection pattern leads to motion-based prediction in an experiment tracking a moving dot. In contrast to our proposed model, a network with random or isotropic connectivity fails to predict the path when the moving dot disappears. Furthermore, we show that a simple linear decoding approach is sufficient to transform neuronal spiking activity into a probabilistic estimate for reading out the target trajectory.},
	Author = {Kaplan, Bernhard A and Lansner, Anders and Masson, Guillaume S and Perrinet, Laurent U},
	Date = {2013-09-17},
	Date-Added = {2020-07-06 17:19:20 +0200},
	Date-Modified = {2020-07-06 17:19:20 +0200},
	Doi = {10.3389/fncom.2013.00112},
	Grants = {facets-itn},
	Journal = {Frontiers in Computational Neuroscience},
	Keywords = {Bayesian model,large-scale_networks,motion detection,motion prediction,predictive coding,pynn,spike},
	Number = {112},
	Title = {Anisotropic connectivity implements motion-based prediction in a spiking neural network},
	Url = {https://laurentperrinet.github.io/publication/kaplan-13},
	Volume = {7},
	Year = {2013},
	Bdsk-Url-1 = {https://laurentperrinet.github.io/publication/kaplan-13},
	Bdsk-Url-2 = {https://doi.org/10.3389/fncom.2013.00112}}

@article{Perrinet10shl,
	Abstract = {Neurons in the input layer of primary visual cortex in primates develop edge-like receptive fields. One approach to understanding the emergence of this response is to state that neural activity has to efficiently represent sensory data with respect to the statistics of natural scenes. Furthermore, it is believed that such an efficient coding is achieved using a competition across neurons so as to generate a sparse representation, that is, where a relatively small number of neurons are simultaneously active. Indeed, different models of sparse coding coupled with Hebbian learning and homeostasis have been proposed that successfully match the observed emergent response. However, the specific role of homeostasis in learning such sparse representations is still largely unknown. By quantitatively assessing the efficiency of the neural representation during learning, we derive a cooperative homeostasis mechanism which optimally tunes the competition between neurons within the sparse coding algorithm. We apply this homeostasis while learning small patches taken from natural images and compare its efficiency with state-of-the-art algorithms. Results show that while different sparse coding algorithms give similar coding results, the homeostasis provides an optimal balance for the representation of natural images within the population of neurons. Competition in sparse coding is optimized when it is fair: By contributing to optimize statistical competition across neurons, homeostasis is crucial in providing a more efficient solution to the emergence of independent components.},
	Annotation = {Posted Online March 17, 2010.},
	Author = {Perrinet, Laurent U},
	Date = {2010-07-17},
	Date-Added = {2020-07-06 17:19:20 +0200},
	Date-Modified = {2020-07-06 17:19:20 +0200},
	Doi = {10.1162/neco.2010.05-08-795},
	Issn = {1530-888X},
	Journal = {Neural Computation},
	Keywords = {association field,coding decoding,eye movements,homeostasis,matching pursuit,motion-clouds,receptive field,sparse coding,sparse hebbian learning,statistics of natural images,unsupervised learning},
	Number = {7},
	Pages = {1812--36},
	Preprint = {https://hal-amu.archives-ouvertes.fr/hal-00156610},
	Publisher = {MIT Press},
	Title = {Role of homeostasis in learning sparse representations},
	Url = {https://arxiv.org/abs/0706.3177},
	Url_Code = {https://laurentperrinet.github.io/publication/perrinet-10-shl},
	Volume = {22},
	Year = {2010},
	Bdsk-Url-1 = {https://laurentperrinet.github.io/publication/perrinet-10-shl},
	Bdsk-Url-2 = {https://doi.org/10.1162/neco.2010.05-08-795}}

@incollection{Perrinet15bicv,
	Abstract = {The representation of images in the brain is known to be sparse. That is, as neural activity is recorded in a visual area, for instance the primary visual cortex of primates, only a few neurons are active at a given time with respect to the whole population. It is believed that such a property reflects the efficient match of the representation with the statistics of natural scenes. Applying such a paradigm to computer vision therefore seems a promising approach towards more biomimetic algorithms. Herein, we will describe a biologically-inspired approach to this problem. First, we will describe an unsupervised learning paradigm which is particularly adapted to the efficient coding of image patches. Then, we will outline a complete multi-scale framework (SparseLets) implementing a biologically inspired sparse representation of natural images. Finally, we will propose novel methods for integrating prior information into these algorithms and provide some preliminary experimental results. We will conclude by giving some perspective on applying such algorithms to computer vision. More specifically, we will propose that bio-inspired approaches may be applied to computer vision using predictive coding schemes, sparse models being one simple and efficient instance of such schemes.},
	Author = {Perrinet, Laurent U},
	Booktitle = {Biologically Inspired Computer Vision},
	Chapter = {13},
	Date = {2015-11},
	Date-Added = {2020-07-06 17:19:20 +0200},
	Date-Modified = {2020-07-06 17:19:20 +0200},
	Doi = {10.1002/9783527680863.ch14},
	Editor = {Crist{\'o}bal, Gabriel and Perrinet, Laurent U and Keil, Matthias S},
	Isbn = {9783527680863},
	Keywords = {Biologically Inspired Computer vision,sparse coding},
	Preprint = {https://hal-amu.archives-ouvertes.fr/hal-01444362},
	Publisher = {Wiley-VCH Verlag GmbH and Co. KGaA},
	Title = {Sparse Models for Computer Vision},
	Url = {http://onlinelibrary.wiley.com/doi/10.1002/9783527680863.ch14/summary},
	Url_Code = {https://github.com/bicv/Perrinet2015BICV_sparse},
	Year = {2015},
	Bdsk-Url-1 = {https://arxiv.org/abs/1701.06859}}

@article{PerrinetAdamsFriston14,
	Abstract = {This paper considers the problem of sensorimotor delays in the optimal control of (smooth) eye movements under uncertainty. Specifically, we consider delays in the visuo-oculomotor loop and their implications for active inference. Active inference uses a generalisation of Kalman filtering to provide Bayes optimal estimates of hidden states and action in generalised coordinates of motion. Representing hidden states in generalised coordinates provides a simple way of compensating for both sensory and oculomotor delays. The efficacy of this scheme is illustrated using neuronal simulations of pursuit initiation responses, with and without compensation. We then consider an extension of the generative model to simulate smooth pursuit eye movements in which the visuo-oculomotor system believes both the target and its centre of gaze are attracted to a (hidden) point moving in the visual field. Finally, the generative model is equipped with a hierarchical structure, so that it can recognise and remember unseen (occluded) trajectories and emit anticipatory responses. These simulations speak to a straightforward and neurobiologically plausible solution to the generic problem of integrating information from different sources with different temporal delays and the particular difficulties encountered when a system, like the oculomotor system, tries to control its environment with delayed signals.},
	Annote = {https://arxiv.org/abs/1610.05564},
	Author = {Perrinet, Laurent U and Adams, Rick A and Friston, Karl},
	Booktitle = {Biological Cybernetics},
	Date = {2014-12-16},
	Date-Added = {2020-07-06 17:19:20 +0200},
	Date-Modified = {2020-07-06 17:19:20 +0200},
	Doi = {10.1007/s00422-014-0620-8},
	Issn = {1432-0770},
	Journal = {Biological Cybernetics},
	Keywords = {active inference,Bayesian model,Biologically Inspired Computer vision,eye movements,free energy,motion detection},
	Number = {6},
	Pages = {777--801},
	Preprint = {https://hal-amu.archives-ouvertes.fr/hal-01382350},
	Publisher = {Springer Berlin Heidelberg},
	Title = {Active inference, eye movements and oculomotor delays},
	Url = {http://link.springer.com/article/10.1007%2Fs00422-014-0620-8},
	Volume = {108},
	Year = {2014},
	Bdsk-Url-1 = {https://hal.archives-ouvertes.fr/hal-01382350},
	Bdsk-Url-2 = {https://doi.org/10.1007/s00422-014-0620-8}}

@article{Adams12,
	Abstract = {This paper introduces a model of oculomotor control during the smooth pursuit of occluded visual targets. This model is based upon active inference, in which subjects try to minimise their (proprioceptive) prediction error based upon posterior beliefs about the hidden causes of their (exteroceptive) sensory input. Our model appeals to a single principle -the minimisation of variational free energy - to provide Bayes optimal solutions to the smooth pursuit problem. However, it tries to accommodate the cardinal features of smooth pursuit of partially occluded targets that have been observed empirically in normal subjects and schizophrenia. Specifically, we account for the ability of normal subjects to anticipate periodic target trajectories and emit pre-emptive smooth pursuit eye movements -prior to the emergence of a target from behind an occluder. Furthermore, we show that a single deficit in the postsynaptic gain of prediction error units (encoding the precision of posterior beliefs) can account for several features of smooth pursuit in schizophrenia: namely, a reduction in motor gain and anticipatory eye movements during visual occlusion, a paradoxical improvement in tracking unpredicted deviations from target trajectories and a failure to recognise and exploit regularities in the periodic motion of visual targets. This model will form the basis of subsequent (dynamic causal) models of empirical eye tracking measurements, which we hope to validate, using psychopharmacology and studies of schizophrenia.},
	Author = {Adams, Rick A and Perrinet, Laurent U and Friston, Karl},
	Date = {2012-10-26},
	Date-Added = {2020-07-06 17:18:01 +0200},
	Date-Modified = {2020-07-06 17:18:01 +0200},
	Doi = {10.1371/journal.pone.0047502},
	Journal = {PLoS ONE},
	Keywords = {active inference,Bayesian model,eye movements,motion detection},
	Number = {10},
	Pages = {e47502+},
	Publisher = {Public Library of Science},
	Title = {Smooth Pursuit and Visual Occlusion: Active Inference and Oculomotor Control in Schizophrenia},
	Url = {http://dx.doi.org/10.1371/journal.pone.0047502},
	Volume = {7},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1371/journal.pone.0047502}}

@article{Chemla19,
	Abstract = {The ``apparent motion'' illusion is evoked when stationary stimuli are successively flashed in spatially separated positions. It depends on the precise spatial and temporal separations of the stimuli. For large spatiotemporal separation, the long-range apparent motion (lrAM), it remains unclear how the visual system computes unambiguous motion signals. Here we investigated whether intracortical interactions within retinotopic maps could shape a global motion representation at the level of V1 population in response to a lrAM. In fixating monkeys, voltage-sensitive dye imaging revealed the emergence of a spatio-temporal representation of the motion trajectory at the scale of V1 population activity, shaped by systematic backward suppressive waves. We show that these waves are the expected emergent property of a recurrent gain control fed by the horizontal intra-cortical network. Such non-linearities explain away ambiguous correspondence problems of the stimulus along the motion path, preformating V1 population response for an optimal read-out by downstream areas.},
	Author = {Chemla, Sandrine and Reynaud, Alexandre and diVolo, Matteo and Zerlaut, Yann and Perrinet, Laurent U and Destexhe, Alain and Chavane, Fr{\'e}d{\'e}ric Y},
	Date = {2019-03-18},
	Date-Added = {2020-07-06 17:18:01 +0200},
	Date-Modified = {2020-07-06 17:18:01 +0200},
	Doi = {10.1523/JNEUROSCI.2792-18.2019},
	Grants = {anr-bala-v1,anr-trajectory},
	Journal = {Journal of Neuroscience},
	Keywords = {area-v1},
	Pages = {18},
	Preprint = {http://biorxiv.org/lookup/doi/10.1101/372763},
	Summary = {Traveling waves have recently been observed in different animal species, brain areas and behavioral states. However, it is still unclear what are their functional roles. In the case of cortical visual processing, waves propagate across retinotopic maps and can hereby generate interactions between spatially and temporally separated instances of feedforward driven activity. Such interactions could participate in processing long-range apparent motion stimuli, an illusion for which no clear neuronal mechanisms have yet been proposed. Using this paradigm in awake monkeys, we show that suppressive traveling waves produce to a spatio-temporal normalization of apparent motion stimuli. Our study suggests that cortical waves shape the representation of illusory moving stimulus within retinotopic maps for an straightforward read-out by downstream areas.},
	Title = {Suppressive waves disambiguate the representation of long-range apparent motion in awake monkey V1},
	Url = {http://www.jneurosci.org/content/early/2019/03/18/JNEUROSCI.2792-18.2019},
	Urldate = {2018-07-27},
	Volume = {2792},
	Year = {2019},
	Bdsk-Url-1 = {http://biorxiv.org/lookup/doi/10.1101/372763},
	Bdsk-Url-2 = {https://doi.org/10/gdvqbh}}

	@article{KhoeiMassonPerrinet17,
	    abstract = {Due to its inherent neural delays, the visual system has an outdated access to sensory information about the current position of moving objects. In contrast, living organisms are remarkably able to track and intercept moving objects under a large range of challenging environmental conditions. Physiological, behavioral and psychophysical evidences strongly suggest that position coding is extrapolated using an explicit and reliable representation of object's motion but it is still unclear how these two representations interact. For instance, the so-called flash-lag effect supports the idea of a differential processing of position between moving and static objects. Although elucidating such mechanisms is crucial in our understanding of the dynamics of visual processing, a theory is still missing to explain the different facets of this visual illusion. Here, we reconsider several of the key aspects of the flash-lag effect in order to explore the role of motion upon neural coding of objects' position. First, we formalize the problem using a Bayesian modeling framework which includes a graded representation of the degree of belief about visual motion. We introduce a motion-based prediction model as a candidate explanation for the perception of coherent motion. By including the knowledge of a fixed delay, we can model the dynamics of sensory information integration by extrapolating the information acquired at previous instants in time. Next, we simulate the optimal estimation of object position with and without delay compensation and compared it with human perception under a broad range of different psychophysical conditions. Our computational study suggests that the explicit, probabilistic representation of velocity information is crucial in explaining position coding, and therefore the flash-lag effect. We discuss these theoretical results in light of the putative corrective mechanisms that can be used to cancel out the detrimental effects of neural delays and illuminate the more general question of the dynamical representation of spatial information at the present time in the visual pathways.},
	    author = {Khoei, Mina A and Masson, Guillaume S and Perrinet, Laurent U},
	    bdsk-url-1 = {http://dx.doi.org/10.1371/journal.pcbi.1005068},
	    date = {2017-01-26},
	    date-modified = {2020-03-31 11:07:30 +0200},
	    doi = {10.1371/journal.pcbi.1005068},
	    grants = {facets-itn},
	    journal = {PLoS Computational Biology},
	    keywords = {Bayesian model,motion prediction},
	    number = {1},
	    pages = {e1005068},
	    preprint = {https://hal-amu.archives-ouvertes.fr/hal-01771125},
	    title = {The flash-lag effect as a motion-based predictive shift},
	    url = {https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/},
	    url_code = {https://github.com/laurentperrinet/Khoei_2017_PLoSCB},
	    volume = {13},
	    year = {2017}
	}


@article{Maass97,
	abstract = {The computational power of formal models for networks of spiking neurons is compared with that of other neural network models based on McCulloch Pitts neurons (i.e., threshold gates), respectively, sigmoidal gates. In particular it is shown that networks of spiking neurons are, with regard to the number of neurons that are needed, computationally more powerful than these other neural network models. A concrete biologically relevant function is exhibited which can be computed by a single spiking neuron (for biologically reasonable values of its parameters), but which requires hundreds of hidden units on a sigmoidal neural net. On the other hand, it is known that any function that can be computed by a small sigmoidal neural net can also be computed by a small network of spiking neurons. This article does not assume prior knowledge about spiking neurons, and it contains an extensive list of references to the currently available literature on computations in networks of spiking neurons and relevant results from neurobiology. {\copyright} 1997 Elsevier Science Ltd. All rights reserved.},
	author = {Maass, Wolfgang},
	date = {1997-12},
	date-added = {2020-07-06 16:56:43 +0200},
	date-modified = {2020-07-06 16:56:43 +0200},
	doi = {10/fm92kt},
	file = {/Users/laurentperrinet/Zotero/storage/VQ37H3XV/Maass - 1997 - Networks of spiking neurons The third generation .pdf},
	issn = {08936080},
	journaltitle = {Neural Networks},
	langid = {english},
	number = {9},
	pages = {1659--1671},
	shorttitle = {Networks of Spiking Neurons},
	title = {Networks of Spiking Neurons: {{The}} Third Generation of Neural Network Models},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608097000117},
	urldate = {2020-07-06},
	volume = {10},
	Bdsk-Url-1 = {https://linkinghub.elsevier.com/retrieve/pii/S0893608097000117},
	Bdsk-Url-2 = {https://doi.org/10/fm92kt}}

@article{Silver16,
	abstract = {A computer Go program based on deep neural networks defeats a human professional player to achieve one of the grand challenges of artificial intelligence.},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	date = {2016-01},
	date-added = {2020-01-03 11:46:18 +0100},
	date-modified = {2020-01-03 11:46:18 +0100},
	doi = {10/f77tw6},
	file = {/Users/laurentperrinet/Zotero/storage/HUULD54G/nature16961.html},
	issn = {1476-4687},
	journaltitle = {Nature},
	langid = {english},
	note = {00000},
	number = {7587},
	pages = {484-489},
	shortjournal = {Nature},
	title = {Mastering the Game of {{Go}} with Deep Neural Networks and Tree Search},
	url = {https://www.nature.com/articles/nature16961},
	urldate = {2020-01-03},
	volume = {529},
	Bdsk-Url-1 = {https://www.nature.com/articles/nature16961},
	Bdsk-Url-2 = {https://doi.org/10/f77tw6}}

@article{Lamme00,
	author = {Lamme, Victor A. F. and Roelfsema, Pieter R.},
	date = {2000-11-01},
	doi = {10/ccv3w2},
	eprint = {11074267},
	eprinttype = {pmid},
	file = {/Users/laurentperrinet/Zotero/storage/442FWQBU/Lamme and Roelfsema - 2000 - The distinct modes of vision offered by feedforwar.pdf;/Users/laurentperrinet/Zotero/storage/47374LQB/S0166-2236(00)01657-X.html},
	issn = {0166-2236, 1878-108X},
	journaltitle = {Trends in Neurosciences},
	langid = {english},
	number = {11},
	pages = {571-579},
	title = {The Distinct Modes of Vision Offered by Feedforward and Recurrent Processing},
	url = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(00)01657-X},
	urldate = {2019-03-18},
	volume = {23},
	Bdsk-Url-1 = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(00)01657-X},
	Bdsk-Url-2 = {https://doi.org/10/ccv3w2}}

@article{Kirchner06,
	abstract = {Previous ultra-rapid go/no-go categorization studies with manual responses have demonstrated the remarkable speed and efficiency with which humans process natural scenes. Using a forced-choice saccade task we show here that when two scenes are simultaneously flashed in the left and right hemifields, human participants can reliably make saccades to the side containing an animal in as little as 120 ms. Low level differences between target and distractor images were unable to account for these exceptionally fast responses. The results suggest a very fast and unexpected route linking visual processing in the ventral stream with the programming of saccadic eye movements.},
	author = {Kirchner, H and Thorpe, Sj},
	date = {2006},
	doi = {10.1016/j.visres.2005.10.002},
	eprint = {16289663},
	eprinttype = {pmid},
	issn = {0042-6989},
	journaltitle = {Vision Research},
	keywords = {Visual Pathways,Humans,Psychomotor Performance,Reaction Time,Saccades,Photic Stimulation,Female,Male,Adult,Learning,Learning: physiology,Pattern Recognition,Visual,Visual: physiology,perrinet11sfn,assofield,Ocular,Ocular: physiology,Visual Pathways: physiology,Fixation,Saccades: physiology,Psychomotor Performance: physiology,Electrooculography,Electrooculography: methods,\#nosource},
	number = {11},
	pages = {1762--76},
	title = {Ultra-Rapid Object Detection with Saccadic Eye Movements: Visual Processing Speed Revisited},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698905005110},
	volume = {46},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S0042698905005110},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.visres.2005.10.002}}


@article{Brette19,
	author = {Brette, Romain},
	doi = {10/gfvs6r},
	file = {Brette - 2019 - Is coding a relevant metaphor for the brain.pdf:/Users/laurentperrinet/Zotero/storage/FVBNT276/Brette - 2019 - Is coding a relevant metaphor for the brain.pdf:application/pdf},
	issn = {0140-525X, 1469-1825},
	journal = {Behavioral and Brain Sciences},
	language = {en},
	month = feb,
	note = {00002},
	pages = {1--44},
	title = {Is coding a relevant metaphor for the brain?},
	url = {https://www.cambridge.org/core/product/identifier/S0140525X19000049/type/journal_article},
	urldate = {2019-02-22},
	year = {2019},
	Bdsk-Url-1 = {https://www.cambridge.org/core/product/identifier/S0140525X19000049/type/journal_article},
	Bdsk-Url-2 = {https://doi.org/10/gfvs6r}}

@article{Olshausen97,
	author = {Olshausen, Bruno A and Field, David J},
	journal = {Vision research},
	number = {23},
	pages = {3311--3325},
	publisher = {Elsevier},
	title = {Sparse coding with an overcomplete basis set: A strategy employed by V1?},
	volume = {37},
	year = {1997}}

@article{Bringuier99,
	abstract = {The receptive field of a visual neuron is classically defined as the region of space (or retina) where a visual stimulus evokes a change in its firing activity. At the cortical level, a challenging issue concerns the roles of feedforward, local recurrent, intracortical, and cortico-cortical feedback connectivity in receptive field properties. Intracellular recordings in cat area 17 showed that the visually evoked synaptic integration field extends over a much larger area than that established on the basis of spike activity. Synaptic depolarizing responses to stimuli flashed at increasing distances from the center of the receptive field decreased in strength, whereas their onset latency increased. These findings suggest that subthreshold responses in the unresponsive region surrounding the classical discharge field result from the integration of visual activation waves spread by slowly conducting horizontal axons within primary visual cortex.},
	author = {Bringuier, Vincent and Chavane, Fr{\'e}d{\'e}ric and Glaeser, Larry and Fr{\'e}gnac, Yves},
	doi = {10/b9shf4},
	file = {Snapshot:/Users/laurentperrinet/Zotero/storage/BRHDGRNI/695.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = jan,
	note = {00535},
	number = {5402},
	pages = {695--699},
	pmid = {9924031},
	title = {Horizontal {Propagation} of {Visual} {Activity} in the {Synaptic} {Integration} {Field} of {Area} 17 {Neurons}},
	url = {http://science.sciencemag.org/content/283/5402/695},
	urldate = {2019-02-07},
	volume = {283},
	year = {1999},
	Bdsk-Url-1 = {http://science.sciencemag.org/content/283/5402/695},
	Bdsk-Url-2 = {https://doi.org/10/b9shf4}}

@article{Markov13,
	abstract = {We investigated the influence of interareal distance on connectivity patterns in a database obtained from the injection of retrograde tracers in 29 areas distributed over six regions (occipital, temporal, parietal, frontal, prefrontal, and limbic). One-third of the 1,615 pathways projecting to the 29 target areas were reported only recently and deemed new-found projections (NFPs). NFPs are predominantly long-range, low-weight connections. A minimum dominating set analysis (a graph theoretic measure) shows that NFPs play a major role in globalizing input to small groups of areas. Randomization tests show that ( i ) NFPs make important contributions to the specificity of the connectivity profile of individual cortical areas, and ( ii ) NFPs share key properties with known connections at the same distance. We developed a similarity index, which shows that intraregion similarity is high, whereas the interregion similarity declines with distance. For area pairs, there is a steep decline with distance in the similarity and probability of being connected. Nevertheless, the present findings reveal an unexpected binary specificity despite the high density (66\%) of the cortical graph. This specificity is made possible because connections are largely concentrated over short distances. These findings emphasize the importance of long-distance connections in the connectivity profile of an area. We demonstrate that long-distance connections are particularly prevalent for prefrontal areas, where they may play a prominent role in large-scale communication and information integration.},
	author = {Markov, Nikola T. and Ercsey-Ravasz, Maria and Lamy, Camille and Gomes, Ana Rita Ribeiro and Magrou, Loic and Misery, Pierre and Giroud, Pascale and Barone, Pascal and Dehay, Colette and Toroczkai, Zolt{\'a}n and Knoblauch, Kenneth and Essen, David C. Van and Kennedy, Henry},
	date-modified = {2019-09-03 12:32:22 +0200},
	doi = {10.1073/PNAS.1218972110},
	issn = {0027-8424},
	journal = {Proceedings of the National Academy of Sciences},
	number = {13},
	pages = {5187--5192},
	pmid = {23479610},
	title = {The role of long-range connections on the specificity of the macaque interareal cortical network},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23479610 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3612613},
	volume = {110},
	year = {2013},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pubmed/23479610%20http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3612613},
	Bdsk-Url-2 = {https://doi.org/10.1073/PNAS.1218972110}}


@incollection{Paugam12,
	author = {Paugam-Moisy, H{\'e}lene and Bohte, Sander},
	booktitle = {Handbook of natural computing},
	pages = {335--376},
	publisher = {Springer},
	title = {Computing with spiking neuron networks},
	year = {2012}}

@article{Lagorce17,
	abstract = {This paper describes novel event-based spatiotemporal features called time-surfaces and how they can be used to create a hierarchical event-based pattern recognition architecture. Unlike existing hierarchical architectures for pattern recognition, the presented model relies on a time oriented approach to extract spatio-temporal features from the asynchronously acquired dynamics of a visual scene. These dynamics are acquired using biologically inspired frameless asynchronous event-driven vision sensors. Similarly to cortical structures, subsequent layers in our hierarchy extract increasingly abstract features using increasingly large spatio-temporal windows. The central concept is to use the rich temporal information provided by events to create contexts in the form of time-surfaces which represent the recent temporal activity within a local spatial neighborhood. We demonstrate that this concept can robustly be used at all stages of an event-based hierarchical model. First layer feature units operate on groups of pixels, while subsequent layer feature units operate on the output of lower level feature units. We report results on a previously published 36 class character recognition task and a 4 class canonical dynamic card pip task, achieving near 100\% accuracy on each. We introduce a new 7 class moving face recognition task, achieving 79\% accuracy.},
	author = {Lagorce, Xavier and Orchard, Garrick and Galluppi, Francesco and Shi, Bertram E. and Benosman, Ryad B.},
	doi = {10.1109/TPAMI.2016.2574707},
	file = {Attachment:/Users/laurentperrinet/Zotero/storage/EH96DS22/Lagorce et al. - 2017 - HOTS A Hierarchy of Event-Based Time-Surfaces for Pattern Recognition(4).pdf:application/pdf},
	issn = {0162-8828},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {event-based vision, feature extraction, Neuromorphic sensing},
	number = {7},
	pages = {1346--1359},
	pmid = {27411216},
	title = {{HOTS}: {A} {Hierarchy} of {Event}-{Based} {Time}-{Surfaces} for {Pattern} {Recognition}},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27411216 http://ieeexplore.ieee.org/document/7508476/},
	volume = {39},
	year = {2017},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pubmed/27411216%20http://ieeexplore.ieee.org/document/7508476/},
	Bdsk-Url-2 = {https://doi.org/10.1109/TPAMI.2016.2574707}}

@article{Oconnor13,
	abstract = {Deep Belief Networks (DBNs) have recently shown impressive performance on a broad range of classification problems. Their generative properties allow better understanding of the performance, and provide a simpler solution for sensor fusion tasks. However, because of their inherent need for feedback and parallel update of large numbers of units, DBNs are expensive to implement on serial computers. This paper proposes a method based on the Siegert approximation for Integrate-and-Fire neurons to map an offline-trained DBN onto an efficient event-driven spiking neural network suitable for hardware implementation. The method is demonstrated in simulation and by a real-time implementation of a 3-layer network with 2694 neurons used for visual classification of MNIST handwritten digits with input from a 128x128 Dynamic Vision Sensor (DVS) silicon retina, and sensory-fusion using additional input from a 64-channel AER-EAR silicon cochlea. The system is implemented through the open-source software in the jAER project and runs in real-time on a laptop computer. It is demonstrated that the system can recognize digits in the presence of distractions, noise, scaling, translation and rotation, and that the degradation of recognition performance by using an event-based approach is less than 1\%. Recognition is achieved in an average of 5.8 ms after the onset of the presentation of a digit. By cue integration from both silicon retina and cochlea outputs we show that the system can be biased to select the correct digit from otherwise ambiguous input.},
	author = {O'Connor, Peter and Neil, Daniel and Liu, Shih-Chii and Delbruck, Tobi and Pfeiffer, Michael},
	doi = {10.3389/fnins.2013.00178},
	file = {Attachment:/Users/laurentperrinet/Zotero/storage/8FIM7BDE/O'Connor et al. - 2013 - Real-time classification and sensor fusion with a spiking deep belief network.pdf:application/pdf},
	issn = {1662-453X},
	journal = {Frontiers in Neuroscience},
	keywords = {deep learning, Generative Model, Spiking Neural network, Deep Belief Networks, sensory fusion, Silicon Cochlea, Silicon Retina},
	pages = {178},
	title = {Real-time classification and sensor fusion with a spiking deep belief network},
	url = {http://journal.frontiersin.org/article/10.3389/fnins.2013.00178/abstract},
	volume = {7},
	year = {2013},
	Bdsk-Url-1 = {http://journal.frontiersin.org/article/10.3389/fnins.2013.00178/abstract},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnins.2013.00178}}

@incollection{Ghosh09,
	author = {Ghosh-Dastidar, Samanwoy and Adeli, Hojjat},
	booktitle = {Advances in Computational Intelligence},
	pages = {167--178},
	publisher = {Springer},
	title = {Third generation neural networks: Spiking neural networks},
	year = {2009}}


@article{Muller14,
	abstract = {Propagating waves occur in many excitable media and were recently found in neural systems from retina to neocortex. While propagating waves are clearly present under anaesthesia, whether they also appear during awake and conscious states remains unclear. One possibility is that these waves are systematically missed in trial-averaged data, due to variability. Here we present a method for detecting propagating waves in noisy multichannel recordings. Applying this method to single-trial voltage-sensitive dye imaging data, we show that the stimulus-evoked population response in primary visual cortex of the awake monkey propagates as a travelling wave, with consistent dynamics across trials. A network model suggests that this reliability is the hallmark of the horizontal fibre network of superficial cortical layers. Propagating waves with similar properties occur independently in secondary visual cortex, but maintain precise phase relations with the waves in primary visual cortex. These results show that, in response to a visual stimulus, propagating waves are systematically evoked in several visual areas, generating a consistent spatiotemporal frame for further neuronal interactions.},
	author = {Muller, Lyle and Reynaud, Alexandre and Chavane, Fr{\'e}d{\'e}ric and Destexhe, Alain},
	date = {2014-04-28},
	date-added = {2019-01-29 16:03:33 -0300},
	date-modified = {2019-01-29 16:03:33 -0300},
	doi = {10/f52mxc},
	file = {Full Text:/Users/laurentperrinet/Zotero/storage/URC9ZKNI/Muller et al. - 2014 - The stimulus-evoked population response in visual .pdf:application/pdf},
	issn = {2041-1723},
	journaltitle = {Nature Communications},
	keywords = {Animals, Visual Cortex, Macaca mulatta, Eye Movements, Photic Stimulation, Models, Neurological, Evoked Potentials, Visual, Fixation, Ocular, Pyrazoles, Thiazoles},
	note = {00068},
	pages = {3675},
	pmcid = {PMC4015334},
	pmid = {24770473},
	shortjournal = {Nat Commun},
	title = {The stimulus-evoked population response in visual cortex of awake monkey is a propagating wave},
	volume = {5},
	year = {2014},
	Bdsk-Url-1 = {https://doi.org/10/f52mxc}}

@article{Muller18,
	abstract = {Advanced recording techniques have enabled the identification of travelling waves of neuronal activity in different areas of the cortex. Sejnowski and colleagues review these findings, consider the mechanisms by which travelling waves are generated and evaluate their possible roles in cortical function.},
	author = {Muller, Lyle and Chavane, Fr{\'e}d{\'e}ric and Reynolds, John and Sejnowski, Terrence J.},
	date = {2018-03},
	date-added = {2019-01-29 16:02:59 -0300},
	date-modified = {2019-01-29 16:02:59 -0300},
	doi = {10.1038/nrn.2018.20},
	file = {Muller et al. - 2018 - Cortical travelling waves mechanisms and computat.pdf:/Users/laurentperrinet/Zotero/storage/4BS6L43A/Muller et al. - 2018 - Cortical travelling waves mechanisms and computat.pdf:application/pdf;PubMed Central Full Text PDF:/Users/laurentperrinet/Zotero/storage/K4YL5NPK/Muller et al. - 2018 - Cortical travelling waves mechanisms and computat.pdf:application/pdf},
	issn = {1471-003X},
	journaltitle = {Nature Reviews Neuroscience},
	keywords = {Visual system, Neural encoding, Dynamical systems},
	title = {Cortical travelling waves: mechanisms and computational principles},
	url = {http://www.nature.com/doifinder/10.1038/nrn.2018.20},
	year = {2018},
	Bdsk-Url-1 = {http://www.nature.com/doifinder/10.1038/nrn.2018.20},
	Bdsk-Url-2 = {https://doi.org/10.1038/nrn.2018.20}}

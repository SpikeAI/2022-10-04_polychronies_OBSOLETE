
@article{gautrais_rate_1998,
	title = {Rate coding versus temporal order coding: a theoretical approach},
	volume = {48},
	shorttitle = {Rate coding versus temporal order coding},
	number = {1-3},
	journal = {Biosystems},
	author = {Gautrais, Jacques and Thorpe, Simon},
	year = {1998},
	note = {Publisher: Elsevier},
	keywords = {⛔ No INSPIRE recid found},
	pages = {57--65},
}

@article{delorme_spikenet_1999,
	title = {{SpikeNET}: {A} simulator for modeling large networks of integrate and fire neurons},
	volume = {26},
	shorttitle = {{SpikeNET}},
	journal = {Neurocomputing},
	author = {Delorme, Arnaud and Gautrais, Jacques and Van Rullen, Rufin and Thorpe, Simon},
	year = {1999},
	note = {Publisher: Elsevier},
	keywords = {⛔ No INSPIRE recid found},
	pages = {989--996},
}

@article{serre_feedforward_2007,
	title = {A feedforward architecture accounts for rapid categorization},
	volume = {104},
	doi = {10/cr3ksx},
	number = {15},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Serre, T. and Oliva, A. and Poggio, T.},
	year = {2007},
	note = {tex.bdsk-url-2: https://doi.org/10.1073/pnas.0700622104
tex.date-added: 2022-05-05 19:08:15 +0200
tex.date-modified: 2022-05-05 19:08:15 +0200},
	keywords = {⛔ No INSPIRE recid found},
	pages = {6424--6429},
}

@misc{jeremie_ultrafast_2022,
	title = {Ultrafast image categorization in vivo and in silico},
	url = {http://arxiv.org/abs/2205.03635},
	abstract = {Humans are able to categorize images very efficiently, in particular to detect very rapidly the presence of an animal. Recently, deep learning algorithms have achieved higher accuracy than humans for a large set of visual recognition tasks. However, the tasks on which these artificial networks are usually trained and evaluated are usually very specialized which do not generalize well, for example with an accuracy drop following a rotation of the image. In this regard, biological visual systems are more flexible and efficient than artificial systems for more generic tasks, such as detecting an animal. To further the comparison between biological and artificial neural networks, we retrained the standard VGG16 convolutional neural network (CNN) on two independent tasks that are ecologically relevant to humans: detecting the presence of an animal or an artifact. We show that retraining the network achieves a human-like level of performance, comparable to what is reported in psychophysical tasks. Moreover, we show that categorization is better when combining the models' outputs. Indeed, animals (e.g. lions) tend to be less present in photographs containing artifacts (e.g. buildings). Furthermore, these re-trained models were able to reproduce some unexpected behavioral observations of human psychophysics, such as robustness to rotations (e.g., an upside-down or tilted image) or to a grayscale transformation. Finally, we quantified the number of CNN layers needed to achieve such performance, showing that good accuracy for ultrafast image categorization could be achieved with only a few layers, challenging the belief that image recognition would require a deep sequential analysis of visual objects.},
	urldate = {2022-10-26},
	publisher = {arXiv},
	author = {Jérémie, Jean-Nicolas and Perrinet, Laurent U.},
	month = oct,
	year = {2022},
	note = {arXiv:2205.03635 [cs, q-bio]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Quantitative Biology - Neurons and Cognition, ⛔ No INSPIRE recid found},
}

@misc{yu_stsc-snn_2022,
	title = {{STSC}-{SNN}: {Spatio}-{Temporal} {Synaptic} {Connection} with {Temporal} {Convolution} and {Attention} for {Spiking} {Neural} {Networks}},
	shorttitle = {{STSC}-{SNN}},
	url = {http://arxiv.org/abs/2210.05241},
	abstract = {Spiking Neural Networks (SNNs), as one of the algorithmic models in neuromorphic computing, have gained a great deal of research attention owing to temporal information processing capability, low power consumption, and high biological plausibility. The potential to efficiently extract spatio-temporal features makes it suitable for processing the event streams. However, existing synaptic structures in SNNs are almost full-connections or spatial 2D convolution, neither of which can extract temporal dependencies adequately. In this work, we take inspiration from biological synapses and propose a spatio-temporal synaptic connection SNN (STSC-SNN) model, to enhance the spatio-temporal receptive fields of synaptic connections, thereby establishing temporal dependencies across layers. Concretely, we incorporate temporal convolution and attention mechanisms to implement synaptic filtering and gating functions. We show that endowing synaptic models with temporal dependencies can improve the performance of SNNs on classification tasks. In addition, we investigate the impact of performance vias varied spatial-temporal receptive fields and reevaluate the temporal modules in SNNs. Our approach is tested on neuromorphic datasets, including DVS128 Gesture (gesture recognition), N-MNIST, CIFAR10-DVS (image classification), and SHD (speech digit recognition). The results show that the proposed model outperforms the state-of-the-art accuracy on nearly all datasets.},
	urldate = {2022-10-25},
	publisher = {arXiv},
	author = {Yu, Chengting and Gu, Zheming and Li, Da and Wang, Gaoang and Wang, Aili and Li, Erping},
	month = oct,
	year = {2022},
	note = {arXiv:2210.05241 [cs, q-bio, stat]},
	keywords = {Computer Science - Neural and Evolutionary Computing, Quantitative Biology - Neurons and Cognition, Statistics - Machine Learning, ⛔ No INSPIRE recid found},
}

@article{vanrullen_continuous_2006,
	title = {The {Continuous} {Wagon} {Wheel} {Illusion} {Is} {Associated} with {Changes} in {Electroencephalogram} {Power} at 13 {Hz}},
	volume = {26},
	copyright = {Copyright © 2006 Society for Neuroscience 0270-6474/06/26502-06.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/26/2/502},
	doi = {10.1523/jneurosci.4654-05.2006},
	language = {en},
	number = {2},
	urldate = {2019-11-05},
	journal = {Journal of Neuroscience},
	author = {VanRullen, Rufin and Reddy, Leila and Koch, Christof},
	month = jan,
	year = {2006},
	pmid = {16407547},
	note = {00000 },
	keywords = {⛔ No INSPIRE recid found},
	pages = {502--507},
}

@article{ghosh_synchronized_2022,
	title = {The synchronized dynamics of time-varying networks},
	volume = {949},
	issn = {03701573},
	url = {http://arxiv.org/abs/2109.07618},
	doi = {10.1016/j.physrep.2021.10.006},
	abstract = {Over the past two decades, complex network theory provided the ideal framework for investigating the intimate relationships between the topological properties characterizing the wiring of connections among a system's unitary components and its emergent synchronized functioning. An increased number of setups from the real world found therefore a representation in term of graphs, while more and more sophisticated methods were developed with the aim of furnishing a realistic description of the connectivity patterns under study. In particular, a significant number of systems in physics, biology and social science features a time-varying nature of the interactions among their units. We here give a comprehensive review of the major results obtained by contemporary studies on the emergence of synchronization in time-varying networks. In particular, two paradigmatic frameworks will be described in details. The first encompasses those systems where the time dependence of the nodes' connections is due to adaptation, external forces, or any other process affecting each of the links of the network. The second framework, instead, corresponds to the case in which the structural evolution of the graph is due to the movement of the nodes, or agents, in physical spaces and to the fact that interactions may be ruled by space-dependent laws in a way that connections are continuously switched on and off in the course of the time. Finally, our report ends with a short discussion on promising directions and open problems for future studies.},
	urldate = {2022-10-17},
	journal = {Physics Reports},
	author = {Ghosh, Dibakar and Frasca, Mattia and Rizzo, Alessandro and Majhi, Soumen and Rakshit, Sarbendu and Alfaro-Bittner, Karin and Boccaletti, Stefano},
	month = feb,
	year = {2022},
	note = {arXiv:2109.07618 [physics]},
	keywords = {Physics - Physics and Society, ⛔ No INSPIRE recid found},
	pages = {1--63},
}

@article{sotomayor-gomez_spikeship_2021,
	title = {{SpikeShip}: {A} method for fast, unsupervised discovery of high-dimensional neural spiking patterns},
	url = {https://www.biorxiv.org/content/10.1101/2020.06.03.131573},
	doi = {10.1101/2020.06.03.131573},
	journal = {bioRxiv : the preprint server for biology},
	author = {Sotomayor-Gómez, Boris and Battaglia, Francesco P and Vinck, Martin},
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2020--06},
}

@article{lee_combinatorial_2004,
	title = {A {Combinatorial} {Method} for {Analyzing} {Sequential} {Firing} {Patterns} {Involving} an {Arbitrary} {Number} of {Neurons} {Based} on {Relative} {Time} {Order}},
	volume = {92},
	issn = {0022-3077, 1522-1598},
	url = {https://www.physiology.org/doi/10.1152/jn.01030.2003},
	doi = {10.1152/jn.01030.2003},
	abstract = {Information processing in the brain is believed to require coordinated activity across many neurons. With the recent development of techniques for simultaneously recording the spiking activity of large numbers of individual neurons, the search for complex multicell firing patterns that could help reveal this neural code has become possible. Here we develop a new approach for analyzing sequential firing patterns involving an arbitrary number of neurons based on relative firing order. Specifically, we develop a combinatorial method for quantifying the degree of matching between a “reference sequence” of N distinct “letters” (representing a particular target order of firing by N cells) and an arbitrarily long “word” composed of any subset of those letters including repeats (representing the relative time order of spikes in an arbitrary firing pattern). The method involves computing the probability that a random permutation of the word's letters would by chance alone match the reference sequence as well as or better than the actual word does, assuming all permutations were equally likely. Lower probabilities thus indicate better matching. The overall degree and statistical significance of sequence matching across a heterogeneous set of words (such as those produced during the course of an experiment) can be computed from the corresponding set of probabilities. This approach can reduce the sample size problem associated with analyzing complex firing patterns. The approach is general and thus applicable to other types of neural data beyond multiple spike trains, such as EEG events or imaging signals from multiple locations. We have recently applied this method to quantify memory traces of sequential experience in the rodent hippocampus during slow wave sleep.},
	language = {en},
	number = {4},
	urldate = {2022-10-17},
	journal = {Journal of Neurophysiology},
	author = {Lee, Albert K. and Wilson, Matthew A.},
	month = oct,
	year = {2004},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2555--2573},
}

@article{nadasdy_replay_1999,
	title = {Replay and {Time} {Compression} of {Recurring} {Spike} {Sequences} in the {Hippocampus}},
	volume = {19},
	copyright = {Copyright © 1999 Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/19/21/9497},
	doi = {10.1523/JNEUROSCI.19-21-09497.1999},
	abstract = {Information in neuronal networks may be represented by the spatiotemporal patterns of spikes. Here we examined the temporal coordination of pyramidal cell spikes in the rat hippocampus during slow-wave sleep. In addition, rats were trained to run in a defined position in space (running wheel) to activate a selected group of pyramidal cells. A template-matching method and a joint probability map method were used for sequence search. Repeating spike sequences in excess of chance occurrence were examined by comparing the number of repeating sequences in the original spike trains and in surrogate trains after Monte Carlo shuffling of the spikes. Four different shuffling procedures were used to control for the population dynamics of hippocampal neurons. Repeating spike sequences in the recorded cell assemblies were present in both the awake and sleeping animal in excess of what might be predicted by random variations. Spike sequences observed during wheel running were “replayed” at a faster timescale during single sharp-wave bursts of slow-wave sleep. We hypothesize that the endogenously expressed spike sequences during sleep reflect reactivation of the circuitry modified by previous experience. Reactivation of acquired sequences may serve to consolidate information.},
	language = {en},
	number = {21},
	urldate = {2022-10-17},
	journal = {Journal of Neuroscience},
	author = {Nádasdy, Zoltán and Hirase, Hajime and Czurkó, András and Csicsvari, Jozsef and Buzsáki, György},
	month = nov,
	year = {1999},
	pmid = {10531452},
	note = {Publisher: Society for Neuroscience
Section: ARTICLE},
	keywords = {coding, decoding, memory, network, retrieval, sharp waves, sleep, θ, ⛔ No INSPIRE recid found},
	pages = {9497--9507},
}

@article{aronov_non-euclidean_2004,
	title = {Non-{Euclidean} properties of spike train metric spaces},
	volume = {69},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.69.061905},
	doi = {10.1103/PhysRevE.69.061905},
	abstract = {Quantifying the dissimilarity (or distance) between two sequences is essential to the study of action potential (spike) trains in neuroscience and genetic sequences in molecular biology. In neuroscience, traditional methods for sequence comparisons rely on techniques appropriate for multivariate data, which typically assume that the space of sequences is intrinsically Euclidean. More recently, metrics that do not make this assumption have been introduced for comparison of neural activity patterns. These metrics have a formal resemblance to those used in the comparison of genetic sequences. Yet the relationship between such metrics and the traditional Euclidean distances has remained unclear. We show, both analytically and computationally, that the geometries associated with metric spaces of event sequences are intrinsically non-Euclidean. Our results demonstrate that metric spaces enrich the study of neural activity patterns, since accounting for perceptual spaces requires a non-Euclidean geometry.},
	number = {6},
	urldate = {2022-10-17},
	journal = {Physical Review E},
	author = {Aronov, Dmitriy and Victor, Jonathan D.},
	month = jun,
	year = {2004},
	note = {Publisher: American Physical Society},
	keywords = {⛔ No INSPIRE recid found},
	pages = {061905},
}

@article{victor_nature_1996,
	title = {Nature and precision of temporal coding in visual cortex: a metric-space analysis},
	volume = {76},
	issn = {0022-3077, 1522-1598},
	shorttitle = {Nature and precision of temporal coding in visual cortex},
	url = {https://www.physiology.org/doi/10.1152/jn.1996.76.2.1310},
	doi = {10.1152/jn.1996.76.2.1310},
	abstract = {1. We recorded single-unit and multi-unit activity in response to transient presentation of texture and grating patterns at 25 sites within the parafoveal representation of V1, V2, and V3 of two awake monkeys trained to perform a fixation task. In grating experiments, stimuli varied in orientation, spatial frequency, or both. In texture experiments, stimuli varied in contrast, check size, texture type, or pairs of these attributes. 2. To examine the nature and precision of temporal coding, we compared individual responses elicited by each set of stimuli in terms of two families of metrics. One family of metrics, D(spike), was sensitive to the absolute spike time (following stimulus onset). The second family of metrics, D(interval), was sensitive to the pattern of interspike intervals. In each family, the metrics depend on a parameter q, which expresses the precision of temporal coding. For q = 0, both metrics collapse into the "spike count" metric D(Count), which is sensitive to the number of impulses but insensitive to their position in time. 3. Each of these metrics, with values of q ranging from 0 to 512/s, was used to calculate the distance between all pairs of spike trains within each dataset. The extent of stimulus-specific clustering manifest in these pairwise distances was quantified by an information measure. Chance clustering was estimated by applying the same procedure to synthetic data sets in which responses were assigned randomly to the input stimuli. 4. Of the 352 data sets, 170 showed evidence of tuning via the spike count (q = 0) metric, 294 showed evidence of tuning via the spike time metric, 272 showed evidence of tuning via the spike interval metric to the stimulus attribute (contrast, check size, orientation, spatial frequency, or texture type) under study. Across the entire dataset, the information not attributable to chance clustering averaged 0.042 bits for the spike count metric, 0.171 bits for the optimal spike time metric, and 0.107 bits for the optimal spike interval metric. 5. The reciprocal of the optimal cost q serves as a measure of the temporal precision of temporal coding. In V1 and V2, with both metrics, temporal precision was highest for contrast (ca. 10-30 ms) and lowest for texture type (ca. 100 ms). This systematic dependence of q on stimulus attribute provides a possible mechanism for the simultaneous representation of multiple stimulus attributes in one spike train. 6. Our findings are inconsistent with Poisson models of spike trains. Synthetic data sets in which firing rate was governed by a time-dependent Poisson process matched to the observed poststimulus time histogram (PSTH) overestimated clustering induced by D(count) and, for low values of q, D(spike)[q] and D(intervals)[q]. Synthetic data sets constructed from a modified Poisson process, which preserved not only the PSTH but also spike count statistics accounted for the clustering induced by D(count) but underestimated the clustering induced by D(spike)[q] and D(interval)[q].},
	language = {en},
	number = {2},
	urldate = {2022-10-17},
	journal = {Journal of Neurophysiology},
	author = {Victor, J. D. and Purpura, K. P.},
	month = aug,
	year = {1996},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1310--1326},
}

@article{van_rossum_novel_2001,
	title = {A novel spike distance},
	volume = {13},
	issn = {0899-7667},
	doi = {10.1162/089976601300014321},
	abstract = {The discrimination between two spike trains is a fundamental problem for both experimentalists and the nervous system itself. We introduce a measure for the distance between two spike trains. The distance has a time constant as a parameter. Depending on this parameter, the distance interpolates between a coincidence detector and a rate difference counter. The dependence of the distance on noise is studied with an integrate-and-fire model. For an intermediate range of the time constants, the distance depends linearly on the noise. This property can be used to determine the intrinsic noise of a neuron.},
	language = {eng},
	number = {4},
	journal = {Neural Computation},
	author = {van Rossum, M. C.},
	month = apr,
	year = {2001},
	pmid = {11255567},
	keywords = {Algorithms, Evoked Potentials, Models, Neurological, Neurons, Poisson Distribution, ⛔ No INSPIRE recid found},
	pages = {751--763},
}

@article{dahlem_dynamics_2009,
	title = {Dynamics of delay-coupled excitable neural systems},
	volume = {19},
	url = {https://doi.org/d43v5b},
	doi = {10.1142/s0218127409023111},
	abstract = {We study the nonlinear dynamics of two delay-coupled neural systems each modeled by excitable dynamics of FitzHugh–Nagumo type and demonstrate that bistability between the stable fixed point and limit cycle oscillations occurs for sufficiently large delay times τ and coupling strength C. As the mechanism for these delay-induced oscillations, we identify a saddle-node bifurcation of limit cycles.},
	language = {en},
	number = {02},
	journal = {International Journal of Bifurcation and Chaos},
	author = {Dahlem, M. A. and HILLER, G. and PANCHUK, A. and SCHÖLL, E.},
	year = {2009},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1142/s0218127409023111},
	keywords = {⛔ No INSPIRE recid found},
	pages = {745--753},
}

@article{khoei_motion-based_2013,
	title = {Motion-based prediction explains the role of tracking in motion extrapolation},
	volume = {107},
	issn = {09284257},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S092842571300051X},
	doi = {10.1016/j.jphysparis.2013.08.001},
	abstract = {During normal viewing, the continuous stream of visual input is regularly interrupted, for instance by blinks of the eye. Despite these frequents blanks (that is the transient absence of a raw sensory source), the visual system is most often able to maintain a continuous representation of motion. For instance, it maintains the movement of the eye such as to stabilize the image of an object. This ability suggests the existence of a generic neural mechanism of motion extrapolation to deal with fragmented inputs. In this paper, we have modeled how the visual system may extrapolate the trajectory of an object during a blank using motion-based prediction. This implies that using a prior on the coherency of motion, the system may integrate previous motion information even in the absence of a stimulus. In order to compare with experimental results, we simulated tracking velocity responses. We found that the response of the motion integration process to a blanked trajectory pauses at the onset of the blank, but that it quickly recovers the information on the trajectory after reappearance. This is compatible with behavioral and neural observations on motion extrapolation. To understand these mechanisms, we have recorded the response of the model to a noisy stimulus. Crucially, we found that motion-based prediction acted at the global level as a gain control mechanism and that we could switch from a smooth regime to a binary tracking behavior where the dot is tracked or lost. Our results imply that a local prior implementing motion-based prediction is sufﬁcient to explain a large range of neural and behavioral results at a more global level. We show that the tracking behavior deteriorates for sensory noise levels higher than a certain value, where motion coherency and predictability fail to hold longer. In particular, we found that motion-based prediction leads to the emergence of a tracking behavior only when enough information from the trajectory has been accumulated. Then, during tracking, trajectory estimation is robust to blanks even in the presence of relatively high levels of noise. Moreover, we found that tracking is necessary for motion extrapolation, this calls for further experimental work exploring the role of noise in motion extrapolation.},
	language = {en},
	number = {5},
	urldate = {2022-10-17},
	journal = {Journal of Physiology-Paris},
	author = {Khoei, Mina A. and Masson, Guillaume S. and Perrinet, Laurent U.},
	month = nov,
	year = {2013},
	keywords = {⛔ No INSPIRE recid found},
	pages = {409--420},
}

@article{susi_nmnsd-spiking_2021,
	title = {{nMNSD}-{A} {Spiking} {Neuron}-{Based} {Classifier} {That} {Combines} {Weight}-{Adjustment} and {Delay}-{Shift}},
	volume = {15},
	issn = {1662-4548},
	doi = {10.3389/fnins.2021.582608},
	abstract = {The recent "multi-neuronal spike sequence detector" (MNSD) architecture integrates the weight- and delay-adjustment methods by combining heterosynaptic plasticity with the neurocomputational feature spike latency, representing a new opportunity to understand the mechanisms underlying biological learning. Unfortunately, the range of problems to which this topology can be applied is limited because of the low cardinality of the parallel spike trains that it can process, and the lack of a visualization mechanism to understand its internal operation. We present here the nMNSD structure, which is a generalization of the MNSD to any number of inputs. The mathematical framework of the structure is introduced, together with the "trapezoid method," that is a reduced method to analyze the recognition mechanism operated by the nMNSD in response to a specific input parallel spike train. We apply the nMNSD to a classification problem previously faced with the classical MNSD from the same authors, showing the new possibilities the nMNSD opens, with associated improvement in classification performances. Finally, we benchmark the nMNSD on the classification of static inputs (MNIST database) obtaining state-of-the-art accuracies together with advantageous aspects in terms of time- and energy-efficiency if compared to similar classification methods.},
	language = {eng},
	journal = {Frontiers in Neuroscience},
	author = {Susi, Gianluca and Antón-Toro, Luis F. and Maestú, Fernando and Pereda, Ernesto and Mirasso, Claudio},
	year = {2021},
	pmid = {33679293},
	pmcid = {PMC7933525},
	keywords = {MNIST database, MNSD, classification, delay learning, heterosynaptic plasticity, online learning, spike latency, ⛔ No INSPIRE recid found},
	pages = {582608},
}

@article{dugue_phase_2011,
	title = {The {Phase} of {Ongoing} {Oscillations} {Mediates} the {Causal} {Relation} between {Brain} {Excitation} and {Visual} {Perception}},
	volume = {31},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.1161-11.2011},
	doi = {10.1523/JNEUROSCI.1161-11.2011},
	language = {en},
	number = {33},
	urldate = {2022-10-17},
	journal = {Journal of Neuroscience},
	author = {Dugue, L. and Marque, P. and VanRullen, R.},
	month = aug,
	year = {2011},
	keywords = {⛔ No INSPIRE recid found},
	pages = {11889--11893},
}

@article{fries_mechanism_2005,
	title = {A mechanism for cognitive dynamics: neuronal communication through neuronal coherence},
	volume = {9},
	issn = {1364-6613},
	shorttitle = {A mechanism for cognitive dynamics},
	doi = {10.1016/j.tics.2005.08.011},
	abstract = {At any one moment, many neuronal groups in our brain are active. Microelectrode recordings have characterized the activation of single neurons and fMRI has unveiled brain-wide activation patterns. Now it is time to understand how the many active neuronal groups interact with each other and how their communication is flexibly modulated to bring about our cognitive dynamics. I hypothesize that neuronal communication is mechanistically subserved by neuronal coherence. Activated neuronal groups oscillate and thereby undergo rhythmic excitability fluctuations that produce temporal windows for communication. Only coherently oscillating neuronal groups can interact effectively, because their communication windows for input and for output are open at the same times. Thus, a flexible pattern of coherence defines a flexible communication structure, which subserves our cognitive flexibility.},
	language = {eng},
	number = {10},
	journal = {Trends in Cognitive Sciences},
	author = {Fries, Pascal},
	month = oct,
	year = {2005},
	pmid = {16150631},
	keywords = {Action Potentials, Animals, Biological Clocks, Brain, Cognition, Humans, Nerve Net, Neurons, Nonlinear Dynamics, Periodicity, Pyramidal Tracts, Synaptic Transmission, ⛔ No INSPIRE recid found},
	pages = {474--480},
}

@book{hebb_organization_1949,
	address = {New York},
	title = {The organization of behavior: {A} neuropsychological theory},
	publisher = {Wiley},
	author = {Hebb, Donald O.},
	year = {1949},
	keywords = {\#nosource, bicv-sparse, ⛔ No INSPIRE recid found},
}

@article{benvenuti_anticipatory_2020,
	title = {Anticipatory responses along motion trajectories in awake monkey area {V1}},
	copyright = {All rights reserved},
	url = {https://www.biorxiv.org/content/10.1101/2020.03.26.010017v1},
	doi = {10.1101/2020.03.26.010017},
	abstract = {What are the neural mechanisms underlying motion integration of translating objects? Visual motion integration is generally conceived of as a feedforward, hierarchical, information processing. However, feedforward models fail to account for many contextual effects revealed using natural moving stimuli. In particular, a translating object evokes a sequence of transient feedforward responses in the primary visual cortex but also propagations of activity through horizontal and feedback pathways. We investigated how these pathways shape the representation of a translating bar in monkey V1. We show that, for long trajectories, spiking activity builds-up hundreds of milliseconds before the bar enters the neurons receptive fields. Using VSDI and LFP recordings guided by a phenomenological model of propagation dynamics, we demonstrate that this anticipatory response arises from the interplay between horizontal and feedback networks driving V1 neurons well ahead of their feedforward inputs. This mechanism could subtend several perceptual contextual effects observed with translating objects.},
	language = {english},
	urldate = {2020-03-31},
	journal = {bioRxiv : the preprint server for biology},
	author = {Benvenuti, Giacomo and Chemla, Sandrine and Boonman, Arjan and Perrinet, Laurent U and Masson, Guillaume S and Chavane, Frederic},
	month = mar,
	year = {2020},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2020.03.26.010017},
}

@article{le_bec_horizontal_2022,
	title = {Horizontal connectivity in {V1}: {Prediction} of coherence in contour and motion integration},
	volume = {17},
	issn = {1932-6203},
	shorttitle = {Horizontal connectivity in {V1}},
	url = {https://dx.plos.org/10.1371/journal.pone.0268351},
	doi = {10.1371/journal.pone.0268351},
	abstract = {This study demonstrates the functional importance of the Surround context relayed laterally in V1 by the horizontal connectivity, in controlling the latency and the gain of the cortical response to the feedforward visual drive. We report here four main findings: 1) a centripetal apparent motion sequence results in a shortening of the spiking latency of V1 cells, when the orientation of the local inducer and the global motion axis are both co-aligned with the RF orientation preference; 2) this contextual effects grows with visual flow speed, peaking at 150–250°/s when it matches the propagation speed of horizontal connectivity (0.15–0.25 mm/ms); 3) For this speed range, the axial sensitivity of V1 cells is tilted by 90° to become co-aligned with the orientation preference axis; 4) the strength of modulation by the surround context correlates with the spatiotemporal coherence of the apparent motion flow. Our results suggest an internally-generated binding process, linking local (orientation /position) and global (motion/direction) features as early as V1. This long-range diffusion process constitutes a plausible substrate in V1 of the human psychophysical bias in speed estimation for collinear motion. Since it is demonstrated in the anesthetized cat, this novel form of contextual control of the cortical gain and phase is a built-in property in V1, whose expression does not require behavioral attention and top-down control from higher cortical areas. We propose that horizontal connectivity participates in the propagation of an internal “prediction” wave, shaped by visual experience, which links contour co-alignment and global axial motion at an apparent speed in the range of saccade-like eye movements.},
	language = {en},
	number = {7},
	urldate = {2022-09-26},
	journal = {PLOS ONE},
	author = {Le Bec, Benoit and Troncoso, Xoana G. and Desbois, Christophe and Passarelli, Yannick and Baudot, Pierre and Monier, Cyril and Pananceau, Marc and Frégnac, Yves},
	editor = {Charpier, Stéphane},
	month = jul,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found},
	pages = {e0268351},
}

@article{pearce_marie-jean-pierre_2009,
	title = {Marie-{Jean}-{Pierre} {Flourens} (1794–1867) and {Cortical} {Localization}},
	volume = {61},
	issn = {0014-3022, 1421-9913},
	url = {https://www.karger.com/Article/FullText/206858},
	doi = {10.1159/000206858},
	abstract = {The child prodigy Marie-Jean-Pierre Flourens received his medical degree at Montpellier when aged 19. As a young promising physician Flourens was asked to investigate Gall’s controversial views on cerebral localization. To test Gall’s assertions, Flourens developed ablation as a procedure to explore the workings of the brain. By removing anatomically defined areas of the brain of an animal and watching its behaviour, he thought he might localize certain functions. Flourens did not favour the idea of cerebral localization and concluded that the brain functioned as a whole and thus arose the concept of ‘cerebral equipotentiality’. This culminated in his 1824 Recherches expérimentales sur les propriétés et les fonctions du système nerveux. His techniques were, however, crude and imperfect, and his experiments were mainly on birds. Much criticism and debate ensued. A gifted man, Flourens also advanced the physiology of the vestibular apparatus and described the anaesthetic properties of ether.},
	language = {en},
	number = {5},
	urldate = {2022-10-10},
	journal = {European Neurology},
	author = {Pearce, J.M.S.},
	year = {2009},
	keywords = {⛔ No INSPIRE recid found},
	pages = {311--314},
}

@article{carandini_normalization_2012,
	title = {Normalization as a canonical neural computation},
	volume = {13},
	doi = {10.1038/nrn3136},
	number = {1},
	journal = {Nature Reviews Neuroscience},
	author = {Carandini, Matteo and Heeger, David J},
	year = {2012},
	pmid = {22108672},
	note = {tex.ids= Carandini12a, Carandini2011
publisher: Nature Publishing Group},
	keywords = {\#nosource, Adaptation, Afferent Pathways, Anim, Physiological, contrast\_response, divisive\_normalization, normalization, ⛔ No INSPIRE recid found},
	pages = {51--62},
}

@article{hubel_receptive_1968,
	title = {Receptive fields and functional architecture of monkey striate cortex},
	volume = {195},
	issn = {1469-7793},
	url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1968.sp008455},
	doi = {10.1113/jphysiol.1968.sp008455},
	language = {english},
	number = {1},
	journal = {The Journal of Physiology},
	author = {Hubel, David H and Wiesel, Torsten N},
	year = {1968},
	pmcid = {PMC1557912},
	pmid = {4966457},
	note = {tex.ids= Hubel1968a
tex.bdsk-url-2: https://doi.org/10/gc8z3q},
	keywords = {\#nosource, area-v1, bicv-motion, bicv-sparse, ⛔ No INSPIRE recid found},
	pages = {215--243},
}

@article{adrian_impulses_1926,
	title = {The impulses produced by sensory nerve endings},
	volume = {61},
	issn = {0022-3751},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1514868/},
	abstract = {Images
null},
	number = {4},
	urldate = {2022-10-10},
	journal = {The Journal of Physiology},
	author = {Adrian, E. D. and Zotterman, Yngve},
	month = aug,
	year = {1926},
	pmid = {16993807},
	pmcid = {PMC1514868},
	keywords = {⛔ No INSPIRE recid found},
	pages = {465--483},
}

@article{piccolino_luigi_1997,
	title = {Luigi {Galvani} and animal electricity: two centuries after the foundation of electrophysiology},
	volume = {20},
	issn = {0166-2236},
	shorttitle = {Luigi {Galvani} and animal electricity},
	url = {https://www.sciencedirect.com/science/article/pii/S0166223697011016},
	doi = {10.1016/S0166-2236(97)01101-6},
	abstract = {Luigi Galvani and his famous experiments on frogs carried out in the second half of the 18th century belong more to legend than to the history of science. Galvani not only laid the foundations of a new science, electrophysiology, but also opened the way for the invention of the electric battery, and thus for the development of the physical investigations of electricity. However, in spite of the widespread celebration of his work, Galvani's scientific endeavours have been largely misrepresented in the history of science. The scholar of Bologna has a stereotyped image as an `occasional' scientist, who started his studies by chance, largely ignored the scientific theories of his time and wandered aimlessly in mental elaborations until the physicist of Pavia, Alessandro Volta, entered the field, correctly interpreted Galvani's results and eventually developed the electric battery. With the present understanding of electrical phenomena in excitable membranes, it is now time to reconsider the real matter raised by Galvani's discoveries and by his hypothesis of an intrinsic `animal electricity', and to make a clearer evaluation of a revolutionary phase of scientific progress.},
	language = {en},
	number = {10},
	urldate = {2022-10-10},
	journal = {Trends in Neurosciences},
	author = {Piccolino, Marco},
	month = oct,
	year = {1997},
	keywords = {Galvani, Volta, animal electricity, electrophysiology, history of science, nervous signalling, ⛔ No INSPIRE recid found},
	pages = {443--448},
}

@article{haessig_event-based_2020,
	title = {Event-{Based} {Computation} for {Touch} {Localization} {Based} on {Precise} {Spike} {Timing}},
	volume = {14},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/article/10.3389/fnins.2020.00420},
	doi = {10/ghvnxj},
	abstract = {Precise spike timing and temporal coding are used extensively within the nervous system of insects and in the sensory periphery of higher order animals. However, conventional Artificial Neural Networks (ANNs) and machine learning algorithms cannot take advantage of this coding strategy, due to their rate-based representation of signals. Even in the case of artificial Spiking Neural Networks (SNNs), identifying applications where temporal coding outperforms the rate coding strategies of ANNs is still an open challenge. Neuromorphic sensory-processing systems provide an ideal context for exploring the potential advantages of temporal coding, as they are able to efficiently extract the information required to cluster or classify spatio-temporal activity patterns from relative spike timing. Here we propose a neuromorphic model inspired by the sand scorpion to explore the benefits of temporal coding, and validate it in an event-based sensory-processing task. The task consists in localizing a target using only the relative spike timing of eight spatially-separated vibration sensors. We propose two different approaches in which the SNNs learns to cluster spatio-temporal patterns in an unsupervised manner and we demonstrate how the task can be solved both analytically and through numerical simulation of multiple SNN models. We argue that the models presented are optimal for spatio-temporal pattern classification using precise spike timing in a task that could be used as a standard benchmark for evaluating event-based sensory processing models based on temporal coding.},
	urldate = {2021-10-20},
	journal = {Frontiers in Neuroscience},
	author = {Haessig, Germain and Milde, Moritz B. and Aceituno, Pau Vilimelis and Oubari, Omar and Knight, James C. and van Schaik, André and Benosman, Ryad B. and Indiveri, Giacomo},
	year = {2020},
	note = {00007
tex.ids= Haessig2020a},
	keywords = {⛔ No INSPIRE recid found},
	pages = {420},
}

@article{wang_neuromorphic_2015,
	title = {A neuromorphic implementation of multiple spike-timing synaptic plasticity rules for large-scale neural networks},
	volume = {9},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2015.00180},
	doi = {10.3389/fnins.2015.00180},
	abstract = {We present a neuromorphic implementation of multiple synaptic plasticity learning rules, which include both Spike Timing Dependent Plasticity (STDP) and Spike Timing Dependent Delay Plasticity (STDDP). We present a fully digital implementation as well as a mixed-signal implementation, both of which use a novel dynamic-assignment time-multiplexing approach and support up to 226 (64M) synaptic plasticity elements. Rather than implementing dedicated synapses for particular types of synaptic plasticity, we implemented a more generic synaptic plasticity adaptor array that is separate from the neurons in the neural network. Each adaptor performs synaptic plasticity according to the arrival times of the pre- and post-synaptic spikes assigned to it, and sends out a weighted or delayed pre-synaptic spike to the post-synaptic neuron in the neural network. This strategy provides great flexibility for building complex large-scale neural networks, as a neural network can be configured for multiple synaptic plasticity rules without changing its structure. We validate the proposed neuromorphic implementations with measurement results and illustrate that the circuits are capable of performing both STDP and STDDP. We argue that it is practical to scale the work presented here up to 236 (64G) synaptic adaptors on a current high-end FPGA platform.},
	urldate = {2022-10-06},
	journal = {Frontiers in Neuroscience},
	author = {Wang, Runchun M. and Hamilton, Tara J. and Tapson, Jonathan C. and van Schaik, André},
	year = {2015},
	keywords = {⛔ No INSPIRE recid found},
}

@article{isbister_clustering_2021,
	title = {Clustering and control for adaptation uncovers time-warped spike time patterns in cortical networks in vivo},
	volume = {11},
	copyright = {2021 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-021-94002-0},
	doi = {10.1038/s41598-021-94002-0},
	abstract = {How information in the nervous system is encoded by patterns of action potentials (i.e. spikes) remains an open question. Multi-neuron patterns of single spikes are a prime candidate for spike time encoding but their temporal variability requires further characterisation. Here we show how known sources of spike count variability affect stimulus-evoked spike time patterns between neurons separated over multiple layers and columns of adult rat somatosensory cortex in vivo. On subsets of trials (clusters) and after controlling for stimulus-response adaptation, spike time differences between pairs of neurons are “time-warped” (compressed/stretched) by trial-to-trial changes in shared excitability, explaining why fixed spike time patterns and noise correlations are seldom reported. We show that predicted cortical state is correlated between groups of 4 neurons, introducing the possibility of spike time pattern modulation by population-wide trial-to-trial changes in excitability (i.e. cortical state). Under the assumption of state-dependent coding, we propose an improved potential encoding capacity.},
	language = {en},
	number = {1},
	urldate = {2022-10-06},
	journal = {Scientific Reports},
	author = {Isbister, James B. and Reyes-Puerta, Vicente and Sun, Jyh-Jang and Horenko, Illia and Luhmann, Heiko J.},
	month = jul,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {⛔ No INSPIRE recid found},
	pages = {15066},
}

@article{dard_rapid_2022,
	title = {The rapid developmental rise of somatic inhibition disengages hippocampal dynamics from self-motion},
	volume = {11},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.78116},
	doi = {10.7554/eLife.78116},
	abstract = {Early electrophysiological brain oscillations recorded in preterm babies and newborn rodents are initially mostly driven by bottom-up sensorimotor activity and only later can detach from external inputs. This is a hallmark of most developing brain areas, including the hippocampus, which, in the adult brain, functions in integrating external inputs onto internal dynamics. Such developmental disengagement from external inputs is likely a fundamental step for the proper development of cognitive internal models. Despite its importance, the developmental timeline and circuit basis for this disengagement remain unknown. To address this issue, we have investigated the daily evolution of CA1 dynamics and underlying circuits during the first two postnatal weeks of mouse development using two-photon calcium imaging in non-anesthetized pups. We show that the first postnatal week ends with an abrupt shift in the representation of self-motion in CA1. Indeed, most CA1 pyramidal cells switch from activated to inhibited by self-generated movements at the end of the first postnatal week, whereas the majority of GABAergic neurons remain positively modulated throughout this period. This rapid switch occurs within 2 days and follows the rapid anatomical and functional surge of local somatic GABAergic innervation. The observed change in dynamics is consistent with a two-population model undergoing a strengthening of inhibition. We propose that this abrupt developmental transition inaugurates the emergence of internal hippocampal dynamics.},
	urldate = {2022-10-05},
	journal = {eLife},
	author = {Dard, Robin F and Leprince, Erwan and Denis, Julien and Rao Balappa, Shrisha and Suchkov, Dmitrii and Boyce, Richard and Lopez, Catherine and Giorgi-Kurz, Marie and Szwagier, Tom and Dumont, Théo and Rouault, Hervé and Minlebaev, Marat and Baude, Agnès and Cossart, Rosa and Picardo, Michel A},
	editor = {Peyrache, Adrien and Colgin, Laura L and Butt, Simon JB},
	month = jul,
	year = {2022},
	note = {tex.ids= Dard2021
publisher: eLife Sciences Publications, Ltd},
	keywords = {⛔ No INSPIRE recid found},
	pages = {e78116},
}

@inproceedings{thanasoulis_delay-based_2021,
	title = {Delay-{Based} {Neural} {Computation}: {Pulse} {Routing} {Architecture} and {Benchmark} {Application} in {FPGA}},
	url = {https://doi.org/gn63rh},
	doi = {10.1109/icecs53924.2021.9665468},
	booktitle = {2021 28th {IEEE} {International} {Conference} on {Electronics}, {Circuits}, and {Systems} ({ICECS})},
	publisher = {IEEE},
	author = {Thanasoulis, Vasilis and Vogginger, Bernhard and Partzsch, Johannes and Mayr, Christian},
	month = nov,
	year = {2021},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1109/icecs53924.2021.9665468
tex.ids= Thanasoulis2021a},
	keywords = {⛔ No INSPIRE recid found},
}

@article{wang_delay_2019,
	title = {A {Delay} {Learning} {Algorithm} {Based} on {Spike} {Train} {Kernels} for {Spiking} {Neurons}},
	volume = {13},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2019.00252},
	abstract = {Neuroscience research confirms that the synaptic delays are not constant, but can be modulated. This paper proposes a supervised delay learning algorithm for spiking neurons with temporal encoding, in which both the weight and delay of a synaptic connection can be adjusted to enhance the learning performance. The proposed algorithm firstly defines spike train kernels to transform discrete spike trains during the learning phase into continuous analog signals so that common mathematical operations can be performed on them, and then deduces the supervised learning rules of synaptic weights and delays by gradient descent method. The proposed algorithm is successfully applied to various spike train learning tasks, and the effects of parameters of synaptic delays are analyzed in detail. Experimental results show that the network with dynamic delays achieves higher learning accuracy and less learning epochs than the network with static delays. The delay learning algorithm is further validated on a practical example of an image classification problem. The results again show that it can achieve a good classification performance with a proper receptive field. Therefore, the synaptic delay learning is significant for practical applications and theoretical researches of spiking neural networks.},
	urldate = {2022-10-04},
	journal = {Frontiers in Neuroscience},
	author = {Wang, Xiangwen and Lin, Xianghong and Dang, Xiaochao},
	year = {2019},
	keywords = {⛔ No DOI found, ⛔ No INSPIRE recid found},
}

@article{berry_spike_2022,
	title = {Spike {Trains} of {Retinal} {Ganglion} {Cells} {Viewing} a {Repeated} {Natural} {Movie}},
	url = {https://dataspace.princeton.edu/handle/88435/dsp015425kd84r},
	doi = {10.34770/V0V4-3H52},
	abstract = {This archive contains spike trains simultaneously recorded from ganglion cells in the tiger salamander retina with a multi-electrode array while viewing a repeated natural movie clip.  These data have been analyzed in previous papers, notably Puchalla et al. Neuron 2005 and Schneidman et al. Nature 2006.},
	language = {en\_US},
	urldate = {2022-10-04},
	author = {Berry, Michael J.},
	month = mar,
	year = {2022},
	note = {type: dataset
This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: url:https://dataspace.princeton.edu/handle/88435/dsp015425kd84r},
	keywords = {⛔ No INSPIRE recid found},
}

@article{pang_fast_2019,
	title = {Fast and flexible sequence induction in spiking neural networks via rapid excitability changes},
	volume = {8},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.44324},
	doi = {10.7554/eLife.44324},
	abstract = {Cognitive flexibility likely depends on modulation of the dynamics underlying how biological neural networks process information. While dynamics can be reshaped by gradually modifying connectivity, less is known about mechanisms operating on faster timescales. A compelling entrypoint to this problem is the observation that exploratory behaviors can rapidly cause selective hippocampal sequences to ‘replay’ during rest. Using a spiking network model, we asked whether simplified replay could arise from three biological components: fixed recurrent connectivity; stochastic ‘gating’ inputs; and rapid gating input scaling via long-term potentiation of intrinsic excitability (LTP-IE). Indeed, these enabled both forward and reverse replay of recent sensorimotor-evoked sequences, despite unchanged recurrent weights. LTP-IE ‘tags’ specific neurons with increased spiking probability under gating input, and ordering is reconstructed from recurrent connectivity. We further show how LTP-IE can implement temporary stimulus-response mappings. This elucidates a novel combination of mechanisms that might play a role in rapid cognitive flexibility.},
	urldate = {2022-10-04},
	journal = {eLife},
	author = {Pang, Rich and Fairhall, Adrienne L},
	editor = {Salinas, Emilio and Marder, Eve and Salinas, Emilio},
	month = may,
	year = {2019},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {cognitive flexibility, excitability, neural network, neurocentric, sequence, short-term memory, ⛔ No INSPIRE recid found},
	pages = {e44324},
}

@article{weyl_ueber_1916,
	title = {Ueber die {Gleichverteilung} von {Zahlen} mod. {Eins}},
	volume = {77},
	url = {https://doi.org/crprvc},
	doi = {10.1007/bf01475864},
	language = {de},
	number = {3},
	journal = {Mathematische Annalen},
	author = {Weyl, Hermann},
	month = sep,
	year = {1916},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1007/bf01475864},
	keywords = {⛔ No INSPIRE recid found},
	pages = {313--352},
}

@article{perkel_neuronal_1967,
	title = {Neuronal {Spike} {Trains} and {Stochastic} {Point} {Processes}: {I}. {The} {Single} {Spike} {Train}},
	volume = {7},
	issn = {0006-3495},
	shorttitle = {Neuronal {Spike} {Trains} and {Stochastic} {Point} {Processes}},
	url = {https://www.sciencedirect.com/science/article/pii/S0006349567865962},
	doi = {10.1016/S0006-3495(67)86596-2},
	abstract = {In a growing class of neurophysiological experiments, the train of impulses (“spikes”) produced by a nerve cell is subjected to statistical treatment involving the time intervals between spikes. The statistical techniques available for the analysis of single spike trains are described and related to the underlying mathematical theory, that of stochastic point processes, i.e., of stochastic processes whose realizations may be described as series of point events occurring in time, separated by random intervals. For single stationary spike trains, several orders of complexity of statistical treatment are described; the major distinction is that between statistical measures that depend in an essential way on the serial order of interspike intervals and those that are order-independent. The interrelations among the several types of calculations are shown, and an attempt is made to ameliorate the current nomenclatural confusion in this field. Applications, interpretations, and potential difficulties of the statistical techniques are discussed, with special reference to types of spike trains encountered experimentally. Next, the related types of analysis are described for experiments which involve repeated presentations of a brief, isolated stimulus. Finally, the effects of nonstationarity, e.g. long-term changes in firing rate, on the various statistical measures are discussed. Several commonly observed patterns of spike activity are shown to be differentially sensitive to such changes. A companion paper covers the analysis of simultaneously observed spike trains.},
	language = {en},
	number = {4},
	urldate = {2022-10-04},
	journal = {Biophysical Journal},
	author = {Perkel, Donald H. and Gerstein, George L. and Moore, George P.},
	month = jul,
	year = {1967},
	keywords = {⛔ No INSPIRE recid found},
	pages = {391--418},
}

@article{perkel_neuronal_1967-1,
	title = {Neuronal {Spike} {Trains} and {Stochastic} {Point} {Processes}: {II}. {Simultaneous} {Spike} {Trains}},
	volume = {7},
	issn = {0006-3495},
	shorttitle = {Neuronal {Spike} {Trains} and {Stochastic} {Point} {Processes}},
	url = {https://www.sciencedirect.com/science/article/pii/S0006349567865974},
	doi = {10.1016/S0006-3495(67)86597-4},
	abstract = {The statistical analysis of two simultaneously observed trains of neuronal spikes is described, using as a conceptual framework the theory of stochastic point processes. The first statistical question that arises is whether the observed trains are independent; statistical techniques for testing independence are developed around the notion that, under the null hypothesis, the times of spike occurrence in one train represent random instants in time with respect to the other. If the null hypothesis is rejected—if dependence is attributed to the trains—the problem then becomes that of characterizing the nature and source of the observed dependencies. Statistical signs of various classes of dependencies, including direct interaction and shared input, are discussed and illustrated through computer simulations of interacting neurons. The effects of nonstationarities on the statistical measures for simultaneous spike trains are also discussed. For two-train comparisons of irregularly discharging nerve cells, moderate nonstationarities are shown to have little effect on the detection of interactions. Combining repetitive stimulation and simultaneous recording of spike trains from two (or more) neurons yields additional clues as to possible modes of interaction among the monitored neurons; the theory presented is illustrated by an application to experimentally obtained data from auditory neurons. A companion paper covers the analysis of single spike trains.},
	language = {en},
	number = {4},
	urldate = {2022-10-04},
	journal = {Biophysical Journal},
	author = {Perkel, Donald H. and Gerstein, George L. and Moore, George P.},
	month = jul,
	year = {1967},
	keywords = {⛔ No INSPIRE recid found},
	pages = {419--440},
}

@misc{ghosh_spatiotemporal_2019,
	title = {Spatiotemporal filtering for event-based action recognition},
	url = {http://arxiv.org/abs/1903.07067},
	author = {Ghosh, Rohan and Gupta, Anupam and Silva, Andrei Nakagawa and Soares, Alcimar and Thakor, Nitish V.},
	year = {2019},
	keywords = {⛔ No DOI found, ⛔ No INSPIRE recid found},
}

@article{warner_probabilistic_2022,
	title = {A probabilistic latent variable model for detecting structure in binary data},
	url = {http://arxiv.org/abs/2201.11108},
	abstract = {We introduce a novel, probabilistic binary latent variable model to detect noisy or approximate repeats of patterns in sparse binary data. The model is based on the ”Noisy-OR model” [5], used previously for disease and topic modelling. The model’s capability is demonstrated by extracting structure in recordings from retinal neurons, but it can be widely applied to discover and model latent structure in noisy binary data. In the context of spiking neural data, the task is to “explain” spikes of individual neurons in terms of groups of neurons, ”Cell Assemblies” (CAs), that often fire together, due to mutual interactions or other causes. The model infers sparse activity in a set of binary latent variables, each describing the activity of a cell assembly. When the latent variable of a cell assembly is active, it reduces the probabilities of neurons belonging to this assembly to be inactive. The conditional probability kernels of the latent components are learned from the data in an expectation maximization scheme, involving inference of latent states and parameter adjustments to the model. We thoroughly validate the model on synthesized spike trains constructed to statistically resemble recorded retinal responses to white noise stimulus and natural movie stimulus in data. We also apply our model to spiking responses recorded in retinal ganglion cells (RGCs) during stimulation with a movie and discuss the found structure.},
	language = {en},
	urldate = {2022-02-16},
	journal = {arXiv:2201.11108 [cs, q-bio, stat]},
	author = {Warner, Christopher and Ruda, Kiersten and Sommer, Friedrich T.},
	month = jan,
	year = {2022},
	note = {arXiv: 2201.11108},
	keywords = {Computer Science - Machine Learning, Quantitative Biology - Neurons and Cognition, Statistics - Machine Learning, ⛔ No INSPIRE recid found},
}

@techreport{sotomayor-gomez_spikeship_2020,
	type = {preprint},
	title = {{SpikeShip}: {A} method for fast, unsupervised discovery of high-dimensional neural spiking patterns},
	shorttitle = {{SpikeShip}},
	url = {http://biorxiv.org/lookup/doi/10.1101/2020.06.03.131573},
	abstract = {Neural coding and memory formation depend on temporal spiking sequences that span high-dimensional neural ensembles. The unsupervised discovery and characterization of these spiking sequences requires a suitable dissimilarity measure to compare any two spiking patterns. Here, we present a new measure of dissimilarity between multineuron spike sequences based on optimal transport theory, called SpikeShip. SpikeShip compares any two spiking patterns based on all the relative spike-timing relationships among neurons. Specifically, SpikeShip computes the optimal transport cost, i.e. the Earth Mover’s Distance, to make all the relative spike-timing relationships (across neurons) identical between two spiking patterns. It achieves this by computing the optimal transport of spikes across time, per neuron separately, and then decomposing this transport cost in a temporal rigid translation term and a vector of neuron-specific transport flows. We show that SpikeShip can be effectively computed for high-dimensional neuronal ensembles, has a low computational cost, and is explicitly based on the higher-order structure in the spiking patterns. We then applied SpikeShip to largescale Neuropixel recordings during spontaneous activity and visual encoding. Using SpikeShip, we show that high-dimensional spiking sequences reliably distinguish between different natural images and different behavioral states. These spiking sequences carried complementary information to conventional firing rate codes. SpikeShip opens new avenues for studying neural coding and memory consolidation by finding patterns in high-dimensional neural ensembles.},
	language = {en},
	urldate = {2022-01-13},
	institution = {Neuroscience},
	author = {Sotomayor-Gómez, Boris and Battaglia, Francesco P. and Vinck, Martin},
	month = jun,
	year = {2020},
	doi = {10.1101/2020.06.03.131573},
	keywords = {⛔ No INSPIRE recid found},
}

@article{pauli_reproducing_2018,
	title = {Reproducing {Polychronization}: {A} {Guide} to {Maximizing} the {Reproducibility} of {Spiking} {Network} {Models}},
	volume = {12},
	issn = {1662-5196},
	shorttitle = {Reproducing {Polychronization}},
	url = {https://www.frontiersin.org/article/10.3389/fninf.2018.00046},
	doi = {10/gd8zj5},
	abstract = {Any modeler who has attempted to reproduce a spiking neural network model from its description in a paper has discovered what a painful endeavor this is. Even when all parameters appear to have been specified, which is rare, typically the initial attempt to reproduce the network does not yield results that are recognizably akin to those in the original publication. Causes include inaccurately reported or hidden parameters (e.g., wrong unit or the existence of an initialization distribution), differences in implementation of model dynamics, and ambiguities in the text description of the network experiment. The very fact that adequate reproduction often cannot be achieved until a series of such causes have been tracked down and resolved is in itself disconcerting, as it reveals unreported model dependencies on specific implementation choices that either were not clear to the original authors, or that they chose not to disclose. In either case, such dependencies diminish the credibility of the model's claims about the behavior of the target system. To demonstrate these issues, we provide a worked example of reproducing a seminal study for which, unusually, source code was provided at time of publication. Despite this seemingly optimal starting position, reproducing the results was time consuming and frustrating. Further examination of the correctly reproduced model reveals that it is highly sensitive to implementation choices such as the realization of background noise, the integration timestep, and the thresholding parameter of the analysis algorithm. From this process, we derive a guideline of best practices that would substantially reduce the investment in reproducing neural network studies, whilst simultaneously increasing their scientific quality. We propose that this guideline can be used by authors and reviewers to assess and improve the reproducibility of future network models.},
	urldate = {2021-10-21},
	journal = {Frontiers in Neuroinformatics},
	author = {Pauli, Robin and Weidel, Philipp and Kunkel, Susanne and Morrison, Abigail},
	year = {2018},
	note = {00000},
	keywords = {⛔ No INSPIRE recid found},
	pages = {46},
}

@article{izhikevich_polychronous_2009,
	title = {Polychronous {Wavefront} {Computations}},
	volume = {19},
	issn = {0218-1274, 1793-6551},
	url = {https://www.izhikevich.org/publications/polychronous_wavefront_computations.htm},
	doi = {10/db98d7},
	abstract = {There is great interest in methods for computing that do not involve digital machines. Many computational paradigms were inspired by brain research, such as Boolean neuronal logic [McCulloch \& Pitts, 1943], the perceptron [Rosenblatt, 1958], attractor neural networks [Hopfield, 1982] and cellular neural nets [Chua \& Yang, 1988]. All these paradigms abstract biological circuits to artificial neural networks, i.e. interconnected units (neurons) that perform computations based on the connections between the units (synapses). Here we present a novel computational framework based on polychronous wavefront dynamics. It is entirely different from an artificial neural network paradigm, rather it is based on temporal and spatial patterns of activity in pulse-propagating media and their interaction with transponders, which create pulses in response to receiving appropriate inputs, e.g. two coincident input pulses. A pulse propagates as a circular wave from its source to other transponders. Computations result from interactions between transponders, and they are encoded by the exact physical locations of transponders and by precise timings of pulses. We illustrate temporal pattern recognition, reverberating memory, temporal signal analysis and basic logical operations using polychronous wavefront computations. This work reveals novel principles for designing nanoscale computational devices.},
	language = {en},
	number = {05},
	urldate = {2019-09-10},
	journal = {International Journal of Bifurcation and Chaos},
	author = {Izhikevich, Eugene M. and Hoppensteadt, Frank C.},
	month = may,
	year = {2009},
	note = {00000 
tex.ids= Izhikevich09a
publisher: World Scientific Publishing Co.},
	keywords = {polychronization, ⛔ No INSPIRE recid found},
	pages = {1733--1739},
}

@article{huning_synaptic_1998,
	title = {Synaptic {Delay} {Learning} in {Pulse}-{Coupled} {Neurons}},
	volume = {10},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/089976698300017665},
	doi = {10/cthfps},
	abstract = {We present rules for the unsupervised learning of coincidence between excitatory postsynaptic potentials (EPSPs) by the adjustment of post-synaptic delays between the transmitter binding and the opening of ion channels. Starting from a gradient descent scheme, we develop a robust and more biological threshold rule by which EPSPs from different synapses can be gradually pulled into coincidence. The synaptic delay changes are determined from the summed potential—at the site where the coincidence is to be established—and from postulated synaptic learning functions that accompany the individual EPSPs. According to our scheme, templates for the detection of spatiotemporal patterns of synaptic activation can be learned, which is demonstrated by computer simulation. Finally, we discuss possible relations to biological mechanisms.},
	number = {3},
	urldate = {2021-09-16},
	journal = {Neural Computation},
	author = {Hüning, Harald and Glünder, Helmut and Palm, Günther},
	month = apr,
	year = {1998},
	note = {00000 
tex.ids= Huning1998a},
	keywords = {⛔ No INSPIRE recid found},
	pages = {555--565},
}

@article{grossberger_unsupervised_2018,
	title = {Unsupervised clustering of temporal patterns in high-dimensional neuronal ensembles using a novel dissimilarity measure},
	volume = {14},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006283},
	doi = {10/gdvbsx},
	abstract = {Temporally ordered multi-neuron patterns likely encode information in the brain. We introduce an unsupervised method, SPOTDisClust (Spike Pattern Optimal Transport Dissimilarity Clustering), for their detection from high-dimensional neural ensembles. SPOTDisClust measures similarity between two ensemble spike patterns by determining the minimum transport cost of transforming their corresponding normalized cross-correlation matrices into each other (SPOTDis). Then, it performs density-based clustering based on the resulting inter-pattern dissimilarity matrix. SPOTDisClust does not require binning and can detect complex patterns (beyond sequential activation) even when high levels of out-of-pattern “noise” spiking are present. Our method handles efficiently the additional information from increasingly large neuronal ensembles and can detect a number of patterns that far exceeds the number of recorded neurons. In an application to neural ensemble data from macaque monkey V1 cortex, SPOTDisClust can identify different moving stimulus directions on the sole basis of temporal spiking patterns.},
	language = {en},
	number = {7},
	urldate = {2021-11-30},
	journal = {PLOS Computational Biology},
	author = {Grossberger, Lukas and Battaglia, Francesco P. and Vinck, Martin},
	year = {2018},
	note = {00000 
tex.ids= Grossberger18a
publisher: Public Library of Science},
	keywords = {⛔ No INSPIRE recid found},
	pages = {e1006283},
}

@article{ghosh_synchronization_2021,
	title = {Synchronization in time-varying networks},
	url = {http://arxiv.org/abs/2109.07618},
	abstract = {Over the past two decades, complex network theory provided the ideal framework for investigating the intimate relationships between the topological properties characterizing the wiring of connections among a system's unitary components and its emergent synchronized functioning. An increased number of setups from the real world found therefore a representation in term of graphs, while more and more sophisticated methods were developed with the aim of furnishing a realistic description of the connectivity patterns under study. In particular, a significant number of systems in physics, biology and social science features a time-varying nature of the interactions among their units. We here give a comprehensive review of the major results obtained by contemporary studies on the emergence of synchronization in time-varying networks. In particular, two paradigmatic frameworks will be described in details. The first encompasses those systems where the time dependence of the nodes' connections is due to adaptation, external forces, or any other process affecting each of the links of the network. The second framework, instead, corresponds to the case in which the structural evolution of the graph is due to the movement of the nodes, or agents, in physical spaces and to the fact that interactions may be ruled by space-dependent laws in a way that connections are continuously switched on and off in the course of the time. Finally, our report ends with a short discussion on promising directions and open problems for future studies.},
	urldate = {2021-09-21},
	journal = {arXiv:2109.07618 [physics]},
	author = {Ghosh, Dibakar and Frasca, Mattia and Rizzo, Alessandro and Majhi, Soumen and Rakshit, Sarbendu and Alfaro-Bittner, Karin and Boccaletti, Stefano},
	month = sep,
	year = {2021},
	note = {00000 
arXiv: 2109.07618},
	keywords = {⛔ No DOI found, ⛔ No INSPIRE recid found},
}

@article{foss_multistability_2000,
	title = {Multistability in {Recurrent} {Neural} {Loops} {Arising} {From} {Delay}},
	volume = {84},
	issn = {0022-3077, 1522-1598},
	url = {https://www.physiology.org/doi/10.1152/jn.2000.84.2.975},
	doi = {10/gmvbsh},
	abstract = {The dynamics of a recurrent inhibitory neural loop composed of a periodically spiking Aplysia motoneuron reciprocally connected to a computer are investigated as a function of the time delay, τ, for propagation around the loop. It is shown that for certain choices of τ, multiple qualitatively different neural spike trains co-exist. A mathematical model is constructed for the dynamics of this pulsed-coupled recurrent loop in which all parameters are readily measured experimentally: the phase resetting curve of the neuron for a given simulated postsynaptic current and τ. For choices of the parameters for which multiple spiking patterns co-exist in the experimental paradigm, the model exhibits multistability. Numerical simulations suggest that qualitatively similar results will occur if the motoneuron is replaced by several other types of neurons and that once τ becomes sufficiently long, multistability will be the dominant form of dynamical behavior. These observations suggest that great care must be taken in determining the etiology of qualitative changes in neural spiking patterns, particularly when propagation times around polysynaptic loops are long.},
	language = {en},
	number = {2},
	urldate = {2021-09-16},
	journal = {Journal of Neurophysiology},
	author = {Foss, Jennifer and Milton, John},
	month = aug,
	year = {2000},
	note = {00126 
tex.ids= Foss00a
publisher: American Physiological Society},
	keywords = {⛔ No INSPIRE recid found},
	pages = {975--985},
}

@article{eurich_dynamics_1999,
	title = {Dynamics of {Self}-{Organized} {Delay} {Adaptation}},
	volume = {82},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.82.1594},
	doi = {10/dj9c7q},
	abstract = {Adaptation of interaction delays is essential for the functioning of many natural and technical systems. We introduce a novel framework for studying the dynamics of delay adaptation in systems which optimize coincidence of inputs. For the important case of periodically modulated input we derive conditions for the existence and stability of solutions which constrain the set of mechanisms for reliable delay adaptation. Using numerical examples we show that our approach is applicable to more general than periodic input patterns such as Poissonian point processes with coordinated rate fluctuations.},
	number = {7},
	urldate = {2021-09-16},
	journal = {Physical Review Letters},
	author = {Eurich, Christian W. and Pawelzik, Klaus and Ernst, Udo and Cowan, Jack D. and Milton, John G.},
	month = feb,
	year = {1999},
	note = {00082 
Publisher: American Physical Society},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1594--1597},
}

@article{sun_learning_2016,
	title = {Learning polychronous neuronal groups using joint weight-delay spike-timing-dependent plasticity},
	volume = {28},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/NECO_a_00879},
	doi = {10.1162/NECO_a_00879},
	abstract = {Polychronous neuronal group (PNG), a type of cell assembly, is one of the putative mechanisms for neural information representation. According to the reader-centric definition, some readout neurons can become selective to the information represented by polychronous neuronal groups under ongoing activity. Here, in computational models, we show that the frequently activated polychronous neuronal groups can be learned by readout neurons with joint weight-delay spike-timing-dependent plasticity. The identity of neurons in the group and their expected spike timing at millisecond scale can be recovered from the incoming weights and delays of the readout neurons. The detection performance can be further improved by two layers of readout neurons. In this way, the detection of polychronous neuronal groups becomes an intrinsic part of the network, and the readout neurons become differentiated members in the group to indicate whether subsets of the group have been activated according to their spike timing. The readout spikes representing this information can be used to analyze how PNGs interact with each other or propagate to downstream networks for higher-level processing.},
	number = {10},
	journal = {Neural Computation},
	author = {Sun, Haoqi and Sourina, Olga and Huang, Guang-Bin},
	month = oct,
	year = {2016},
	note = {tex.eprint: https://direct.mit.edu/neco/article-pdf/28/10/2181/972099/neco{\textbackslash}\_a{\textbackslash}\_00879.pdf},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {2181--2212},
}

@article{izhikevich_polychronization_2006,
	title = {Polychronization: {Computation} with {Spikes}},
	volume = {18},
	issn = {0899-7667},
	shorttitle = {Polychronization},
	url = {https://doi.org/10.1162/089976606775093882},
	doi = {10/bgh4qv},
	abstract = {We present a minimal spiking network that can polychronize, that is, exhibit reproducible time-locked but not synchronous firing patterns with millisecond precision, as in synfire braids. The network consists of cortical spiking neurons with axonal conduction delays and spike-timing-dependent plasticity (STDP); a ready-to-use MATLAB code is included. It exhibits sleeplike oscillations, gamma (40 Hz) rhythms, conversion of firing rates to spike timings, and other interesting regimes. Due to the interplay between the delays and STDP, the spiking neurons spontaneously self-organize into groups and generate patterns of stereotypical polychronous activity. To our surprise, the number of coexisting polychronous groups far exceeds the number of neurons in the network, resulting in an unprecedented memory capacity of the system. We speculate on the significance of polychrony to the theory of neuronal group selection (TNGS, neural Darwinism), cognitive neural computations, binding and gamma rhythm, mechanisms of attention, and consciousness as “attention to memories.”},
	number = {2},
	urldate = {2018-09-24},
	journal = {Neural Computation},
	author = {Izhikevich, Eugene M.},
	month = feb,
	year = {2006},
	note = {00000},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {245--282},
}

@article{bruno_cortex_2006,
	title = {Cortex {Is} {Driven} by {Weak} but {Synchronously} {Active} {Thalamocortical} {Synapses}},
	volume = {312},
	url = {https://doi.org/c5575v},
	doi = {10.1126/science.1124593},
	abstract = {{\textless}jats:p{\textgreater}Sensory stimuli reach the brain via the thalamocortical projection, a group of axons thought to be among the most powerful in the neocortex. Surprisingly, these axons account for only ∼15\% of synapses onto cortical neurons. The thalamocortical pathway might thus achieve its effectiveness via high-efficacy thalamocortical synapses or via amplification within cortical layer 4. In rat somatosensory cortex, we measured in vivo the excitatory postsynaptic potential evoked by a single synaptic connection and found that thalamocortical synapses have low efficacy. Convergent inputs, however, are both numerous and synchronous, and intracortical amplification is not required. Our results suggest a mechanism of cortical activation by which thalamic input alone can drive cortex.{\textless}/jats:p{\textgreater}},
	language = {en},
	number = {5780},
	journal = {Science},
	author = {Bruno, Randy M. and Sakmann, Bert},
	year = {2006},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1126/science.1124593},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1622--1627},
}

@article{markram_regulation_1997,
	title = {Regulation of {Synaptic} {Efficacy} by {Coincidence} of {Postsynaptic} {APs} and {EPSPs}},
	volume = {275},
	url = {https://doi.org/ftvvd8},
	doi = {10.1126/science.275.5297.213},
	abstract = {{\textless}jats:p{\textgreater}Activity-driven modifications in synaptic connections between neurons in the neocortex may occur during development and learning. In dual whole-cell voltage recordings from pyramidal neurons, the coincidence of postsynaptic action potentials (APs) and unitary excitatory postsynaptic potentials (EPSPs) was found to induce changes in EPSPs. Their average amplitudes were differentially up- or down-regulated, depending on the precise timing of postsynaptic APs relative to EPSPs. These observations suggest that APs propagating back into dendrites serve to modify single active synaptic connections, depending on the pattern of electrical activity in the pre- and postsynaptic neurons.{\textless}/jats:p{\textgreater}},
	language = {en},
	number = {5297},
	journal = {Science},
	author = {Markram, Henry and Lübke, Joachim and Frotscher, Michael and Sakmann, Bert},
	month = jan,
	year = {1997},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1126/science.275.5297.213},
	keywords = {⛔ No INSPIRE recid found},
	pages = {213--215},
}

@article{meister_concerted_1995,
	title = {Concerted {Signaling} by {Retinal} {Ganglion} {Cells}},
	volume = {270},
	url = {https://doi.org/dszfrn},
	doi = {10.1126/science.270.5239.1207},
	language = {en},
	number = {5239},
	journal = {Science},
	author = {Meister, Markus and Lagnado, Leon and Baylor, Denis A.},
	month = nov,
	year = {1995},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1126/science.270.5239.1207},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1207--1210},
}

@article{branco_dendritic_2010,
	title = {Dendritic {Discrimination} of {Temporal} {Input} {Sequences} in {Cortical} {Neurons}},
	volume = {329},
	url = {https://doi.org/dqx4n4},
	doi = {10.1126/science.1189664},
	abstract = {{\textless}jats:title{\textgreater}Discriminating Dendrites{\textless}/jats:title{\textgreater}
          {\textless}jats:p{\textgreater}
            Can dendrites read out spatiotemporal input sequences? Combining two-photon glutamate uncaging and two-photon calcium imaging, electrophysiology, and computational modeling,
            {\textless}jats:bold{\textgreater}
              Branco
              {\textless}jats:italic{\textgreater}et al.{\textless}/jats:italic{\textgreater}
            {\textless}/jats:bold{\textgreater}
            (p.
            {\textless}jats:related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" page="1671" related-article-type="in-this-issue" vol="329" xlink:href="10.1126/science.1189664"{\textgreater}1671{\textless}/jats:related-article{\textgreater}
            , published online 12 August; see the Perspective by
            {\textless}jats:bold{\textgreater}
              {\textless}jats:related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" issue="5999" page="1611" related-article-type="in-this-issue" vol="329" xlink:href="10.1126/science.1196743"{\textgreater}Destexhe{\textless}/jats:related-article{\textgreater}
            {\textless}/jats:bold{\textgreater}
            ) discovered that single dendrites were indeed sensitive to both the direction and velocity of synaptic inputs. This direction- and velocity-sensitivity was measurable with only a few inputs and should thus be engaged frequently during normal brain function.
          {\textless}/jats:p{\textgreater}},
	language = {en},
	number = {5999},
	journal = {Science},
	author = {Branco, Tiago and Clark, Beverley A. and Häusser, Michael},
	month = sep,
	year = {2010},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1126/science.1189664},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1671--1675},
}

@article{stringer_spontaneous_2019,
	title = {Spontaneous behaviors drive multidimensional, brainwide activity},
	volume = {364},
	url = {https://doi.org/gfz6mh},
	doi = {10.1126/science.aav7893},
	abstract = {{\textless}jats:title{\textgreater}Neuron activity across the brain{\textless}/jats:title{\textgreater}
          {\textless}jats:p{\textgreater}
            How is it that groups of neurons dispersed through the brain interact to generate complex behaviors? Three papers in this issue present brain-scale studies of neuronal activity and dynamics (see the Perspective by Huk and Hart). Allen
            {\textless}jats:italic{\textgreater}et al.{\textless}/jats:italic{\textgreater}
            found that in thirsty mice, there is widespread neural activity related to stimuli that elicit licking and drinking. Individual neurons encoded task-specific responses, but every brain area contained neurons with different types of response. Optogenetic stimulation of thirst-sensing neurons in one area of the brain reinstated drinking and neuronal activity across the brain that previously signaled thirst. Gründemann
            {\textless}jats:italic{\textgreater}et al.{\textless}/jats:italic{\textgreater}
            investigated the activity of mouse basal amygdala neurons in relation to behavior during different tasks. Two ensembles of neurons showed orthogonal activity during exploratory and nonexploratory behaviors, possibly reflecting different levels of anxiety experienced in these areas. Stringer
            {\textless}jats:italic{\textgreater}et al.{\textless}/jats:italic{\textgreater}
            analyzed spontaneous neuronal firing, finding that neurons in the primary visual cortex encoded both visual information and motor activity related to facial movements. The variability of neuronal responses to visual stimuli in the primary visual area is mainly related to arousal and reflects the encoding of latent behavioral states.
          {\textless}/jats:p{\textgreater}
          {\textless}jats:p{\textgreater}
            {\textless}jats:italic{\textgreater}Science{\textless}/jats:italic{\textgreater}
            , this issue p.
            {\textless}jats:related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" issue="6437" page="eaav3932" related-article-type="in-this-issue" vol="364" xlink:href="10.1126/science.aav3932"{\textgreater}eaav3932{\textless}/jats:related-article{\textgreater}
            , p.
            {\textless}jats:related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" issue="6437" page="eaav8736" related-article-type="in-this-issue" vol="364" xlink:href="10.1126/science.aav8736"{\textgreater}eaav8736{\textless}/jats:related-article{\textgreater}
            , p.
            {\textless}jats:related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" issue="6437" page="eaav7893" related-article-type="in-this-issue" vol="364" xlink:href="10.1126/science.aav7893"{\textgreater}eaav7893{\textless}/jats:related-article{\textgreater}
            ; see also p.
            {\textless}jats:related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" issue="6437" page="236" related-article-type="in-this-issue" vol="364" xlink:href="10.1126/science.aax1512"{\textgreater}236{\textless}/jats:related-article{\textgreater}
          {\textless}/jats:p{\textgreater}},
	language = {en},
	number = {6437},
	journal = {Science},
	author = {Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas and Reddy, Charu Bai and Carandini, Matteo and Harris, Kenneth D.},
	year = {2019},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1126/science.aav7893},
	keywords = {⛔ No INSPIRE recid found},
}

@article{mainen_reliability_1995,
	title = {Reliability of {Spike} {Timing} in {Neocortical} {Neurons}},
	volume = {268},
	url = {https://doi.org/b2mms6},
	doi = {10.1126/science.7770778},
	language = {en},
	number = {5216},
	journal = {Science},
	author = {Mainen, Zachary F. and Sejnowski, Terrence J.},
	year = {1995},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1126/science.7770778},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1503--1506},
}

@article{singer_visual_1995,
	title = {Visual {Feature} {Integration} and the {Temporal} {Correlation} {Hypothesis}},
	volume = {18},
	url = {https://doi.org/cgx8jp},
	doi = {10.1146/annurev.ne.18.030195.003011},
	language = {en},
	number = {1},
	journal = {Annual Review of Neuroscience},
	author = {Singer, W and Gray, C M},
	month = mar,
	year = {1995},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1146/annurev.ne.18.030195.003011},
	keywords = {⛔ No INSPIRE recid found},
	pages = {555--586},
}

@article{aviel_embedding_2003,
	title = {On {Embedding} {Synfire} {Chains} in a {Balanced} {Network}},
	volume = {15},
	url = {https://doi.org/fgj3wf},
	doi = {10.1162/089976603321780290},
	abstract = {{\textless}jats:p{\textgreater} We investigate the formation of synfire waves in a balanced network of integrate-and-fire neurons. The synaptic connectivity of this network embodies synfire chains within a sparse random connectivity. This network can exhibit global oscillations but can also operate in an asynchronous activity mode. We analyze the correlations of two neurons in a pool as convenient indicators for the state of the network. We find, using different models, that these indicators depend on a scaling variable. {\textless}/jats:p{\textgreater}{\textless}jats:p{\textgreater} Beyond a critical point, strong correlations and large network oscillations are obtained. We looked for the conditions under which a synfire wave could be propagated on top of an otherwise asynchronous state of the network. This condition was found to be highly restrictive, requiring a large number of neurons for its implementation in our network. The results are based on analytic derivations and simulations. {\textless}/jats:p{\textgreater}},
	language = {en},
	number = {6},
	journal = {Neural Computation},
	author = {Aviel, Y. and Mehring, C. and Abeles, M. and Horn, D.},
	year = {2003},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1162/089976603321780290},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1321--1340},
}

@article{caporale_spike_2008,
	title = {Spike {Timing}–{Dependent} {Plasticity}: {A} {Hebbian} {Learning} {Rule}},
	volume = {31},
	url = {https://doi.org/fqxrgj},
	doi = {10.1146/annurev.neuro.31.060407.125639},
	abstract = {{\textless}jats:p{\textgreater} Spike timing–dependent plasticity (STDP) as a Hebbian synaptic learning rule has been demonstrated in various neural circuits over a wide spectrum of species, from insects to humans. The dependence of synaptic modification on the order of pre- and postsynaptic spiking within a critical window of tens of milliseconds has profound functional implications. Over the past decade, significant progress has been made in understanding the cellular mechanisms of STDP at both excitatory and inhibitory synapses and of the associated changes in neuronal excitability and synaptic integration. Beyond the basic asymmetric window, recent studies have also revealed several layers of complexity in STDP, including its dependence on dendritic location, the nonlinear integration of synaptic modification induced by complex spike trains, and the modulation of STDP by inhibitory and neuromodulatory inputs. Finally, the functional consequences of STDP have been examined directly in an increasing number of neural circuits in vivo. {\textless}/jats:p{\textgreater}},
	language = {en},
	number = {1},
	journal = {Annual Review of Neuroscience},
	author = {Caporale, Natalia and Dan, Yang},
	year = {2008},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1146/annurev.neuro.31.060407.125639},
	keywords = {⛔ No INSPIRE recid found},
	pages = {25--46},
}

@article{brette_computing_2012,
	title = {Computing with {Neural} {Synchrony}},
	volume = {8},
	url = {https://doi.org/f32tvz},
	doi = {10.1371/journal.pcbi.1002561},
	language = {en},
	number = {6},
	journal = {PLoS Computational Biology},
	author = {Brette, Romain},
	editor = {Sporns, Olaf},
	year = {2012},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1371/journal.pcbi.1002561},
	keywords = {⛔ No INSPIRE recid found},
	pages = {e1002561},
}

@article{grun_unitary_2002,
	title = {Unitary {Events} in {Multiple} {Single}-{Neuron} {Spiking} {Activity}: {II}. {Nonstationary} {Data}},
	volume = {14},
	url = {https://doi.org/ffvbkp},
	doi = {10.1162/089976602753284464},
	abstract = {{\textless}jats:p{\textgreater} In order to detect members of a functional group (cell assembly) in simultaneously recorded neuronal spiking activity, we adopted the widely used operational definition that membership in a common assembly is expressed in near-simultaneous spike activity. Unitary event analysis, a statistical method to detect the significant occurrence of coincident spiking activity in stationary data, was recently developed (see the companion article in this issue). The technique for the detection of unitary events is based on the assumption that the underlying processes are stationary in time. This requirement, however, is usually not fulfilled in neuronal data. Here we describe a method that properly normalizes for changes of rate: the unitary events by moving window analysis (UEMWA). Analysis for unitary events is performed separately in overlapping time segments by sliding a window of constant width along the data. In each window, stationarity is assumed. Performance and sensitivity are demonstrated by use of simulated spike trains of independently firing neurons, into which coincident events are inserted. If cortical neurons organize dynamically into functional groups, the occurrence of near-simultaneous spike activity should be time varying and related to behavior and stimuli. UEMWA also accounts for these potentially interesting nonstationarities and allows locating them in time. The potential of the new method is illustrated by results from multiple single-unit recordings from frontal and motor cortical areas in awake, behaving monkey. {\textless}/jats:p{\textgreater}},
	language = {en},
	number = {1},
	journal = {Neural Computation},
	author = {Grün, Sonja and Diesmann, Markus and Aertsen, Ad},
	month = jan,
	year = {2002},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1162/089976602753284464},
	keywords = {⛔ No INSPIRE recid found},
	pages = {81--119},
}

@article{grun_unitary_2002-1,
	title = {Unitary {Events} in {Multiple} {Single}-{Neuron} {Spiking} {Activity}: {I}. {Detection} and {Significance}},
	volume = {14},
	url = {https://doi.org/c63kkn},
	doi = {10.1162/089976602753284455},
	abstract = {{\textless}jats:p{\textgreater} It has been proposed that cortical neurons organize dynamically into functional groups (cell assemblies) by the temporal structure of their joint spiking activity. Here, we describe a novel method to detect conspicuous patterns of coincident joint spike activity among simultaneously recorded single neurons. The statistical significance of these unitary events of coincident joint spike activity is evaluated by the joint-surprise. The method is tested and calibrated on the basis of simulated, stationary spike trains of independently firing neurons, into which coincident joint spike events were inserted under controlled conditions. The sensitivity and specificity of the method are investigated for their dependence on physiological parameters (firing rate, coincidence precision, coincidence pattern complexity) and temporal resolution of the analysis. In the companion article in this issue, we describe an extension of the method, designed to deal with nonstationary firing rates. {\textless}/jats:p{\textgreater}},
	language = {en},
	number = {1},
	journal = {Neural Computation},
	author = {Grün, Sonja and Diesmann, Markus and Aertsen, Ad},
	month = jan,
	year = {2002},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1162/089976602753284455},
	keywords = {⛔ No INSPIRE recid found},
	pages = {43--80},
}

@article{keysers_speed_2001,
	title = {The {Speed} of {Sight}},
	volume = {13},
	url = {https://doi.org/cfdjtg},
	doi = {10.1162/089892901564199},
	abstract = {{\textless}jats:title{\textgreater}Abstract{\textless}/jats:title{\textgreater}
               {\textless}jats:p{\textgreater}Macaque monkeys were presented with continuous rapid serial visual presentation (RSVP) sequences of unrelated naturalistic images at rates of 14-222 msec/image, while neurons that responded selectively to complex patterns (e.g., faces) were recorded in temporal cortex. Stimulus selectivity was preserved for 65\% of these neurons even at surprisingly fast presentation rates (14 msec/image or 72 images/sec). Five human subjects were asked to detect or remember images under equivalent conditions. Their performance in both tasks was above chance at all rates (14-111 msec/image). The performance of single neurons was comparable to that of humans and responded in a similar way to changes in presentation rate. The implications for the role of temporal cortex cells in perception are discussed.{\textless}/jats:p{\textgreater}},
	language = {en},
	number = {1},
	journal = {Journal of Cognitive Neuroscience},
	author = {Keysers, C. and Xiao, D.-K. and Földiák, P. and Perrett, D. I.},
	month = jan,
	year = {2001},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1162/089892901564199},
	keywords = {⛔ No INSPIRE recid found},
	pages = {90--101},
}

@article{schrader_detecting_2008,
	title = {Detecting {Synfire} {Chain} {Activity} {Using} {Massively} {Parallel} {Spike} {Train} {Recording}},
	volume = {100},
	url = {https://doi.org/cvb22p},
	doi = {10.1152/jn.01245.2007},
	abstract = {{\textless}jats:p{\textgreater} The synfire chain model has been proposed as the substrate that underlies computational processes in the brain and has received extensive theoretical study. In this model cortical tissue is composed of a superposition of feedforward subnetworks (chains) each capable of transmitting packets of synchronized spikes with high reliability. Computations are then carried out by interactions of these chains. Experimental evidence for synfire chains has so far been limited to inference from detection of a few repeating spatiotemporal neuronal firing patterns in multiple single-unit recordings. Demonstration that such patterns actually come from synfire activity would require finding a meta organization among many detected patterns, as yet an untried approach. In contrast we present here a new method that directly visualizes the repetitive occurrence of synfire activity even in very large data sets of multiple single-unit recordings. We achieve reliability and sensitivity by appropriately averaging over neuron space (identities) and time. We test the method with data from a large-scale balanced recurrent network simulation containing 50 randomly activated synfire chains. The sensitivity is high enough to detect synfire chain activity in simultaneous single-unit recordings of 100 to 200 neurons from such data, enabling application to experimental data in the near future. {\textless}/jats:p{\textgreater}},
	language = {en},
	number = {4},
	journal = {Journal of Neurophysiology},
	author = {Schrader, Sven and Grün, Sonja and Diesmann, Markus and Gerstein, George L.},
	month = oct,
	year = {2008},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1152/jn.01245.2007},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2165--2176},
}

@article{zhao_understanding_2011,
	title = {Understanding {Auditory} {Spectro}-{Temporal} {Receptive} {Fields} and {Their} {Changes} with {Input} {Statistics} by {Efficient} {Coding} {Principles}},
	volume = {7},
	url = {https://doi.org/bjc6c9},
	doi = {10.1371/journal.pcbi.1002123},
	language = {en},
	number = {8},
	journal = {PLoS Computational Biology},
	author = {Zhao, Lingyun and Zhaoping, Li},
	editor = {Graham, Lyle J.},
	year = {2011},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1371/journal.pcbi.1002123},
	keywords = {⛔ No INSPIRE recid found},
	pages = {e1002123},
}

@article{torre_asset_2016,
	title = {{ASSET}: {Analysis} of {Sequences} of {Synchronous} {Events} in {Massively} {Parallel} {Spike} {Trains}},
	volume = {12},
	url = {https://doi.org/gnpx4q},
	doi = {10.1371/journal.pcbi.1004939},
	language = {en},
	number = {7},
	journal = {PLOS Computational Biology},
	author = {Torre, Emiliano and Canova, Carlos and Denker, Michael and Gerstein, George and Helias, Moritz and Grün, Sonja},
	editor = {Sporns, Olaf},
	year = {2016},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1371/journal.pcbi.1004939},
	keywords = {⛔ No INSPIRE recid found},
	pages = {e1004939},
}

@article{kerr_delay_2013,
	title = {Delay {Selection} by {Spike}-{Timing}-{Dependent} {Plasticity} in {Recurrent} {Networks} of {Spiking} {Neurons} {Receiving} {Oscillatory} {Inputs}},
	volume = {9},
	url = {https://doi.org/f4rm5j},
	doi = {10.1371/journal.pcbi.1002897},
	language = {en},
	number = {2},
	journal = {PLoS Computational Biology},
	author = {Kerr, Robert R. and Burkitt, Anthony N. and Thomas, Doreen A. and Gilson, Matthieu and Grayden, David B.},
	editor = {Morrison, Abigail},
	year = {2013},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1371/journal.pcbi.1002897},
	keywords = {⛔ No INSPIRE recid found},
	pages = {e1002897},
}

@article{burkitt_predictive_2021,
	title = {Predictive {Visual} {Motion} {Extrapolation} {Emerges} {Spontaneously} and without {Supervision} at {Each} {Layer} of a {Hierarchical} {Neural} {Network} with {Spike}-{Timing}-{Dependent} {Plasticity}},
	volume = {41},
	url = {https://doi.org/gjtwzk},
	doi = {10.1523/jneurosci.2017-20.2021},
	language = {en},
	number = {20},
	journal = {The Journal of Neuroscience},
	author = {Burkitt, Anthony N. and Hogendoorn, Hinze},
	year = {2021},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1523/jneurosci.2017-20.2021},
	keywords = {⛔ No INSPIRE recid found},
	pages = {4428--4438},
}

@article{kilavik_long-term_2009,
	title = {Long-{Term} {Modifications} in {Motor} {Cortical} {Dynamics} {Induced} by {Intensive} {Practice}},
	volume = {29},
	url = {https://doi.org/bf84ps},
	doi = {10.1523/jneurosci.1554-09.2009},
	language = {en},
	number = {40},
	journal = {Journal of Neuroscience},
	author = {Kilavik, B. E. and Roux, S. and Ponce-Alvarez, A. and Confais, J. and Grun, S. and Riehle, A.},
	month = oct,
	year = {2009},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1523/jneurosci.1554-09.2009},
	keywords = {⛔ No INSPIRE recid found},
	pages = {12653--12663},
}

@article{softky_highly_1993,
	title = {The highly irregular firing of cortical cells is inconsistent with temporal integration of random {EPSPs}},
	volume = {13},
	url = {https://doi.org/ggzph6},
	doi = {10.1523/jneurosci.13-01-00334.1993},
	language = {en},
	number = {1},
	journal = {The Journal of Neuroscience},
	author = {Softky, WR and Koch, C},
	month = jan,
	year = {1993},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1523/jneurosci.13-01-00334.1993},
	keywords = {⛔ No INSPIRE recid found},
	pages = {334--350},
}

@article{stella_comparing_2022,
	title = {Comparing {Surrogates} to {Evaluate} {Precisely} {Timed} {Higher}-{Order} {Spike} {Correlations}},
	volume = {9},
	url = {https://doi.org/gqjvht},
	doi = {10.1523/eneuro.0505-21.2022},
	language = {en},
	number = {3},
	journal = {eneuro},
	author = {Stella, Alessandra and Bouss, Peter and Palm, Günther and Grün, Sonja},
	year = {2022},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1523/eneuro.0505-21.2022},
	keywords = {⛔ No INSPIRE recid found},
	pages = {ENEURO.0505--21.2022},
}

@article{gilson_stdp_2010,
	title = {{STDP} in recurrent neuronal networks},
	volume = {4},
	url = {https://doi.org/c8ck59},
	doi = {10.3389/fncom.2010.00023},
	journal = {Frontiers in Computational Neuroscience},
	author = {Gilson, Matthieu},
	year = {2010},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.3389/fncom.2010.00023},
	keywords = {⛔ No INSPIRE recid found},
}

@article{torre_synchronous_2016,
	title = {Synchronous {Spike} {Patterns} in {Macaque} {Motor} {Cortex} during an {Instructed}-{Delay} {Reach}-to-{Grasp} {Task}},
	volume = {36},
	url = {https://doi.org/f82b6j},
	doi = {10.1523/jneurosci.4375-15.2016},
	language = {en},
	number = {32},
	journal = {Journal of Neuroscience},
	author = {Torre, E. and Quaglio, P. and Denker, M. and Brochier, T. and Riehle, A. and Grun, S.},
	year = {2016},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1523/jneurosci.4375-15.2016},
	keywords = {⛔ No INSPIRE recid found},
	pages = {8329--8340},
}

@article{pachitariu_robustness_2018,
	title = {Robustness of {Spike} {Deconvolution} for {Neuronal} {Calcium} {Imaging}},
	volume = {38},
	url = {https://doi.org/gd9mcx},
	doi = {10.1523/jneurosci.3339-17.2018},
	language = {en},
	number = {37},
	journal = {The Journal of Neuroscience},
	author = {Pachitariu, Marius and Stringer, Carsen and Harris, Kenneth D.},
	year = {2018},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1523/jneurosci.3339-17.2018},
	keywords = {⛔ No INSPIRE recid found},
	pages = {7976--7985},
}

@article{kremkow_push-pull_2016,
	title = {Push-{Pull} {Receptive} {Field} {Organization} and {Synaptic} {Depression}: {Mechanisms} for {Reliably} {Encoding} {Naturalistic} {Stimuli} in {V1}},
	volume = {10},
	url = {https://doi.org/ggkdkh},
	doi = {10.3389/fncir.2016.00037},
	journal = {Frontiers in Neural Circuits},
	author = {Kremkow, Jens and Perrinet, Laurent U. and Monier, Cyril and Alonso, Jose-Manuel and Aertsen, Ad and Frégnac, Yves and Masson, Guillaume S.},
	year = {2016},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.3389/fncir.2016.00037},
	keywords = {⛔ No INSPIRE recid found},
}

@article{di_mauro_alfio_sne_2022,
	title = {{SNE}: an {Energy}-{Proportional} {Digital} {Accelerator} for {Sparse} {Event}-{Based} {Convolutions}},
	url = {https://doi.org/gp3m5v},
	doi = {10.3929/ethz-b-000543342},
	abstract = {Event-based sensors are drawing increasing attention due to their high temporal resolution, low power consumption, and low bandwidth. To efficiently extract semantically meaningful information from sparse data streams produced by such sensors, we present a 4.5TOP/s/W digital accelerator capable of performing 4-bits-quantized event-based convolutional neural networks (eCNN). Compared to standard convolutional engines, our accelerator performs a number of operations proportional to the number of events contained into the input data stream, ultimately achieving a high energy-to-information processing proportionality. On the IBM-DVS-Gesture dataset, we report 80uJ/inf to 261uJ/inf, respectively, when the input activity is 1.2\% and 4.9\%. Our accelerator consumes 0.221pJ/SOP, to the best of our knowledge it is the lowest energy/OP reported on a digital neuromorphic engine.},
	language = {en},
	journal = {ETH Zurich},
	author = {{Di Mauro, Alfio} and {Prasad, Arpan Suravi} and {Huang, Zhikai} and {Spallanzani, Matteo} and {Conti, Francesco} and {Benini, Luca}},
	year = {2022},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.3929/ethz-b-000543342},
	keywords = {⛔ No INSPIRE recid found},
}

@article{davison_pynn_2008,
	title = {{PyNN}: a common interface for neuronal network simulators},
	volume = {2},
	url = {https://doi.org/fh8h6j},
	doi = {10.3389/neuro.11.011.2008},
	journal = {Frontiers in Neuroinformatics},
	author = {Davison, Andrew P},
	year = {2008},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.3389/neuro.11.011.2008},
	keywords = {⛔ No INSPIRE recid found},
}

@article{pfeil_six_2013,
	title = {Six {Networks} on a {Universal} {Neuromorphic} {Computing} {Substrate}},
	volume = {7},
	url = {https://doi.org/gh4jg3},
	doi = {10.3389/fnins.2013.00011},
	journal = {Frontiers in Neuroscience},
	author = {Pfeil, Thomas and Grübl, Andreas and Jeltsch, Sebastian and Müller, Eric and Müller, Paul and Petrovici, Mihai A. and Schmuker, Michael and Brüderle, Daniel and Schemmel, Johannes and Meier, Karlheinz},
	year = {2013},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.3389/fnins.2013.00011},
	keywords = {⛔ No INSPIRE recid found},
}

@article{torre_statistical_2013,
	title = {Statistical evaluation of synchronous spike patterns extracted by frequent item set mining},
	volume = {7},
	url = {https://doi.org/gpshgq},
	doi = {10.3389/fncom.2013.00132},
	journal = {Frontiers in Computational Neuroscience},
	author = {Torre, Emiliano and Picado-Muiño, David and Denker, Michael and Borgelt, Christian and Grün, Sonja},
	year = {2013},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.3389/fncom.2013.00132},
	keywords = {⛔ No INSPIRE recid found},
}

@article{russo_cell_2017,
	title = {Cell assemblies at multiple time scales with arbitrary lag constellations},
	volume = {6},
	url = {https://doi.org/f9kxd8},
	doi = {10.7554/elife.19428},
	abstract = {{\textless}jats:p{\textgreater}Hebb's idea of a cell assembly as the fundamental unit of neural information processing has dominated neuroscience like no other theoretical concept within the past 60 years. A range of different physiological phenomena, from precisely synchronized spiking to broadly simultaneous rate increases, has been subsumed under this term. Yet progress in this area is hampered by the lack of statistical tools that would enable to extract assemblies with arbitrary constellations of time lags, and at multiple temporal scales, partly due to the severe computational burden. Here we present such a unifying methodological and conceptual framework which detects assembly structure at many different time scales, levels of precision, and with arbitrary internal organization. Applying this methodology to multiple single unit recordings from various cortical areas, we find that there is no universal cortical coding scheme, but that assembly structure and precision significantly depends on the brain area recorded and ongoing task demands.{\textless}/jats:p{\textgreater}},
	language = {en},
	journal = {eLife},
	author = {Russo, Eleonora and Durstewitz, Daniel},
	month = jan,
	year = {2017},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.7554/elife.19428},
	keywords = {⛔ No INSPIRE recid found},
}

@article{luczak_packet-based_2015,
	title = {Packet-based communication in the cortex.},
	volume = {16},
	issn = {1471-0048},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/26507295},
	doi = {10.1038/nrn4026},
	abstract = {Cortical circuits work through the generation of coordinated, large-scale activity patterns. In sensory systems, the onset of a discrete stimulus usually evokes a temporally organized packet of population activity lasting ∼50-200 ms. The structure of these packets is partially stereotypical, and variation in the exact timing and number of spikes within a packet conveys information about the identity of the stimulus. Similar packets also occur during ongoing stimuli and spontaneously. We suggest that such packets constitute the basic building blocks of cortical coding.},
	number = {12},
	journal = {Nature reviews. Neuroscience},
	author = {Luczak, Artur and McNaughton, Bruce L and Harris, Kenneth D},
	month = oct,
	year = {2015},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: pubmed:26507295},
	keywords = {⛔ No INSPIRE recid found},
	pages = {745--55},
}

@article{suthers_motor_2002,
	title = {Motor control of birdsong.},
	volume = {12},
	issn = {0959-4388},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/12490259},
	doi = {10.1016/s0959-4388(02)00386-0},
	abstract = {One of the challenges when considering the motor control of birdsong is to understand how such a wide variety of temporally and spectrally diverse vocalizations are learned and produced. A better understanding of central neural processing, together with direct endoscopic observations and physiological studies of peripheral motor function during singing, has resulted in the formation of new theoretical models of song production. Recent work suggests that it may be more profitable to focus on the temporal relationship between control parameters than to attempt to directly correlate neural processing with details of the acoustic output.},
	number = {6},
	journal = {Current opinion in neurobiology},
	author = {Suthers, Roderick A and Margoliash, Daniel},
	year = {2002},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: pubmed:12490259},
	keywords = {⛔ No INSPIRE recid found},
	pages = {684--90},
}

@article{yu_temporal_1996,
	title = {Temporal hierarchical control of singing in birds.},
	volume = {273},
	issn = {0036-8075},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/8791594},
	doi = {10.1126/science.273.5283.1871},
	abstract = {Songs of birds comprise hierarchical sets of vocal gestures. In zebra finches, songs include notes and syllables (groups of notes) delivered in fixed sequences. During singing, premotor neurons in the forebrain nucleus HVc exhibited reliable changes in activity rates whose patterns were uniquely associated with syllable identity. Neurons in the forebrain nucleus robustus archistriatalis, which receives input from the HVc, exhibited precisely timed and structured bursts of activity that were uniquely associated with note identity. Hence, units of vocal behavior are represented hierarchically in the avian forebrain. The representation of temporal sequences at each level of the hierarchy may be established by means of a decoding process involving interactions of higher level input with intrinsic local circuitry. Behavior is apparently represented by precise temporal patterning of spike trains at lower levels of the hierarchy.},
	number = {5283},
	journal = {Science (New York, N.Y.)},
	author = {Yu, A C and Margoliash, D},
	month = sep,
	year = {1996},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: pubmed:8791594},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1871--5},
}

@book{abeles_corticonics_1991,
	address = {Cambridge ; New York},
	title = {Corticonics: neural circuits of the cerebral cortex},
	isbn = {978-0-521-37476-7},
	shorttitle = {Corticonics},
	publisher = {Cambridge University Press},
	author = {Abeles, Moshe},
	year = {1991},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: isbn:9780521376174},
	keywords = {⛔ No INSPIRE recid found},
}

@book{deweese_binary_2003,
	title = {Binary coding in auditory cortex},
	url = {http://papers.nips.cc/paper/2342-binary-coding-in-auditory-cortex},
	abstract = {Cortical neurons have been reported to use both rate and temporal codes. Here we describe a novel mode in which each neuron generates exactly 0 or 1 action potentials, but not more, in response to a stimulus. We used cell-attached recording, which ensured single-unit isolation, to record responses in rat auditory cortex to brief tone pips. Surprisingly, the majority of neurons exhibited binary behavior with few multi-spike responses; several dramatic examples consisted of exactly one spike on 100\% of trials, with no trial-to-trial variability in spike count. Many neurons were tuned to stimulus frequency. Since individual trials yielded at most one spike for most neurons, the information about stimulus frequency was encoded in the population, and would not have been accessible to later stages of processing that only had access to the activity of a single unit. These binary units allow a more efficient population code than is possible with conventional rate coding units, and are consistent with a model of cortical processing in which synchronous packets of spikes propagate stably from one neuronal population to the next.},
	urldate = {2022-10-04},
	publisher = {Neural Information Processing Systems Foundation},
	author = {DeWeese, M. R. and Zador, A. M.},
	year = {2003},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: url:https://repository.cshl.edu/id/eprint/30941},
	keywords = {⛔ No INSPIRE recid found},
}

@article{wild_descending_1993,
	title = {Descending projections of the songbird nucleus robustus archistriatalis.},
	volume = {338},
	issn = {0021-9967},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/8308169},
	doi = {10.1002/cne.903380207},
	abstract = {The descending, efferent projections of nucleus robustus archistriatalis were investigated in male zebra finches and greenfinches with injections of either biotinylated dextran amine or cholera toxin B-chain conjugated to horseradish peroxidase. The results show that in addition to the well-known projections to the tracheosyringeal motor nucleus and the dorsomedial nucleus of the intercollicular complex, there are other projections of comparable density to the ipsilateral nucleus ambiguus and nucleus retroambigualis. Within nucleus ambiguus, robustus axons terminate in close proximity to laryngeal motoneurons which were retrogradely labelled in the same bird by injections of cholera B-chain into the laryngeal muscles; and within nucleus retroambigualis robustus axons terminate in relation to bulbospinal neurons previously shown to project to regions of spinal cord containing motoneurons innervating abdominal expiratory muscles (J.M. Wild, Brain Res. 606:119-124, 1993). These projections of nucleus robustus thus seem well placed to coordinate syringeal, laryngeal, and expiratory muscle activity during vocalization. Other relatively sparse, but distinct, projections of nucleus robustus were found to nucleus dorsolateralis anterior thalami, pars medialis, to a narrow region between the superior olivary nucleus and the spinal lemniscus, and to the rostral ventrolateral medulla. Neurons in these last two locations were retrogradely labelled bilaterally following injections of cholera B-chain into nucleus retroambigualis of one side. Together with sparse contralateral projections of nucleus robustus to all brainstem targets receiving ipsilateral projections, potential pathways are thus identified by which the respiratory-vocal activity controlled by one side of the lower medulla can be influenced by the nucleus robustus of either side, thereby possibly bringing about bilateral coordination of respiratory-vocal output.},
	number = {2},
	journal = {The Journal of comparative neurology},
	author = {Wild, J M},
	year = {1993},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: pubmed:8308169},
	keywords = {⛔ No INSPIRE recid found},
	pages = {225--41},
}

@article{gewaltig_propagation_1970,
	title = {Propagation of cortical synfire activity: survival probability in single trials and stability in the mean.},
	volume = {14},
	issn = {0893-6080},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/11665761},
	doi = {10.1016/s0893-6080(01)00070-3},
	abstract = {The synfire hypothesis states that under appropriate conditions volleys of synchronized spikes (pulse packets) can propagate through the cortical network by traveling along chains of groups of cortical neurons. Here, we present results from network simulations, taking full account of the variability in pulse packet realizations. We repeatedly stimulated a synfire chain of model neurons and estimated activity (a) and temporal jitter (sigma) of the spike response for each neuron group in the chain in many trials. The survival probability of the activity was assessed for each point in (a, sigma)-space. The results confirm and extend our earlier predictions based on single neuron properties and a deterministic state-space analysis [Diesmann, M., Gewaltig, M.-O., \& Aertsen, A. (1999). Stable propagation of synchronous spiking in cortical neural networks. Nature, 402, 529-533].},
	number = {6-7},
	journal = {Neural networks : the official journal of the International Neural Network Society},
	author = {Gewaltig, M O and Diesmann, M and Aertsen, A},
	month = jan,
	year = {1970},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: pubmed:11665761},
	keywords = {⛔ No INSPIRE recid found},
	pages = {657--73},
}

@article{bienenstock_model_1995,
	title = {A model of neocortex},
	volume = {6},
	url = {https://doi.org/gm6nn3},
	doi = {10.1088/0954-898x_6_2_004},
	language = {en},
	number = {2},
	journal = {Network: Computation in Neural Systems},
	author = {Bienenstock, Elie},
	month = jan,
	year = {1995},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1088/0954-898x\_6\_2\_004},
	keywords = {⛔ No INSPIRE recid found},
	pages = {179--224},
}

@article{muller_stimulus-evoked_2014,
	title = {The stimulus-evoked population response in visual cortex of awake monkey is a propagating wave},
	volume = {5},
	issn = {2041-1723},
	doi = {10.1038/ncomms4675},
	abstract = {Propagating waves occur in many excitable media and were recently found in neural systems from retina to neocortex. While propagating waves are clearly present under anaesthesia, whether they also appear during awake and conscious states remains unclear. One possibility is that these waves are systematically missed in trial-averaged data, due to variability. Here we present a method for detecting propagating waves in noisy multichannel recordings. Applying this method to single-trial voltage-sensitive dye imaging data, we show that the stimulus-evoked population response in primary visual cortex of the awake monkey propagates as a travelling wave, with consistent dynamics across trials. A network model suggests that this reliability is the hallmark of the horizontal fibre network of superficial cortical layers. Propagating waves with similar properties occur independently in secondary visual cortex, but maintain precise phase relations with the waves in primary visual cortex. These results show that, in response to a visual stimulus, propagating waves are systematically evoked in several visual areas, generating a consistent spatiotemporal frame for further neuronal interactions.},
	journal = {Nature Communications},
	author = {Muller, Lyle and Reynaud, Alexandre and Chavane, Frédéric and Destexhe, Alain},
	year = {2014},
	note = {00068
Loaded from an external bibliography file by Manubot.
source\_bibliography: manual-references.bib
standard\_id: Muller14},
	keywords = {⛔ No INSPIRE recid found},
	pages = {3675},
}

@article{kaplan_anisotropic_2013,
	title = {Anisotropic connectivity implements motion-based prediction in a spiking neural network},
	volume = {7},
	url = {https://laurentperrinet.github.io/publication/kaplan-13},
	doi = {10.3389/fncom.2013.00112},
	abstract = {Predictive coding hypothesizes that the brain explicitly infers upcoming sensory input to establish a coherent representation of the world. Although it is becoming generally accepted, it is not clear on which level spiking neural networks may implement predictive coding and what function their connectivity may have. We present a network model of conductance-based integrate-and-fire neurons inspired by the architecture of retinotopic cortical areas that assumes predictive coding is implemented through network connectivity, namely in the connection delays and in selectiveness for the tuning properties of source and target cells. We show that the applied connection pattern leads to motion-based prediction in an experiment tracking a moving dot. In contrast to our proposed model, a network with random or isotropic connectivity fails to predict the path when the moving dot disappears. Furthermore, we show that a simple linear decoding approach is sufficient to transform neuronal spiking activity into a probabilistic estimate for reading out the target trajectory.},
	number = {112},
	journal = {Frontiers in Computational Neuroscience},
	author = {Kaplan, Bernhard A and Lansner, Anders and Masson, Guillaume S and Perrinet, Laurent U},
	month = sep,
	year = {2013},
	note = {Loaded from an external bibliography file by Manubot.
source\_bibliography: manual-references.bib
standard\_id: Kaplan13},
	keywords = {⛔ No INSPIRE recid found},
}

@article{chemla_suppressive_2019,
	title = {Suppressive waves disambiguate the representation of long-range apparent motion in awake monkey {V1}},
	volume = {2792},
	url = {http://www.jneurosci.org/content/early/2019/03/18/JNEUROSCI.2792-18.2019},
	doi = {10.1523/JNEUROSCI.2792-18.2019},
	abstract = {The “apparent motion” illusion is evoked when stationary stimuli are successively flashed in spatially separated positions. It depends on the precise spatial and temporal separations of the stimuli. For large spatiotemporal separation, the long-range apparent motion (lrAM), it remains unclear how the visual system computes unambiguous motion signals. Here we investigated whether intracortical interactions within retinotopic maps could shape a global motion representation at the level of V1 population in response to a lrAM. In fixating monkeys, voltage-sensitive dye imaging revealed the emergence of a spatio-temporal representation of the motion trajectory at the scale of V1 population activity, shaped by systematic backward suppressive waves. We show that these waves are the expected emergent property of a recurrent gain control fed by the horizontal intra-cortical network. Such non-linearities explain away ambiguous correspondence problems of the stimulus along the motion path, preformating V1 population response for an optimal read-out by downstream areas.},
	urldate = {2018-07-27},
	journal = {Journal of Neuroscience},
	author = {Chemla, Sandrine and Reynaud, Alexandre and diVolo, Matteo and Zerlaut, Yann and Perrinet, Laurent U and Destexhe, Alain and Chavane, Frédéric Y},
	month = mar,
	year = {2019},
	note = {Loaded from an external bibliography file by Manubot.
source\_bibliography: manual-references.bib
standard\_id: Chemla19},
	keywords = {⛔ No INSPIRE recid found},
	pages = {18},
}

@article{bringuier_horizontal_1999,
	title = {Horizontal {Propagation} of {Visual} {Activity} in the {Synaptic} {Integration} {Field} of {Area} 17 {Neurons}},
	volume = {283},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/283/5402/695},
	doi = {10.1126/science.283.5402.695},
	abstract = {The receptive field of a visual neuron is classically defined as the region of space (or retina) where a visual stimulus evokes a change in its firing activity. At the cortical level, a challenging issue concerns the roles of feedforward, local recurrent, intracortical, and cortico-cortical feedback connectivity in receptive field properties. Intracellular recordings in cat area 17 showed that the visually evoked synaptic integration field extends over a much larger area than that established on the basis of spike activity. Synaptic depolarizing responses to stimuli flashed at increasing distances from the center of the receptive field decreased in strength, whereas their onset latency increased. These findings suggest that subthreshold responses in the unresponsive region surrounding the classical discharge field result from the integration of visual activation waves spread by slowly conducting horizontal axons within primary visual cortex.},
	number = {5402},
	urldate = {2019-02-07},
	journal = {Science},
	author = {Bringuier, Vincent and Chavane, Frédéric and Glaeser, Larry and Frégnac, Yves},
	month = jan,
	year = {1999},
	note = {00535
Loaded from an external bibliography file by Manubot.
source\_bibliography: manual-references.bib
standard\_id: Bringuier99},
	keywords = {⛔ No INSPIRE recid found},
	pages = {695--699},
}

@techreport{goltz_fast_2021,
	title = {Fast and energy-efficient neuromorphic deep learning with first-spike times},
	url = {https://arxiv.org/abs/1912.11443},
	abstract = {For a biological agent operating under environmental pressure, energy consumption and reaction times are of critical importance. Similarly, engineered systems are optimized for short time-to-solution and low energy-to-solution characteristics. At the level of neuronal implementation, this implies achieving the desired results with as few and as early spikes as possible. With time-to-first-spike coding both of these goals are inherently emerging features of learning. Here, we describe a rigorous derivation of a learning rule for such first-spike times in networks of leaky integrate-and-fire neurons, relying solely on input and output spike times, and show how this mechanism can implement error backpropagation in hierarchical spiking networks. Furthermore, we emulate our framework on the BrainScaleS-2 neuromorphic system and demonstrate its capability of harnessing the system's speed and energy characteristics. Finally, we examine how our approach generalizes to other neuromorphic platforms by studying how its performance is affected by typical distortive effects induced by neuromorphic substrates.},
	number = {1912.11443},
	institution = {arXiv},
	author = {Göltz, Julian and Kriener, Laura and Baumbach, Andreas and Billaudelle, Sebastian and Breitwieser, Oliver and Cramer, Benjamin and Dold, Dominik and Kungl, Akos Ferenc and Senn, Walter and Schemmel, Johannes and Meier, Karlheinz and Petrovici, Mihai Alexandru},
	year = {2021},
	note = {license: http://creativecommons.org/licenses/by/4.0/
This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: arxiv:1912.11443},
	keywords = {⛔ No INSPIRE recid found},
}

@article{maass_networks_1997,
	title = {Networks of spiking neurons: {The} third generation of neural network models},
	volume = {10},
	issn = {08936080},
	shorttitle = {Networks of spiking neurons},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608097000117},
	doi = {10.1016/s0893-6080(97)00011-7},
	abstract = {The computational power of formal models for networks of spiking neurons is compared with that of other neural network models based on McCulloch Pitts neurons (i.e., threshold gates), respectively, sigmoidal gates. In particular it is shown that networks of spiking neurons are, with regard to the number of neurons that are needed, computationally more powerful than these other neural network models. A concrete biologically relevant function is exhibited which can be computed by a single spiking neuron (for biologically reasonable values of its parameters), but which requires hundreds of hidden units on a sigmoidal neural net. On the other hand, it is known that any function that can be computed by a small sigmoidal neural net can also be computed by a small network of spiking neurons. This article does not assume prior knowledge about spiking neurons, and it contains an extensive list of references to the currently available literature on computations in networks of spiking neurons and relevant results from neurobiology. © 1997 Elsevier Science Ltd. All rights reserved.},
	language = {en-US},
	number = {9},
	urldate = {2020-07-06},
	journal = {Neural Networks},
	author = {Maass, Wolfgang},
	year = {1997},
	note = {Loaded from an external bibliography file by Manubot.
source\_bibliography: manual-references.bib
standard\_id: Maass97},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1659--1671},
}

@article{kirchner_ultra-rapid_2006,
	title = {Ultra-rapid object detection with saccadic eye movements: {Visual} processing speed revisited},
	volume = {46},
	issn = {0042-6989},
	shorttitle = {Ultra-rapid object detection with saccadic eye movements},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698905005110},
	doi = {10.1016/j.visres.2005.10.002},
	abstract = {Previous ultra-rapid go/no-go categorization studies with manual responses have demonstrated the remarkable speed and efficiency with which humans process natural scenes. Using a forced-choice saccade task we show here that when two scenes are simultaneously flashed in the left and right hemifields, human participants can reliably make saccades to the side containing an animal in as little as 120 ms. Low level differences between target and distractor images were unable to account for these exceptionally fast responses. The results suggest a very fast and unexpected route linking visual processing in the ventral stream with the programming of saccadic eye movements.},
	number = {11},
	journal = {Vision Research},
	author = {Kirchner, H and Thorpe, Sj},
	year = {2006},
	note = {Loaded from an external bibliography file by Manubot.
source\_bibliography: manual-references.bib
standard\_id: Kirchner06},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1762--76},
}

@techreport{bellec_fitting_2021,
	title = {Fitting summary statistics of neural data with a differentiable spiking network simulator},
	url = {https://arxiv.org/abs/2106.10064},
	abstract = {Fitting network models to neural activity is an important tool in neuroscience. A popular approach is to model a brain area with a probabilistic recurrent spiking network whose parameters maximize the likelihood of the recorded activity. Although this is widely used, we show that the resulting model does not produce realistic neural activity. To correct for this, we suggest to augment the log-likelihood with terms that measure the dissimilarity between simulated and recorded activity. This dissimilarity is defined via summary statistics commonly used in neuroscience and the optimization is efficient because it relies on back-propagation through the stochastically simulated spike trains. We analyze this method theoretically and show empirically that it generates more realistic activity statistics. We find that it improves upon other fitting algorithms for spiking network models like GLMs (Generalized Linear Models) which do not usually rely on back-propagation. This new fitting algorithm also enables the consideration of hidden neurons which is otherwise notoriously hard, and we show that it can be crucial when trying to infer the network connectivity from spike recordings.},
	number = {2106.10064},
	institution = {arXiv},
	author = {Bellec, Guillaume and Wang, Shuqi and Modirshanechi, Alireza and Brea, Johanni and Gerstner, Wulfram},
	month = nov,
	year = {2021},
	note = {license: http://creativecommons.org/licenses/by/4.0/
This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: arxiv:2106.10064},
	keywords = {⛔ No INSPIRE recid found},
}

@article{muller_cortical_2018,
	title = {Cortical travelling waves: {Mechanisms} and computational principles},
	issn = {1471-003X},
	shorttitle = {Cortical travelling waves},
	url = {http://www.nature.com/doifinder/10.1038/nrn.2018.20},
	doi = {10.1038/nrn.2018.20},
	abstract = {Advanced recording techniques have enabled the identification of travelling waves of neuronal activity in different areas of the cortex. Sejnowski and colleagues review these findings, consider the mechanisms by which travelling waves are generated and evaluate their possible roles in cortical function.},
	journal = {Nature Reviews Neuroscience},
	author = {Muller, Lyle and Chavane, Frédéric and Reynolds, John and Sejnowski, Terrence J.},
	month = mar,
	year = {2018},
	note = {Loaded from an external bibliography file by Manubot.
source\_bibliography: manual-references.bib
standard\_id: Muller18},
	keywords = {⛔ No INSPIRE recid found},
}

@techreport{williams_point_2020,
	title = {Point process models for sequence detection in high-dimensional neural spike trains},
	url = {https://arxiv.org/abs/2010.04875},
	abstract = {Sparse sequences of neural spikes are posited to underlie aspects of working memory, motor production, and learning. Discovering these sequences in an unsupervised manner is a longstanding problem in statistical neuroscience. Promising recent work utilized a convolutive nonnegative matrix factorization model to tackle this challenge. However, this model requires spike times to be discretized, utilizes a sub-optimal least-squares criterion, and does not provide uncertainty estimates for model predictions or estimated parameters. We address each of these shortcomings by developing a point process model that characterizes fine-scale sequences at the level of individual spikes and represents sequence occurrences as a small number of marked events in continuous time. This ultra-sparse representation of sequence events opens new possibilities for spike train modeling. For example, we introduce learnable time warping parameters to model sequences of varying duration, which have been experimentally observed in neural circuits. We demonstrate these advantages on experimental recordings from songbird higher vocal center and rodent hippocampus.},
	number = {2010.04875},
	institution = {arXiv},
	author = {Williams, Alex H. and Degleris, Anthony and Wang, Yixin and Linderman, Scott W.},
	month = oct,
	year = {2020},
	note = {license: http://creativecommons.org/licenses/by/4.0/
This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: arxiv:2010.04875},
	keywords = {⛔ No INSPIRE recid found},
}

@incollection{nowak_timing_1997,
	title = {The {Timing} of {Information} {Transfer} in the {Visual} {System}},
	url = {https://doi.org/gpb33s},
	booktitle = {Extrastriate {Cortex} in {Primates}},
	publisher = {Springer US},
	author = {Nowak, Lionel G. and Bullier, Jean},
	year = {1997},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1007/978-1-4757-9625-4\_5},
	keywords = {⛔ No INSPIRE recid found},
	pages = {205--241},
}

@incollection{grun_unitary_2010,
	title = {Unitary {Event} {Analysis}},
	url = {https://doi.org/dxgxt9},
	booktitle = {Analysis of {Parallel} {Spike} {Trains}},
	publisher = {Springer US},
	author = {Grün, Sonja and Diesmann, Markus and Aertsen, Ad},
	year = {2010},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1007/978-1-4419-5675-0\_10},
	keywords = {⛔ No INSPIRE recid found},
	pages = {191--220},
}

@techreport{yin_sata_2022,
	title = {{SATA}: {Sparsity}-{Aware} {Training} {Accelerator} for {Spiking} {Neural} {Networks}},
	url = {https://arxiv.org/abs/2204.05422},
	abstract = {Spiking Neural Networks (SNNs) have gained huge attention as a potential energy-efficient alternative to conventional Artificial Neural Networks (ANNs) due to their inherent high-sparsity activation. Recently, SNNs with backpropagation through time (BPTT) have achieved a higher accuracy result on image recognition tasks compared to other SNN training algorithms. Despite the success on the algorithm perspective, prior works neglect the evaluation of the hardware energy overheads of BPTT, due to the lack of a hardware evaluation platform for SNN training algorithm design. Moreover, although SNNs have been long seen as an energy-efficient counterpart of ANNs, a quantitative comparison between the training cost of SNNs and ANNs is missing. To address the above-mentioned issues, in this work, we introduce SATA (Sparsity-Aware Training Accelerator), a BPTT-based training accelerator for SNNs. The proposed SATA provides a simple and re-configurable accelerator architecture for the general-purpose hardware evaluation platform, which makes it easier to analyze the training energy for SNN training algorithms. Based on SATA, we show quantitative analyses on the energy efficiency of SNN training and make a comparison between the training cost of SNNs and ANNs. The results show that SNNs consume \$1.27{\textbackslash}times\$ more total energy with considering sparsity (spikes, gradient of firing function, and gradient of membrane potential) when compared to ANNs. We find that such high training energy cost is from time-repetitive convolution operations and data movements during backpropagation. Moreover, to guide the future SNN training algorithm design, we provide several observations on energy efficiency with respect to different SNN-specific training parameters.},
	number = {2204.05422},
	institution = {arXiv},
	author = {Yin, Ruokai and Moitra, Abhishek and Bhattacharjee, Abhiroop and Kim, Youngeun and Panda, Priyadarshini},
	year = {2022},
	note = {license: http://creativecommons.org/licenses/by-nc-nd/4.0/
This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: arxiv:2204.05422},
	keywords = {⛔ No INSPIRE recid found},
}

@techreport{rasetto_challenges_2022,
	title = {The {Challenges} {Ahead} for {Bio}-inspired {Neuromorphic} {Event} {Processors}: {How} {Memristors} {Dynamic} {Properties} {Could} {Revolutionize} {Machine} {Learning}},
	url = {https://arxiv.org/abs/2201.12673},
	abstract = {Neuromorphic engineering has led to the necessary process of rethinking of how we process and integrate information, analyze data, and use the resulting insights to improve computation and avoid the current high power and latency of Artificial Intelligence (AI) hardware. Current neuromorphic processors are, however, limited by digital technologies, which cannot reproduce the abilities of biological neural computation in terms of power, latency and area cost. In this paper, we show that the combined use of the dynamic properties of memristors to implement a model of synaptic integration and the determination of the correct level of abstraction of biological neural networks has the potential to open a new range of capabilities for neuromorphic processors. We test this approach using a novel three-terminal LixWO3 electrochemical memristor, by deriving its conductance model and using it to emulate synaptic temporal kernel computation in the context of a pattern recognition task. We show that these devices allow for robust results with no loss in precision while opening the path for an energy efficient approach to build novel bio-inspired processing units in silicon.},
	number = {2201.12673},
	institution = {arXiv},
	author = {Rasetto, Marco and Wan, Qingzhou and Akolkar, Himanshu and Shi, Bertram and Xiong, Feng and Benosman, Ryad},
	year = {2022},
	note = {license: http://creativecommons.org/licenses/by/4.0/
This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: arxiv:2201.12673},
	keywords = {⛔ No INSPIRE recid found},
}

@techreport{panahi_generative_2021,
	title = {Generative {Models} of {Brain} {Dynamics} -- {A} review},
	url = {https://arxiv.org/abs/2112.12147},
	abstract = {The principled design and discovery of biologically- and physically-informed models of neuronal dynamics has been advancing since the mid-twentieth century. Recent developments in artificial intelligence (AI) have accelerated this progress. This review article gives a high-level overview of the approaches across different scales of organization and levels of abstraction. The studies covered in this paper include fundamental models in computational neuroscience, nonlinear dynamics, data-driven methods, as well as emergent practices. While not all of these models span the intersection of neuroscience, AI, and system dynamics, all of them do or can work in tandem as generative models, which, as we argue, provide superior properties for the analysis of neuroscientific data. We discuss the limitations and unique dynamical traits of brain data and the complementary need for hypothesis- and data-driven modeling. By way of conclusion, we present several hybrid generative models from recent literature in scientific machine learning, which can be efficiently deployed to yield interpretable models of neural dynamics.},
	number = {2112.12147},
	institution = {arXiv},
	author = {Panahi, Mahta Ramezanian and Abrevaya, Germán and Gagnon-Audet, Jean-Christophe and Voleti, Vikram and Rish, Irina and Dumas, Guillaume},
	year = {2021},
	note = {license: http://creativecommons.org/licenses/by/4.0/
This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: arxiv:2112.12147},
	keywords = {⛔ No INSPIRE recid found},
}

@techreport{nadafian_bio-plausible_2020,
	title = {Bio-plausible {Unsupervised} {Delay} {Learning} for {Extracting} {Temporal} {Features} in {Spiking} {Neural} {Networks}},
	url = {https://arxiv.org/abs/2011.09380},
	abstract = {The plasticity of the conduction delay between neurons plays a fundamental role in learning. However, the exact underlying mechanisms in the brain for this modulation is still an open problem. Understanding the precise adjustment of synaptic delays could help us in developing effective brain-inspired computational models in providing aligned insights with the experimental evidence. In this paper, we propose an unsupervised biologically plausible learning rule for adjusting the synaptic delays in spiking neural networks. Then, we provided some mathematical proofs to show that our learning rule gives a neuron the ability to learn repeating spatio-temporal patterns. Furthermore, the experimental results of applying an STDP-based spiking neural network equipped with our proposed delay learning rule on Random Dot Kinematogram indicate the efficacy of the proposed delay learning rule in extracting temporal features.},
	number = {2011.09380},
	institution = {arXiv},
	author = {Nadafian, Alireza and Ganjtabesh, Mohammad},
	month = nov,
	year = {2020},
	note = {license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/
This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: arxiv:2011.09380},
	keywords = {⛔ No INSPIRE recid found},
}

@article{stringer_high-precision_2021,
	title = {High-precision coding in visual cortex},
	volume = {184},
	url = {https://doi.org/gjqbjd},
	doi = {10.1016/j.cell.2021.03.042},
	language = {en},
	number = {10},
	journal = {Cell},
	author = {Stringer, Carsen and Michaelos, Michalis and Tsyboulski, Dmitri and Lindo, Sarah E. and Pachitariu, Marius},
	year = {2021},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.cell.2021.03.042},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2767--2778.e15},
}

@article{levakova_review_2015,
	title = {A review of the methods for neuronal response latency estimation},
	volume = {136},
	url = {https://doi.org/gpshjz},
	doi = {10.1016/j.biosystems.2015.04.008},
	language = {en},
	journal = {Biosystems},
	author = {Levakova, Marie and Tamborrino, Massimiliano and Ditlevsen, Susanne and Lansky, Petr},
	month = oct,
	year = {2015},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.biosystems.2015.04.008},
	keywords = {⛔ No INSPIRE recid found},
	pages = {23--34},
}

@article{pipa_neuroxidence_2008,
	title = {{NeuroXidence}: reliable and efficient analysis of an excess or deficiency of joint-spike events},
	volume = {25},
	url = {https://doi.org/ddh5js},
	doi = {10.1007/s10827-007-0065-3},
	language = {en},
	number = {1},
	journal = {Journal of Computational Neuroscience},
	author = {Pipa, Gordon and Wheeler, Diek W. and Singer, Wolf and Nikolić, Danko},
	month = jan,
	year = {2008},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1007/s10827-007-0065-3},
	keywords = {⛔ No INSPIRE recid found},
	pages = {64--88},
}

@article{stella_3d-spade_2019,
	title = {3d-{SPADE}: {Significance} evaluation of spatio-temporal patterns of various temporal extents},
	volume = {185},
	url = {https://doi.org/gpshj2},
	doi = {10.1016/j.biosystems.2019.104022},
	language = {en},
	journal = {Biosystems},
	author = {Stella, Alessandra and Quaglio, Pietro and Torre, Emiliano and Grün, Sonja},
	month = nov,
	year = {2019},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.biosystems.2019.104022},
	keywords = {⛔ No INSPIRE recid found},
	pages = {104022},
}

@article{kremkow_functional_2010,
	title = {Functional consequences of correlated excitatory and inhibitory conductances in cortical networks},
	volume = {28},
	url = {https://doi.org/c3wrbn},
	doi = {10.1007/s10827-010-0240-9},
	language = {en},
	number = {3},
	journal = {Journal of Computational Neuroscience},
	author = {Kremkow, Jens and Perrinet, Laurent U. and Masson, Guillaume S. and Aertsen, Ad},
	year = {2010},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1007/s10827-010-0240-9},
	keywords = {⛔ No INSPIRE recid found},
	pages = {579--594},
}

@article{quaglio_methods_2018,
	title = {Methods for identification of spike patterns in massively parallel spike trains},
	volume = {112},
	url = {https://doi.org/gdgckg},
	doi = {10.1007/s00422-018-0755-0},
	language = {en},
	number = {1-2},
	journal = {Biological Cybernetics},
	author = {Quaglio, Pietro and Rostami, Vahid and Torre, Emiliano and Grün, Sonja},
	year = {2018},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1007/s00422-018-0755-0},
	keywords = {⛔ No INSPIRE recid found},
	pages = {57--80},
}

@article{grammont_spike_2003,
	title = {Spike synchronization and firing rate in a population of motor cortical neurons in relation to movement direction and reaction time},
	volume = {88},
	url = {https://doi.org/ctvhsb},
	doi = {10.1007/s00422-002-0385-3},
	number = {5},
	journal = {Biological Cybernetics},
	author = {Grammont, F. and Riehle, A.},
	year = {2003},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1007/s00422-002-0385-3},
	keywords = {⛔ No INSPIRE recid found},
	pages = {360--373},
}

@article{tavanaei_representation_2018,
	title = {Representation learning using event-based {STDP}},
	volume = {105},
	url = {https://doi.org/gd6tgv},
	doi = {10.1016/j.neunet.2018.05.018},
	language = {en},
	journal = {Neural Networks},
	author = {Tavanaei, Amirhossein and Masquelier, Timothée and Maida, Anthony},
	month = sep,
	year = {2018},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.neunet.2018.05.018},
	keywords = {⛔ No INSPIRE recid found},
	pages = {294--303},
}

@article{zhang_supervised_2020,
	title = {Supervised learning in spiking neural networks with synaptic delay-weight plasticity},
	volume = {409},
	url = {https://doi.org/ghsm45},
	doi = {10.1016/j.neucom.2020.03.079},
	language = {en},
	journal = {Neurocomputing},
	author = {Zhang, Malu and Wu, Jibin and Belatreche, Ammar and Pan, Zihan and Xie, Xiurui and Chua, Yansong and Li, Guoqi and Qu, Hong and Li, Haizhou},
	month = oct,
	year = {2020},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.neucom.2020.03.079},
	keywords = {⛔ No INSPIRE recid found},
	pages = {103--118},
}

@article{rucci_temporal_2018,
	title = {Temporal {Coding} of {Visual} {Space}},
	volume = {22},
	url = {https://doi.org/gfcskd},
	doi = {10.1016/j.tics.2018.07.009},
	language = {en},
	number = {10},
	journal = {Trends in Cognitive Sciences},
	author = {Rucci, Michele and Ahissar, Ehud and Burr, David},
	month = oct,
	year = {2018},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.tics.2018.07.009},
	keywords = {⛔ No INSPIRE recid found},
	pages = {883--895},
}

@article{van_kempen_top-down_2021,
	title = {Top-down coordination of local cortical state during selective attention},
	volume = {109},
	url = {https://doi.org/ghvj3k},
	doi = {10.1016/j.neuron.2020.12.013},
	language = {en},
	number = {5},
	journal = {Neuron},
	author = {van Kempen, Jochem and Gieselmann, Marc A. and Boyd, Michael and Steinmetz, Nicholas A. and Moore, Tirin and Engel, Tatiana A. and Thiele, Alexander},
	month = mar,
	year = {2021},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.neuron.2020.12.013},
	keywords = {⛔ No INSPIRE recid found},
	pages = {894--904.e8},
}

@article{agus_rapid_2010,
	title = {Rapid {Formation} of {Robust} {Auditory} {Memories}: {Insights} from {Noise}},
	volume = {66},
	url = {https://doi.org/dc3r2d},
	doi = {10.1016/j.neuron.2010.04.014},
	language = {en},
	number = {4},
	journal = {Neuron},
	author = {Agus, Trevor R. and Thorpe, Simon J. and Pressnitzer, Daniel},
	year = {2010},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.neuron.2010.04.014},
	keywords = {⛔ No INSPIRE recid found},
	pages = {610--618},
}

@article{kheradpisheh_stdp-based_2018,
	title = {{STDP}-based spiking deep convolutional neural networks for object recognition},
	volume = {99},
	url = {https://doi.org/gc6dqh},
	doi = {10.1016/j.neunet.2017.12.005},
	language = {en},
	journal = {Neural Networks},
	author = {Kheradpisheh, Saeed Reza and Ganjtabesh, Mohammad and Thorpe, Simon J. and Masquelier, Timothée},
	month = mar,
	year = {2018},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.neunet.2017.12.005},
	keywords = {⛔ No INSPIRE recid found},
	pages = {56--67},
}

@article{kenyon_theory_2004,
	title = {A theory of the {Benham} {Top} based on center–surround interactions in the parvocellular pathway},
	volume = {17},
	url = {https://doi.org/bjwzzt},
	doi = {10.1016/j.neunet.2004.05.005},
	language = {en},
	number = {5-6},
	journal = {Neural Networks},
	author = {Kenyon, Garrett T and Hill, Dan and Theiler, James and George, John S and Marshak, David W},
	year = {2004},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.neunet.2004.05.005},
	keywords = {⛔ No INSPIRE recid found},
	pages = {773--786},
}

@article{buzsaki_space_2018,
	title = {Space and {Time}: {The} {Hippocampus} as a {Sequence} {Generator}},
	volume = {22},
	url = {https://doi.org/gfcr76},
	doi = {10.1016/j.tics.2018.07.006},
	language = {en},
	number = {10},
	journal = {Trends in Cognitive Sciences},
	author = {Buzsáki, György and Tingley, David},
	month = oct,
	year = {2018},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.tics.2018.07.006},
	keywords = {⛔ No INSPIRE recid found},
	pages = {853--869},
}

@article{orban_neural_2016,
	title = {Neural {Variability} and {Sampling}-{Based} {Probabilistic} {Representations} in the {Visual} {Cortex}},
	volume = {92},
	url = {https://doi.org/f88725},
	doi = {10.1016/j.neuron.2016.09.038},
	language = {en},
	number = {2},
	journal = {Neuron},
	author = {Orbán, Gergő and Berkes, Pietro and Fiser, József and Lengyel, Máté},
	month = oct,
	year = {2016},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.neuron.2016.09.038},
	keywords = {⛔ No INSPIRE recid found},
	pages = {530--543},
}

@article{puchalla_redundancy_2005,
	title = {Redundancy in the {Population} {Code} of the {Retina}},
	volume = {46},
	url = {https://doi.org/cw22j9},
	doi = {10.1016/j.neuron.2005.03.026},
	language = {en},
	number = {3},
	journal = {Neuron},
	author = {Puchalla, Jason L. and Schneidman, Elad and Harris, Robert A. and Berry, Michael J.},
	year = {2005},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/j.neuron.2005.03.026},
	keywords = {⛔ No INSPIRE recid found},
	pages = {493--504},
}

@article{thorpe_speed_1996,
	title = {Speed of processing in the human visual system},
	volume = {381},
	url = {https://doi.org/c4v35x},
	doi = {10.1038/381520a0},
	language = {en},
	number = {6582},
	journal = {Nature},
	author = {Thorpe, Simon and Fize, Denis and Marlot, Catherine},
	year = {1996},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/381520a0},
	keywords = {⛔ No INSPIRE recid found},
	pages = {520--522},
}

@article{celebrini_dynamics_1993,
	title = {Dynamics of orientation coding in area {V1} of the awake primate},
	volume = {10},
	url = {https://doi.org/dqt5cm},
	doi = {10.1017/s0952523800006052},
	abstract = {{\textless}jats:title{\textgreater}Abstract{\textless}/jats:title{\textgreater}{\textless}jats:p{\textgreater}To investigate the importance of feedback loops in visual information processing, we have analyzed the dynamic aspects of neuronal responses to oriented gratings in cortical area V1 of the awake primate. If recurrent feedback is important in generating orientation selectivity, the initial part of the neuronal response should be relatively poorly selective, and full orientation selectivity should only appear after a delay. Thus, by examining the dynamics of the neuronal responses it should be possible to assess the importance of feedback processes in the development of orientation selectivity. The results were base on a sample of 259 cells recorded in two monkeys, of which 89\% were visually responsive. Of these, approximately two-thirds were orientation selective. Response latency varied considerably between neurons, ranging from a minimum of 41 ms to over 150 ms, although most had latencies of 50–70 ms. Orientation tuning (defined as the bandwidth at half-height) ranged from 16 deg to over 90 deg, with a mean value of around 55 deg. By examining the selectivity of these different neurons by 10-ms time slices, starting at the onset of the neuronal response, we found that the orientation selectivity of virtually every neuron was fully developed at the very start of the neuronal response. Indeed, many neurons showed a marked tendency to respond at somewhat longer latencies to stimuli that were nonoptimally oriented, with the result that orientation selectivity was highest at the very start of the neuronal response. Furthermore, there was no evidence that the neurons with the shortest onset latencies were less selective. Such evidence is inconsistent with the hypothesis that recurrent intracortical feedback plays an important role in the generation of orientation selectivity. Instead, we suggest that orientation selectivity is primarily generated using feedforward mechanisms, including feedforward inhibition. Such a strategy has the advantage of allowing orientation to be computed rapidly, and avoids the initially poorly selective neuronal responses that characterize processing involving recurrent loops.{\textless}/jats:p{\textgreater}},
	language = {en},
	number = {5},
	journal = {Visual Neuroscience},
	author = {Celebrini, Simona and Thorpe, Simon and Trotter, Yves and Imbert, Michel},
	month = sep,
	year = {1993},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1017/s0952523800006052},
	keywords = {⛔ No INSPIRE recid found},
	pages = {811--825},
}

@article{perrinet_networks_2001,
	title = {Networks of integrate-and-fire neuron using rank order coding {A}: {How} to implement spike time dependent {Hebbian} plasticity},
	volume = {38-40},
	url = {https://doi.org/d5p6b2},
	doi = {10.1016/s0925-2312(01)00460-x},
	language = {en},
	journal = {Neurocomputing},
	author = {Perrinet, L. and Delorme, A. and Samuelides, M. and Thorpe, S.J.},
	year = {2001},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/s0925-2312(01)00460-x},
	keywords = {⛔ No INSPIRE recid found},
	pages = {817--822},
}

@article{lamme_distinct_2000,
	title = {The distinct modes of vision offered by feedforward and recurrent processing},
	volume = {23},
	url = {https://doi.org/ccv3w2},
	doi = {10.1016/s0166-2236(00)01657-x},
	language = {en},
	number = {11},
	journal = {Trends in Neurosciences},
	author = {Lamme, Victor A.F. and Roelfsema, Pieter R.},
	month = nov,
	year = {2000},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/s0166-2236(00)01657-x},
	keywords = {⛔ No INSPIRE recid found},
	pages = {571--579},
}

@article{harris_organization_2003,
	title = {Organization of cell assemblies in the hippocampus},
	volume = {424},
	url = {https://doi.org/bm3vgb},
	doi = {10.1038/nature01834},
	language = {en},
	number = {6948},
	journal = {Nature},
	author = {Harris, Kenneth D. and Csicsvari, Jozsef and Hirase, Hajime and Dragoi, George and Buzsáki, György},
	year = {2003},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/nature01834},
	keywords = {⛔ No INSPIRE recid found},
	pages = {552--556},
}

@article{roelfsema_visuomotor_1997,
	title = {Visuomotor integration is associated with zero time-lag synchronization among cortical areas},
	volume = {385},
	url = {https://doi.org/dp8q5v},
	doi = {10.1038/385157a0},
	language = {en},
	number = {6612},
	journal = {Nature},
	author = {Roelfsema, Pieter R. and Engel, Andreas K. and König, Peter and Singer, Wolf},
	month = jan,
	year = {1997},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/385157a0},
	keywords = {⛔ No INSPIRE recid found},
	pages = {157--161},
}

@article{wehr_odour_1996,
	title = {Odour encoding by temporal sequences of firing in oscillating neural assemblies},
	volume = {384},
	url = {https://doi.org/b3t32c},
	doi = {10.1038/384162a0},
	language = {en},
	number = {6605},
	journal = {Nature},
	author = {Wehr, Michael and Laurent, Gilles},
	month = nov,
	year = {1996},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/384162a0},
	keywords = {⛔ No INSPIRE recid found},
	pages = {162--166},
}

@article{decharms_primary_1996,
	title = {Primary cortical representation of sounds by the coordination of action-potential timing},
	volume = {381},
	url = {https://doi.org/bctwmg},
	doi = {10.1038/381610a0},
	language = {en},
	number = {6583},
	journal = {Nature},
	author = {deCharms, R. Christopher and Merzenich, Michael M.},
	year = {1996},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/381610a0},
	keywords = {⛔ No INSPIRE recid found},
	pages = {610--613},
}

@article{perrinet_coherence_2002,
	title = {Coherence detection in a spiking neuron via {Hebbian} learning},
	volume = {44-46},
	url = {https://doi.org/fsk9mk},
	doi = {10.1016/s0925-2312(02)00374-0},
	language = {en},
	journal = {Neurocomputing},
	author = {Perrinet, L. and Samuelides, M.},
	year = {2002},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1016/s0925-2312(02)00374-0},
	keywords = {⛔ No INSPIRE recid found},
	pages = {133--139},
}

@article{schneidman_weak_2006,
	title = {Weak pairwise correlations imply strongly correlated network states in a neural population},
	volume = {440},
	url = {https://doi.org/b9ph32},
	doi = {10.1038/nature04701},
	language = {en},
	number = {7087},
	journal = {Nature},
	author = {Schneidman, Elad and Berry, Michael J. and Segev, Ronen and Bialek, William},
	year = {2006},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/nature04701},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1007--1012},
}

@article{denker_lfp_2018,
	title = {{LFP} beta amplitude is linked to mesoscopic spatio-temporal phase patterns},
	volume = {8},
	url = {https://doi.org/gc9xx6},
	doi = {10.1038/s41598-018-22990-7},
	language = {en},
	number = {1},
	journal = {Scientific Reports},
	author = {Denker, Michael and Zehl, Lyuba and Kilavik, Bjørg E. and Diesmann, Markus and Brochier, Thomas and Riehle, Alexa and Grün, Sonja},
	month = mar,
	year = {2018},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/s41598-018-22990-7},
	keywords = {⛔ No INSPIRE recid found},
}

@article{ganguli_memory_2008,
	title = {Memory traces in dynamical systems},
	volume = {105},
	url = {https://doi.org/bq52bt},
	doi = {10.1073/pnas.0804451105},
	abstract = {{\textless}jats:p{\textgreater}
            To perform nontrivial, real-time computations on a sensory input stream, biological systems must retain a short-term memory trace of their recent inputs. It has been proposed that generic high-dimensional dynamical systems could retain a memory trace for past inputs in their current state. This raises important questions about the fundamental limits of such memory traces and the properties required of dynamical systems to achieve these limits. We address these issues by applying Fisher information theory to dynamical systems driven by time-dependent signals corrupted by noise. We introduce the Fisher Memory Curve (FMC) as a measure of the signal-to-noise ratio (SNR) embedded in the dynamical state relative to the input SNR. The integrated FMC indicates the total memory capacity. We apply this theory to linear neuronal networks and show that the capacity of networks with normal connectivity matrices is exactly 1 and that of any network of N neurons is, at most, N. A nonnormal network achieving this bound is subject to stringent design constraints: It must have a hidden feedforward architecture that superlinearly amplifies its input for a time of order N, and the input connectivity must optimally match this architecture. The memory capacity of networks subject to saturating nonlinearities is further limited, and cannot exceed
            {\textless}jats:inline-formula{\textgreater}
              {\textless}mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" overflow="scroll"{\textgreater}
                {\textless}mml:mrow{\textgreater}
                  {\textless}mml:msqrt{\textgreater}
                    {\textless}mml:mi{\textgreater}N{\textless}/mml:mi{\textgreater}
                  {\textless}/mml:msqrt{\textgreater}
                {\textless}/mml:mrow{\textgreater}
              {\textless}/mml:math{\textgreater}
            {\textless}/jats:inline-formula{\textgreater}
            . This limit can be realized by feedforward structures with divergent fan out that distributes the signal across neurons, thereby avoiding saturation. We illustrate the generality of the theory by showing that memory in fluid systems can be sustained by transient nonnormal amplification due to convective instability or the onset of turbulence.
          {\textless}/jats:p{\textgreater}},
	language = {en},
	number = {48},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Ganguli, Surya and Huh, Dongsung and Sompolinsky, Haim},
	year = {2008},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1073/pnas.0804451105},
	keywords = {⛔ No INSPIRE recid found},
	pages = {18970--18975},
}

@article{chase_first-spike_2007,
	title = {First-spike latency information in single neurons increases when referenced to population onset},
	volume = {104},
	url = {https://doi.org/cm3b98},
	doi = {10.1073/pnas.0610368104},
	abstract = {{\textless}jats:p{\textgreater}It is well known that many stimulus parameters, such as sound location in the auditory system or contrast in the visual system, can modulate the timing of the first spike in sensory neurons. Could first-spike latency be a candidate neural code? Most studies measuring first-spike latency information assume that the brain has an independent reference for stimulus onset from which to extract latency. This assumption creates an obvious confound that casts doubt on the feasibility of first-spike latency codes. If latency is measured relative to an internal reference of stimulus onset calculated from the responses of the neural population, the information conveyed by the latency of single neurons might decrease because of correlated changes in latency across the population. Here we assess the effects of a realistic model of stimulus onset detection on the first-spike latency information conveyed by single neurons in the auditory system. Contrary to expectation, we find that on average, the information contained in single neurons does not decrease; in fact, the majority of neurons show a slight increase in the information conveyed by latency referenced to a population onset. Our results show that first-spike latency codes are a feasible mechanism for information transfer even when biologically plausible estimates of stimulus onset are taken into account.{\textless}/jats:p{\textgreater}},
	language = {en},
	number = {12},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Chase, Steven M. and Young, Eric D.},
	month = mar,
	year = {2007},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1073/pnas.0610368104},
	keywords = {⛔ No INSPIRE recid found},
	pages = {5175--5180},
}

@article{stringer_high-dimensional_2019,
	title = {High-dimensional geometry of population responses in visual cortex},
	volume = {571},
	url = {https://doi.org/gf4cfj},
	doi = {10.1038/s41586-019-1346-5},
	language = {en},
	number = {7765},
	journal = {Nature},
	author = {Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas and Carandini, Matteo and Harris, Kenneth D.},
	year = {2019},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/s41586-019-1346-5},
	keywords = {⛔ No INSPIRE recid found},
	pages = {361--365},
}

@article{johansson_first_2004,
	title = {First spikes in ensembles of human tactile afferents code complex spatial fingertip events},
	volume = {7},
	url = {https://doi.org/dqstpm},
	doi = {10.1038/nn1177},
	language = {en},
	number = {2},
	journal = {Nature Neuroscience},
	author = {Johansson, Roland S and Birznieks, Ingvars},
	month = jan,
	year = {2004},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/nn1177},
	keywords = {⛔ No INSPIRE recid found},
	pages = {170--177},
}

@article{pillow_spatio-temporal_2008,
	title = {Spatio-temporal correlations and visual signalling in a complete neuronal population},
	volume = {454},
	url = {https://doi.org/dzvdm3},
	doi = {10.1038/nature07140},
	language = {en},
	number = {7207},
	journal = {Nature},
	author = {Pillow, Jonathan W. and Shlens, Jonathon and Paninski, Liam and Sher, Alexander and Litke, Alan M. and Chichilnisky, E. J. and Simoncelli, Eero P.},
	year = {2008},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/nature07140},
	keywords = {⛔ No INSPIRE recid found},
	pages = {995--999},
}

@article{duffy_variation_2019,
	title = {Variation in sequence dynamics improves maintenance of stereotyped behavior in an example from bird song},
	volume = {116},
	url = {https://doi.org/gpfjm6},
	doi = {10.1073/pnas.1815910116},
	abstract = {{\textless}jats:title{\textgreater}Significance{\textless}/jats:title{\textgreater}
          {\textless}jats:p{\textgreater}In this work, we show a way by which the nervous system maintains precise, stereotyped behavior in the face of environmental and neural changes. Through a model of bird song learning, we show how instability in neural representation of stable behavior can allow a system to more readily adapt and maintain performance with minimal cost. In this perspective, behaviors are made more robust to environmental change by continually seeking subtly new ways of performing the same task. Thus, one should expect to find variability in neural systems executing stereotyped behaviors, and this variability can serve a constructive role in maintaining skilled behavior.{\textless}/jats:p{\textgreater}},
	language = {en},
	number = {19},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Duffy, Alison and Abe, Elliott and Perkel, David J. and Fairhall, Adrienne L.},
	year = {2019},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1073/pnas.1815910116},
	keywords = {⛔ No INSPIRE recid found},
	pages = {9592--9597},
}

@article{miller_visual_2014,
	title = {Visual stimuli recruit intrinsically generated cortical ensembles},
	volume = {111},
	url = {https://doi.org/f6htkt},
	doi = {10.1073/pnas.1406077111},
	abstract = {{\textless}jats:title{\textgreater}Significance{\textless}/jats:title{\textgreater}
          {\textless}jats:p{\textgreater}This study demonstrates that neuronal groups or ensembles, rather than individual neurons, are emergent functional units of cortical activity. We show that in the presence and absence of visual stimulation, cortical activity is dominated by coactive groups of neurons forming ensembles. These ensembles are flexible and cannot be accounted for by the independent firing properties of neurons in isolation. Intrinsically generated ensembles and stimulus-evoked ensembles are similar, with one main difference: Whereas intrinsic ensembles recur at random time intervals, visually evoked ensembles are time-locked to stimuli. We propose that visual stimuli recruit endogenously generated ensembles to represent visual attributes.{\textless}/jats:p{\textgreater}},
	language = {en},
	number = {38},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Miller, Jae-eun Kang and Ayzenshtat, Inbal and Carrillo-Reid, Luis and Yuste, Rafael},
	month = sep,
	year = {2014},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1073/pnas.1406077111},
	keywords = {⛔ No INSPIRE recid found},
}

@article{safaie_turning_2020,
	title = {Turning the body into a clock: {Accurate} timing is facilitated by simple stereotyped interactions with the environment},
	volume = {117},
	url = {https://doi.org/gnqsmh},
	doi = {10.1073/pnas.1921226117},
	abstract = {{\textless}jats:p{\textgreater}How animals adapt their behavior according to regular time intervals between events is not well understood, especially when intervals last several seconds. One possibility is that animals use disembodied internal neuronal representations of time to decide when to initiate a given action at the end of an interval. However, animals rarely remain immobile during time intervals but tend to perform stereotyped behaviors, raising the possibility that motor routines improve timing accuracy. To test this possibility, we used a task in which rats, freely moving on a motorized treadmill, could obtain a reward if they approached it after a fixed interval. Most animals took advantage of the treadmill length and its moving direction to develop, by trial-and-error, the same motor routine whose execution resulted in the precise timing of their reward approaches. Noticeably, when proficient animals did not follow this routine, their temporal accuracy decreased. Then, naïve animals were trained in modified versions of the task designed to prevent the development of this routine. Compared to rats trained in the first protocol, these animals didn’t reach a comparable level of timing accuracy. Altogether, our results indicate that timing accuracy in rats is improved when the environment affords cues that animals can incorporate into motor routines.{\textless}/jats:p{\textgreater}},
	language = {en},
	number = {23},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Safaie, Mostafa and Jurado-Parras, Maria-Teresa and Sarno, Stefania and Louis, Jordane and Karoutchi, Corane and Petit, Ludovic F. and Pasquet, Matthieu O. and Eloy, Christophe and Robbe, David},
	year = {2020},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1073/pnas.1921226117},
	keywords = {⛔ No INSPIRE recid found},
	pages = {13084--13093},
}

@unpublished{linden_movement_2021,
	title = {Movement is governed by rotational population dynamics in spinal motor networks},
	url = {https://doi.org/gqg6rb},
	abstract = {{\textless}jats:title{\textgreater}ABSTRACT{\textless}/jats:title{\textgreater}{\textless}jats:p{\textgreater}Although the generation of movements is a fundamental function of the nervous system, the underlying neural principles remain unclear. Since flexor- and extensor-muscles alternate during rhythmic movements like walking, it is often assumed that the responsible neural circuitry is similarly displaying alternating activity. Here, we present ensemble-recordings of neurons in the lumbar spinal cord that indicate that, rather than alternating, the population is performing a low-dimensional “rotation” in neural space, in which the neural activity is cycling through all phases continuously during the rhythmic behavior. The radius of rotation correlates with the intended muscle force and a perturbation of the low-dimensional trajectory can modify the motor behavior. Since existing models of spinal motor control offer an inadequate explanation of rotation, we propose a new theory of neural generation of movements from which this and other unresolved issues, such as speed regulation, force control, and multi-functionalism, are readily explained.{\textless}/jats:p{\textgreater}},
	author = {Lindén, Henrik and Petersen, Peter C. and Vestergaard, Mikkel and Berg, Rune W.},
	month = sep,
	year = {2021},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1101/2021.08.31.458405},
	keywords = {⛔ No INSPIRE recid found},
}

@article{nowak_influence_1997,
	title = {Influence of low and high frequency inputs on spike timing in visual cortical neurons},
	volume = {7},
	url = {https://doi.org/fvjpx7},
	doi = {10.1093/cercor/7.6.487},
	number = {6},
	journal = {Cerebral Cortex},
	author = {Nowak, L.},
	month = sep,
	year = {1997},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1093/cercor/7.6.487},
	keywords = {⛔ No INSPIRE recid found},
	pages = {487--501},
}

@inproceedings{grimaldi_homeostatic_2021,
	title = {A homeostatic gain control mechanism to improve event-driven object recognition},
	url = {https://doi.org/gkzcrv},
	doi = {10.1109/cbmi50038.2021.9461901},
	booktitle = {2021 {International} {Conference} on {Content}-{Based} {Multimedia} {Indexing} ({CBMI})},
	publisher = {IEEE},
	author = {Grimaldi, Antoine and Boutin, Victor and Perrinet, Laurent and Ieng, Sio-Hoi and Benosman, Ryad},
	year = {2021},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1109/cbmi50038.2021.9461901},
	keywords = {⛔ No INSPIRE recid found},
}

@article{gerstner_time_1995,
	title = {Time structure of the activity in neural network models},
	volume = {51},
	url = {https://doi.org/cwcn9d},
	doi = {10.1103/physreve.51.738},
	language = {en},
	number = {1},
	journal = {Physical Review E},
	author = {Gerstner, Wulfram},
	month = jan,
	year = {1995},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1103/physreve.51.738},
	keywords = {⛔ No INSPIRE recid found},
	pages = {738--758},
}

@article{luo_supervised_2022,
	title = {Supervised {Learning} in {Multilayer} {Spiking} {Neural} {Networks} {With} {Spike} {Temporal} {Error} {Backpropagation}},
	url = {https://doi.org/gpzp26},
	doi = {10.1109/tnnls.2022.3164930},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Luo, Xiaoling and Qu, Hong and Wang, Yuchen and Yi, Zhang and Zhang, Jilun and Zhang, Malu},
	year = {2022},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1109/tnnls.2022.3164930},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1--13},
}

@article{azouz_stimulus-selective_2008,
	title = {Stimulus-selective spiking is driven by the relative timing of synchronous excitation and disinhibition in cat striate neurons\textit{in vivo}},
	volume = {28},
	url = {https://doi.org/cbcr8h},
	doi = {10.1111/j.1460-9568.2008.06434.x},
	language = {en},
	number = {7},
	journal = {European Journal of Neuroscience},
	author = {Azouz, Rony and Gray, Charles M.},
	month = oct,
	year = {2008},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1111/j.1460-9568.2008.06434.x},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1286--1300},
}

@article{moser_stability_2014,
	title = {On {Stability} of {Distance} {Measures} for {Event} {Sequences} {Induced} by {Level}-{Crossing} {Sampling}},
	volume = {62},
	url = {https://doi.org/gnpb7w},
	doi = {10.1109/tsp.2014.2305642},
	number = {8},
	journal = {IEEE Transactions on Signal Processing},
	author = {Moser, Bernhard A. and Natschlager, Thomas},
	year = {2014},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1109/tsp.2014.2305642},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1987--1999},
}

@article{tolle_fourth_2011,
	title = {The {Fourth} {Paradigm}: {Data}-{Intensive} {Scientific} {Discovery} [{Point} of {View}]},
	volume = {99},
	url = {https://doi.org/dfggjc},
	doi = {10.1109/jproc.2011.2155130},
	number = {8},
	journal = {Proceedings of the IEEE},
	author = {Tolle, Kristin M. and Tansley, D. Stewart W. and Hey, Anthony J. G.},
	year = {2011},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1109/jproc.2011.2155130},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1334--1337},
}

@article{thorpe_seeking_2001,
	title = {Seeking {Categories} in the {Brain}},
	volume = {291},
	url = {https://doi.org/bzn42k},
	doi = {10.1126/science.1058249},
	language = {en},
	number = {5502},
	journal = {Science},
	author = {Thorpe, Simon J. and Fabre-Thorpe, Michèle},
	month = jan,
	year = {2001},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1126/science.1058249},
	keywords = {⛔ No INSPIRE recid found},
	pages = {260--263},
}

@article{perrinet_coding_2004,
	title = {Coding static natural images using spiking event times: do neurons cooperate?},
	volume = {15},
	doi = {10.1109/TNN.2004.833303},
	number = {5},
	journal = {IEEE Transactions on neural networks},
	author = {Perrinet, Laurent and Samuelides, Manuel and Thorpe, Simon},
	year = {2004},
	note = {Publisher: IEEE},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1164--1175},
}

@article{pastalkova_internally_2008,
	title = {Internally {Generated} {Cell} {Assembly} {Sequences} in the {Rat} {Hippocampus}},
	volume = {321},
	issn = {0036-8075},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2570043/},
	doi = {10.1126/science.1159775},
	abstract = {A longstanding conjecture in neuroscience is that aspects of cognition depend on the brain's ability to self-generate sequential neuronal activity. We found that reliably and continually-changing cell assemblies in the rat hippocampus appeared not only during spatial navigation but also in the absence of changing environmental or body-derived inputs. During the delay period of a memory task each moment in time was characterized by the activity of a unique assembly of neurons. Identical initial conditions triggered a similar assembly sequence, whereas different conditions gave rise, uniquely, to different sequences, thereby predicting behavioral choices, including errors. Such sequences were not formed in control, non-memory, tasks. We hypothesize that neuronal representations, evolved for encoding distance in spatial navigation, also support episodic recall and the planning of action sequences.},
	number = {5894},
	urldate = {2022-02-23},
	journal = {Science (New York, N.Y.)},
	author = {Pastalkova, Eva and Itskov, Vladimir and Amarasingham, Asohan and Buzsáki, György},
	month = sep,
	year = {2008},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1322--1327},
}

@article{riehle_spike_1997,
	title = {Spike synchronization and rate modulation differentially involved in motor cortical function},
	volume = {278},
	doi = {10.1126/science.278.5345.1950},
	number = {5345},
	journal = {Science (New York, N.Y.)},
	author = {Riehle, Alexa and Grun, Sonja and Diesmann, Markus and Aertsen, Ad},
	year = {1997},
	note = {Publisher: American Association for the Advancement of Science},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1950--1953},
}

@article{gutig_spike_2014,
	series = {Theoretical and computational neuroscience},
	title = {To spike, or when to spike?},
	volume = {25},
	issn = {0959-4388},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438814000129},
	doi = {10.1016/j.conb.2014.01.004},
	abstract = {Recent experimental reports have suggested that cortical networks can operate in regimes were sensory information is encoded by relatively small populations of spikes and their precise relative timing. Combined with the discovery of spike timing dependent plasticity, these findings have sparked growing interest in the capabilities of neurons to encode and decode spike timing based neural representations. To address these questions, a novel family of methodologically diverse supervised learning algorithms for spiking neuron models has been developed. These models have demonstrated the high capacity of simple neural architectures to operate also beyond the regime of the well established independent rate codes and to utilize theoretical advantages of spike timing as an additional coding dimension.},
	language = {en},
	urldate = {2022-05-13},
	journal = {Current Opinion in Neurobiology},
	author = {Gütig, Robert},
	month = apr,
	year = {2014},
	keywords = {⛔ No INSPIRE recid found},
	pages = {134--139},
}

@article{luczak_sequential_2007,
	title = {Sequential structure of neocortical spontaneous activity in vivo},
	volume = {104},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/104/1/347},
	doi = {10.1073/pnas.0605643104},
	abstract = {Even in the absence of sensory stimulation, the neocortex shows complex spontaneous activity patterns, often consisting of alternating “DOWN” states of generalized neural silence and “UP” states of massive, persistent network activity. To investigate how this spontaneous activity propagates through neuronal assemblies in vivo, we simultaneously recorded populations of 50–200 cortical neurons in layer V of anesthetized and awake rats. Each neuron displayed a virtually unique spike pattern during UP states, with diversity seen amongst both putative pyramidal cells and interneurons, reflecting a complex but stereotypically organized sequential spread of activation through local cortical networks. Spike timing was most precise during the first ≈100 ms after UP state onset, and decayed as UP states progressed. A subset of UP states propagated as traveling waves, but waves passing a given point in either direction initiated similar local sequences, suggesting local networks as the substrate of sequential firing patterns. A search for repeating motifs indicated that their occurrence and structure was predictable from neurons' individual latencies to UP state onset. We suggest that these stereotyped patterns arise from the interplay of intrinsic cellular conductances and local circuit properties.},
	language = {en},
	number = {1},
	urldate = {2022-02-23},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Luczak, Artur and Barthó, Peter and Marguet, Stephan L. and Buzsáki, György and Harris, Kenneth D.},
	month = jan,
	year = {2007},
	keywords = {microcircuits, neuronal assembly, repeating sequences, slow oscillations, syntire chains, ⛔ No INSPIRE recid found},
	pages = {347--352},
}

@article{bohte_evidence_2004,
	title = {The evidence for neural information processing with precise spike-times: {A} survey},
	volume = {3},
	doi = {10.1023/B:NACO.0000027755.02868.60},
	number = {2},
	journal = {Natural Computing},
	author = {Bohte, Sander M},
	year = {2004},
	keywords = {⛔ No INSPIRE recid found},
	pages = {195--206},
}

@article{carr_circuit_1990,
	title = {A circuit for detection of interaural time differences in the brain stem of the barn owl},
	volume = {10},
	doi = {10.1523/JNEUROSCI.10-10-03227.1990},
	number = {10},
	journal = {Journal of Neuroscience},
	author = {Carr, CE and Konishi, M},
	year = {1990},
	keywords = {⛔ No INSPIRE recid found},
	pages = {3227--3246},
}

@article{davis_spontaneous_2021,
	title = {Spontaneous traveling waves naturally emerge from horizontal fiber time delays and travel through locally asynchronous-irregular states},
	volume = {12},
	doi = {10.1038/s41467-021-26175-1},
	number = {1},
	journal = {Nature Communications},
	author = {Davis, Zachary W and Benigno, Gabriel B and Fletterman, Charlee and Desbordes, Theo and Steward, Christopher and Sejnowski, Terrence J and H Reynolds, John and Muller, Lyle},
	year = {2021},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1--16},
}

@article{perrinet_active_2014,
	title = {Active inference, eye movements and oculomotor delays},
	volume = {108},
	copyright = {All rights reserved},
	issn = {1432-0770},
	url = {https://doi.org/10.1007/s00422-014-0620-8},
	doi = {10.1007/s00422-014-0620-8},
	abstract = {This paper considers the problem of sensorimotor delays in the optimal control of (smooth) eye movements under uncertainty. Specifically, we consider delays in the visuo-oculomotor loop and their implications for active inference. Active inference uses a generalisation of Kalman filtering to provide Bayes optimal estimates of hidden states and action in generalised coordinates of motion. Representing hidden states in generalised coordinates provides a simple way of compensating for both sensory and oculomotor delays. The efficacy of this scheme is illustrated using neuronal simulations of pursuit initiation responses, with and without compensation. We then consider an extension of the generative model to simulate smooth pursuit eye movements in which the visuo-oculomotor system believes both the target and its centre of gaze are attracted to a (hidden) point moving in the visual field. Finally, the generative model is equipped with a hierarchical structure, so that it can recognise and remember unseen (occluded) trajectories and emit anticipatory responses. These simulations speak to a straightforward and neurobiologically plausible solution to the generic problem of integrating information from different sources with different temporal delays and the particular difficulties encountered when a system, like the oculomotor system, tries to control its environment with delayed signals.},
	number = {6},
	journal = {Biological Cybernetics},
	author = {Perrinet, Laurent U and Adams, Rick A and Friston, Karl J},
	month = dec,
	year = {2014},
	keywords = {\#nosource, Active inference, Bayesian model, Biologically Inspired Computer vision, Generalised coordinates, Oculomotor delays, Smooth pursuit eye movements, Tracking eye movements, Variational free energy, active inference, active-inference, bayesian, bicv-motion, bicv-sparse, delays, eye, eye movements, eye-movements, free energy, free-energy, generalized-coordinates, generalized-filtering, motion detection, oculomotor, perception, perrinetadamsfriston14, smooth-pursuit, tracking-eye-movements, variational-filtering, ⛔ No INSPIRE recid found},
	pages = {777--801},
}

@article{villette_internally_2015,
	title = {Internally {Recurring} {Hippocampal} {Sequences} as a {Population} {Template} of {Spatiotemporal} {Information}},
	volume = {88},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627315008417},
	doi = {10/f7whnn},
	abstract = {The hippocampus is essential for spatiotemporal cognition. Sequences of neuronal activation provide a substrate for this fundamental function. At the behavioral timescale, these sequences have been shown to occur either in the presence of successive external landmarks or through internal mechanisms within an episodic memory task. In both cases, activity is externally constrained by the organization of the task and by the size of the environment explored. Therefore, it remains unknown whether hippocampal activity can self-organize into a default mode in the absence of any external memory demand or spatiotemporal boundary. Here we show that, in the presence of self-motion cues, a population code integrating distance naturally emerges in the hippocampus in the form of recurring sequences. These internal dynamics clamp spontaneous travel since run distance distributes into integer multiples of the span of these sequences. These sequences may thus guide navigation when external landmarks are reduced.},
	language = {en},
	number = {2},
	urldate = {2022-01-17},
	journal = {Neuron},
	author = {Villette, Vincent and Malvache, Arnaud and Tressard, Thomas and Dupuy, Nathalie and Cossart, Rosa},
	month = oct,
	year = {2015},
	note = {00085},
	keywords = {⛔ No INSPIRE recid found},
	pages = {357--366},
}

@incollection{paugam-moisy_computing_2012,
	title = {Computing with spiking neuron networks},
	booktitle = {Handbook of natural computing},
	publisher = {Springer-Verlag},
	author = {Paugam-Moisy, Hélène and Bohte, Sander M.},
	month = sep,
	year = {2012},
	keywords = {⛔ No INSPIRE recid found},
}

@article{haimerl_internal_2019,
	title = {Internal representation of hippocampal neuronal population spans a time-distance continuum},
	volume = {116},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/116/15/7477},
	doi = {10.1073/pnas.1718518116},
	abstract = {The hippocampus plays a critical role in episodic memory: the sequential representation of visited places and experienced events. This function is mirrored by hippocampal activity that self organizes into sequences of neuronal activation that integrate spatiotemporal information. What are the underlying mechanisms of such integration is still unknown. Single cell activity was recently shown to combine time and distance information; however, it remains unknown whether a degree of tuning between space and time can be defined at the network level. Here, combining daily calcium imaging of CA1 sequence dynamics in running head-fixed mice and network modeling, we show that CA1 network activity tends to represent a specific combination of space and time at any given moment, and that the degree of tuning can shift within a continuum from 1 day to the next. Our computational model shows that this shift in tuning can happen under the control of the external drive power. We propose that extrinsic global inputs shape the nature of spatiotemporal integration in the hippocampus at the population level depending on the task at hand, a hypothesis which may guide future experimental studies.},
	language = {en},
	number = {15},
	urldate = {2022-01-17},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Haimerl, Caroline and Angulo-Garcia, David and Villette, Vincent and Reichinnek, Susanne and Torcini, Alessandro and Cossart, Rosa and Malvache, Arnaud},
	month = apr,
	year = {2019},
	keywords = {attractor network, hippocampus, neural model, space representation, time representation, ⛔ No INSPIRE recid found},
	pages = {7477--7482},
}

@article{malvache_awake_2016,
	title = {Awake hippocampal reactivations project onto orthogonal neuronal assemblies},
	volume = {353},
	issn = {1095-9203},
	doi = {10/bqpq},
	abstract = {The chained activation of neuronal assemblies is thought to support major cognitive processes, including memory. In the hippocampus, this is observed during population bursts often associated with sharp-wave ripples, in the form of an ordered reactivation of neurons. However, the organization and lifetime of these assemblies remain unknown. We used calcium imaging to map patterns of synchronous neuronal activation in the CA1 region of awake mice during runs on a treadmill. The patterns were composed of the recurring activation of anatomically intermingled, but functionally orthogonal, assemblies. These assemblies reactivated discrete temporal segments of neuronal sequences observed during runs and could be stable across consecutive days. A binding of these assemblies into longer chains revealed temporally ordered replay. These modules may represent the default building blocks for encoding or retrieving experience.},
	language = {eng},
	number = {6305},
	journal = {Science (New York, N.Y.)},
	author = {Malvache, Arnaud and Reichinnek, Susanne and Villette, Vincent and Haimerl, Caroline and Cossart, Rosa},
	month = sep,
	year = {2016},
	pmid = {27634534},
	note = {00105 },
	keywords = {Animals, Brain Mapping, CA1 Region, Hippocampal, Calcium Signaling, Exercise Test, Male, Mice, Nerve Net, Neurons, Running, Wakefulness, ⛔ No INSPIRE recid found},
	pages = {1280--1283},
}

@article{ikegaya_synfire_2004,
	title = {Synfire {Chains} and {Cortical} {Songs}: {Temporal} {Modules} of {Cortical} {Activity}},
	volume = {304},
	shorttitle = {Synfire {Chains} and {Cortical} {Songs}},
	url = {http://www.science.org/doi/10.1126/science.1093173},
	doi = {10/djckcn},
	number = {5670},
	urldate = {2021-11-29},
	journal = {Science},
	author = {Ikegaya, Yuji and Aaron, Gloster and Cossart, Rosa and Aronov, Dmitriy and Lampl, Ilan and Ferster, David and Yuste, Rafael},
	month = apr,
	year = {2004},
	note = {00000 
tex.ids= Ikegaya2004a
publisher: American Association for the Advancement of Science},
	keywords = {\#nosource, polychronization, ⛔ No INSPIRE recid found},
	pages = {559--564},
}

@article{khoei_flash-lag_2017,
	title = {The {Flash}-{Lag} {Effect} as a {Motion}-{Based} {Predictive} {Shift}},
	volume = {13},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005068},
	doi = {10.1371/journal.pcbi.1005068},
	abstract = {Due to its inherent neural delays, the visual system has an outdated access to sensory information about the current position of moving objects. In contrast, living organisms are remarkably able to track and intercept moving objects under a large range of challenging environmental conditions. Physiological, behavioral and psychophysical evidences strongly suggest that position coding is extrapolated using an explicit and reliable representation of object’s motion but it is still unclear how these two representations interact. For instance, the so-called flash-lag effect supports the idea of a differential processing of position between moving and static objects. Although elucidating such mechanisms is crucial in our understanding of the dynamics of visual processing, a theory is still missing to explain the different facets of this visual illusion. Here, we reconsider several of the key aspects of the flash-lag effect in order to explore the role of motion upon neural coding of objects’ position. First, we formalize the problem using a Bayesian modeling framework which includes a graded representation of the degree of belief about visual motion. We introduce a motion-based prediction model as a candidate explanation for the perception of coherent motion. By including the knowledge of a fixed delay, we can model the dynamics of sensory information integration by extrapolating the information acquired at previous instants in time. Next, we simulate the optimal estimation of object position with and without delay compensation and compared it with human perception under a broad range of different psychophysical conditions. Our computational study suggests that the explicit, probabilistic representation of velocity information is crucial in explaining position coding, and therefore the flash-lag effect. We discuss these theoretical results in light of the putative corrective mechanisms that can be used to cancel out the detrimental effects of neural delays and illuminate the more general question of the dynamical representation at the present time of spatial information in the visual pathways.},
	language = {en},
	number = {1},
	urldate = {2022-08-31},
	journal = {PLOS Computational Biology},
	author = {Khoei, Mina A. and Masson, Guillaume S. and Perrinet, Laurent U.},
	month = jan,
	year = {2017},
	note = {Publisher: Public Library of Science},
	keywords = {Coding mechanisms, Extrapolation, Motion, Psychophysics, Sensory perception, Velocity, Vision, Visual system, ⛔ No INSPIRE recid found},
	pages = {e1005068},
}

@article{gollisch_rapid_2008,
	title = {Rapid {Neural} {Coding} in the {Retina} with {Relative} {Spike} {Latencies}},
	volume = {319},
	url = {https://doi.org/c6czvj},
	doi = {10.1126/science.1149639},
	abstract = {{\textless}jats:p{\textgreater}Natural vision is a highly dynamic process. Frequent body, head, and eye movements constantly bring new images onto the retina for brief periods, challenging our understanding of the neural code for vision. We report that certain retinal ganglion cells encode the spatial structure of a briefly presented image in the relative timing of their first spikes. This code is found to be largely invariant to stimulus contrast and robust to noisy fluctuations in response latencies. Mechanistically, the observed response characteristics result from different kinetics in two retinal pathways (“ON” and “OFF”) that converge onto ganglion cells. This mechanism allows the retina to rapidly and reliably transmit new spatial information with the very first spikes emitted by a neural population.{\textless}/jats:p{\textgreater}},
	language = {en},
	number = {5866},
	journal = {Science},
	author = {Gollisch, Tim and Meister, Markus},
	year = {2008},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1126/science.1149639},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1108--1111},
}

@article{grammont_precise_1999,
	title = {Precise spike synchronization in monkey motor cortex involved in preparation for movement},
	volume = {128},
	url = {https://doi.org/b67khx},
	doi = {10.1007/s002210050826},
	number = {1-2},
	journal = {Experimental Brain Research},
	author = {Grammont, Franck and Riehle, Alexa},
	month = sep,
	year = {1999},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1007/s002210050826},
	keywords = {⛔ No INSPIRE recid found},
	pages = {118--122},
}

@article{guise_bayesian_2014,
	title = {A {Bayesian} {Model} of {Polychronicity}},
	volume = {26},
	url = {https://doi.org/f6chbq},
	doi = {10.1162/neco_a_00620},
	abstract = {{\textless}jats:p{\textgreater} A significant feature of spiking neural networks with varying connection delays, such as those in the brain, is the existence of strongly connected groups of neurons known as polychronous neural groups (PNGs). Polychronous groups are found in large numbers in these networks and are proposed by Izhikevich ( 2006a ) to provide a neural basis for representation and memory. When exposed to a familiar stimulus, spiking neural networks produce consistencies in the spiking output data that are the hallmarks of PNG activation. Previous methods for studying the PNG activation response to stimuli have been limited by the template-based methods used to identify PNG activation. In this letter, we outline a new method that overcomes these difficulties by establishing for the first time a probabilistic interpretation of PNG activation. We then demonstrate the use of this method by investigating the claim that PNGs might provide the foundation of a representational system. {\textless}/jats:p{\textgreater}},
	language = {en},
	number = {9},
	journal = {Neural Computation},
	author = {Guise, Mira and Knott, Alistair and Benuskova, Lubica},
	month = sep,
	year = {2014},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1162/neco\_a\_00620},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2052--2073},
}

@article{gutig_tempotron_2006,
	title = {The tempotron: a neuron that learns spike timing–based decisions},
	volume = {9},
	url = {https://doi.org/ch29r4},
	doi = {10.1038/nn1643},
	language = {en},
	number = {3},
	journal = {Nature Neuroscience},
	author = {Gütig, Robert and Sompolinsky, Haim},
	year = {2006},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1038/nn1643},
	keywords = {⛔ No INSPIRE recid found},
	pages = {420--428},
}

@article{berens_fast_2012,
	title = {A {Fast} and {Simple} {Population} {Code} for {Orientation} in {Primate} {V1}},
	volume = {32},
	url = {https://doi.org/f365rn},
	doi = {10.1523/jneurosci.1335-12.2012},
	language = {en},
	number = {31},
	journal = {Journal of Neuroscience},
	author = {Berens, P. and Ecker, A. S. and Cotton, R. J. and Ma, W. J. and Bethge, M. and Tolias, A. S.},
	year = {2012},
	note = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id).
standard\_id: doi:10.1523/jneurosci.1335-12.2012},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {10618--10626},
}

@article{abeles_role_1982,
	title = {Role of the cortical neuron: integrator or coincidence detector?},
	volume = {18},
	number = {1},
	journal = {Israel journal of medical sciences},
	author = {Abeles, Moshe},
	year = {1982},
	keywords = {⛔ No DOI found, ⛔ No INSPIRE recid found},
	pages = {83--92},
}

@article{benosman_asynchronous_2012,
	title = {Asynchronous frameless event-based optical flow},
	volume = {27},
	url = {https://doi.org/10/b55t75},
	doi = {10.1016/j.neunet.2011.11.001},
	abstract = {This paper introduces a process to compute optical flow using an asynchronous event-based retina at high speed and low computational load. A new generation of artificial vision sensors has now started to rely on biologically inspired designs for light acquisition. Biological retinas, and their artificial counterparts, are totally asynchronous and data driven and rely on a paradigm of light acquisition radically different from most of the currently used frame-grabber technologies. This paper introduces a framework for processing visual data using asynchronous event-based acquisition, providing a method for the evaluation of optical flow. The paper shows that current limitations of optical flow computation can be overcome by using event-based visual acquisition, where high data sparseness and high temporal resolution permit the computation of optical flow with micro-second accuracy and at very low computational cost.},
	language = {english},
	journal = {Neural Networks},
	author = {Benosman, Ryad},
	year = {2012},
	keywords = {Asynchronous acquisition, Event-based vision, Frameless vision, Optical flow, Spikes, Temporal dynamics, ⛔ No INSPIRE recid found},
	pages = {6},
}

@article{grimaldi_robust_2022,
	title = {A robust event-driven approach to always-on object recognition},
	doi = {10.36227/techrxiv.18003077.v1},
	abstract = {We propose a neuromimetic architecture able to perform always-on pattern recognition. To achieve this, we extended an existing event-based algorithm [1], which introduced novel spatio-temporal features as a Hierarchy Of Time-Surfaces (HOTS). Built from asynchronous events acquired by a neuromorphic camera, these time surfaces allow to code the local dynamics of a visual scene and to create an efficient event-based pattern recognition architecture. Inspired by neuroscience, we extended this method to increase its performance. Our first contribution was to add a homeostatic gain control on the activity of neurons to improve the learning of spatio-temporal patterns [2]. A second contribution is to draw an analogy between the HOTS algorithm and Spiking Neural Networks (SNN). Following that analogy, our last contribution is to modify the classification layer and remodel the offline pattern categorization method previously used into an online and event-driven one. This classifier uses the spiking output of the network to define novel time surfaces and we then perform online classification with a neuromimetic implementation of a multinomial logistic regression. Not only do these improvements increase consistently the performances of the network, they also make this event-driven pattern recognition algorithm online and bio-realistic. Results were validated on different datasets: DVS barrel [3], Poker-DVS [4] and N-MNIST [5]. We foresee to develop the SNN version of the method and to extend this fully event-driven approach to more naturalistic tasks, notably for always-on, ultra-fast object categorization.},
	urldate = {2022-01-13},
	journal = {TechRxiv preprint},
	author = {Grimaldi, Antoine and Boutin, Victor and Ieng, Sio-Hoi and Benosman, Ryad and Perrinet, Laurent U},
	month = jan,
	year = {2022},
	keywords = {efficient coding, event-based vision, homeostasis, neuromorphic hardware, online classification, ⛔ No INSPIRE recid found},
}

@article{lagorce_hots_2017,
	title = {{HOTS}: {A} {Hierarchy} of {Event}-{Based} {Time}-{Surfaces} for {Pattern} {Recognition}},
	volume = {39},
	issn = {0162-8828},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27411216%20http://ieeexplore.ieee.org/document/7508476/},
	doi = {10.1109/TPAMI.2016.2574707},
	abstract = {This paper describes novel event-based spatiotemporal features called time-surfaces and how they can be used to create a hierarchical event-based pattern recognition architecture. Unlike existing hierarchical architectures for pattern recognition, the presented model relies on a time oriented approach to extract spatio-temporal features from the asynchronously acquired dynamics of a visual scene. These dynamics are acquired using biologically inspired frameless asynchronous event-driven vision sensors. Similarly to cortical structures, subsequent layers in our hierarchy extract increasingly abstract features using increasingly large spatio-temporal windows. The central concept is to use the rich temporal information provided by events to create contexts in the form of time-surfaces which represent the recent temporal activity within a local spatial neighborhood. We demonstrate that this concept can robustly be used at all stages of an event-based hierarchical model. First layer feature units operate on groups of pixels, while subsequent layer feature units operate on the output of lower level feature units. We report results on a previously published 36 class character recognition task and a 4 class canonical dynamic card pip task, achieving near 100\% accuracy on each. We introduce a new 7 class moving face recognition task, achieving 79\% accuracy.},
	number = {7},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Lagorce, Xavier and Orchard, Garrick and Galluppi, Francesco and Shi, Bertram E. and Benosman, Ryad B.},
	year = {2017},
	keywords = {Neuromorphic sensing, event-based vision, feature extraction, ⛔ No INSPIRE recid found},
	pages = {1346--1359},
}

@article{hogendoorn_predictive_2019,
	title = {Predictive {Coding} with {Neural} {Transmission} {Delays}: {A} {Real}-{Time} {Temporal} {Alignment} {Hypothesis}},
	volume = {6},
	issn = {2373-2822},
	shorttitle = {Predictive {Coding} with {Neural} {Transmission} {Delays}},
	url = {http://eneuro.org/lookup/doi/10.1523/ENEURO.0412-18.2019},
	doi = {10.1523/eneuro.0412-18.2019},
	language = {en},
	number = {2},
	urldate = {2019-11-12},
	journal = {eneuro},
	author = {Hogendoorn, Hinze and Burkitt, Anthony N.},
	month = mar,
	year = {2019},
	keywords = {⛔ No INSPIRE recid found},
	pages = {ENEURO.0412--18.2019},
}

@article{perrinet_motion-based_2012,
	title = {Motion-{Based} {Prediction} {Is} {Sufficient} to {Solve} the {Aperture} {Problem}},
	volume = {24},
	copyright = {All rights reserved},
	issn = {0899-7667},
	doi = {10.1162/neco_a_00332},
	abstract = {In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an elongated line is symmetrical along its axis, tangential velocity is ambiguous when measured locally. Here, we develop the hypothesis that motion-based predictive coding is sufficient to infer global motion. Our implementation is based on a context-dependent diffusion of a probabilistic representation of motion. We observe in simulations a progressive solution to the aperture problem similar to physio-logy and behavior. We demonstrate that this solution is the result of two underlying mechanisms. First, we demonstrate the formation of a tracking behavior favoring temporally coherent features independent of their texture. Second, we observe that incoherent features are explained away, while coherent information diffuses progressively to the global scale. Most previous models included ad hoc mechanisms such as end-stopped cells or a selection layer to track specific luminance-based features as necessary conditions to solve the aperture problem. Here, we have proved that motion-based predictive coding, as it is implemented in this functional model, is sufficient to solve the aperture problem. This solution may give insights into the role of prediction underlying a large class of sensory computations.},
	number = {10},
	journal = {Neural Computation},
	author = {Perrinet, Laurent U. and Masson, G.S. Guillaume S.},
	month = aug,
	year = {2012},
	keywords = {\#nosource, Bayesian model, aperture, aperture problem, aperture-problem, association field, coding, emergence, khoei12jpp, khoei13jpp, motion detection, motion prediction, perrinet12pred, predictive, predictive coding, predictive-coding, probabilistic, probabilistic representation, problem, representation, thesis, toupate-inpress, ⛔ No INSPIRE recid found},
	pages = {2726--2750},
}

@article{benosman_event-based_2014,
	title = {Event-{Based} {Visual} {Flow}},
	volume = {25},
	issn = {2162-237X, 2162-2388},
	url = {https://www.neuromorphic-vision.com/public/publications/3/publication.pdf},
	doi = {10.1109/tnnls.2013.2273537},
	abstract = {This paper introduces a new methodology to compute dense visual ﬂow using the precise timings of spikes from an asynchronous event-based retina. Biological retinas, and their artiﬁcial counterparts, are totally asynchronous and data-driven and rely on a paradigm of light acquisition radically different from most of the currently used frame-grabber technologies. This paper introduces a framework to estimate visual ﬂow from the local properties of events’ spatiotemporal space. We will show that precise visual ﬂow orientation and amplitude can be estimated using a local differential approach on the surface deﬁned by coactive events. Experimental results are presented; they show the method adequacy with high data sparseness and temporal resolution of event-based acquisition that allows the computation of motion ﬂow with microsecond accuracy and at very low computational cost.},
	language = {en},
	number = {2},
	urldate = {2022-02-01},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Benosman, Ryad and Clercq, Charles and Lagorce, Xavier and {Sio-Hoi Ieng} and Bartolozzi, Chiara},
	month = feb,
	year = {2014},
	keywords = {⛔ No INSPIRE recid found},
	pages = {407--417},
}

@article{bohte_error-backpropagation_2002,
	title = {Error-backpropagation in temporally encoded networks of spiking neurons},
	volume = {48},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231201006580},
	doi = {10.1016/S0925-2312(01)00658-0},
	abstract = {For a network of spiking neurons that encodes information in the timing of individual spike times, we derive a supervised learning rule, SpikeProp, akin to traditional error-backpropagation. With this algorithm, we demonstrate how networks of spiking neurons with biologically reasonable action potentials can perform complex non-linear classification in fast temporal coding just as well as rate-coded networks. We perform experiments for the classical XOR problem, when posed in a temporal setting, as well as for a number of other benchmark datasets. Comparing the (implicit) number of spiking neurons required for the encoding of the interpolated XOR problem, the trained networks demonstrate that temporal coding is a viable code for fast neural information processing, and as such requires less neurons than instantaneous rate-coding. Furthermore, we find that reliable temporal computation in the spiking networks was only accomplished when using spike response functions with a time constant longer than the coding interval, as has been predicted by theoretical considerations.},
	language = {en},
	number = {1},
	urldate = {2022-09-28},
	journal = {Neurocomputing},
	author = {Bohte, Sander M. and Kok, Joost N. and La Poutré, Han},
	month = oct,
	year = {2002},
	keywords = {Error-backpropagation, Spiking neurons, Temporal coding, ⛔ No INSPIRE recid found},
	pages = {17--37},
}

@article{dardelet_event-by-event_2021,
	title = {An {Event}-by-{Event} {Feature} {Detection} and {Tracking} {Invariant} to {Motion} {Direction} and {Velocity}},
	doi = {10.36227/techrxiv.17013824.v1},
	abstract = {Contour velocity estimation and tracking from a fully event-based perspective.},
	language = {en},
	urldate = {2022-09-28},
	author = {Dardelet, Laurent and Benosman, Ryad and Ieng, Sio-Hoi},
	month = nov,
	year = {2021},
	keywords = {⛔ No INSPIRE recid found},
}

@article{zenke_remarkable_2021,
	title = {The {Remarkable} {Robustness} of {Surrogate} {Gradient} {Learning} for {Instilling} {Complex} {Function} in {Spiking} {Neural} {Networks}},
	volume = {33},
	issn = {0899-7667},
	doi = {10.1162/neco_a_01367},
	abstract = {Brains process information in spiking neural networks. Their intricate connections shape the diverse functions these networks perform. Yet how network connectivity relates to function is poorly understood, and the functional capabilities of models of spiking networks are still rudimentary. The lack of both theoretical insight and practical algorithms to find the necessary connectivity poses a major impediment to both studying information processing in the brain and building efficient neuromorphic hardware systems. The training algorithms that solve this problem for artificial neural networks typically rely on gradient descent. But doing so in spiking networks has remained challenging due to the nondifferentiable nonlinearity of spikes. To avoid this issue, one can employ surrogate gradients to discover the required connectivity. However, the choice of a surrogate is not unique, raising the question of how its implementation influences the effectiveness of the method. Here, we use numerical simulations to systematically study how essential design parameters of surrogate gradients affect learning performance on a range of classification problems. We show that surrogate gradient learning is robust to different shapes of underlying surrogate derivatives, but the choice of the derivative's scale can substantially affect learning performance. When we combine surrogate gradients with suitable activity regularization techniques, spiking networks perform robust information processing at the sparse activity limit. Our study provides a systematic account of the remarkable robustness of surrogate gradient learning and serves as a practical guide to model functional spiking neural networks.},
	number = {4},
	urldate = {2021-12-02},
	journal = {Neural Computation},
	author = {Zenke, Friedemann and Vogels, Tim P.},
	month = mar,
	year = {2021},
	keywords = {⛔ No INSPIRE recid found},
	pages = {899--925},
}

@article{jeremie_ultra-fast_2022,
	title = {Ultra-fast image categorization in vivo and in silico},
	url = {http://arxiv.org/abs/2205.03635},
	doi = {10.48550/arXiv.2205.03635},
	abstract = {Humans are able to robustly categorize images and can, for instance, detect the presence of an animal in a briefly flashed image in as little as 120 ms. Initially inspired by neuroscience, deep-learning algorithms literally bloomed up in the last decade such that the accuracy of machines is at present superior to humans for visual recognition tasks. However, these artificial networks are usually trained and evaluated on very specific tasks, for instance on the 1000 separate categories of ImageNet. In that regard, biological visual systems are more flexible and efficient compared to artificial systems on generic ecological tasks. In order to deepen this comparison, we re-trained the standard VGG Convolutional Neural Network (CNN) on two independent tasks which are ecologically relevant for humans: one task defined as detecting the presence of an animal and the other as detecting the presence of an artifact. We show that retraining the network achieves human-like performance level which is reported in psychophysical tasks. We also compare the accuracy of the detection on an image-by-image basis. This showed in particular that the two models perform better when combining their outputs. Indeed, animals (e.g. lions) tend to be less present in photographs containing artifacts (e.g. buildings). These re-trained models could reproduce some unexpected behavioral observations from humans psychophysics such as the robustness to rotations (e.g. upside-down or slanted image) or to a grayscale transformation.},
	urldate = {2022-05-30},
	author = {Jérémie, Jean-Nicolas and Perrinet, Laurent U.},
	month = may,
	year = {2022},
	note = {arXiv: 2205.03635 [cs, q-bio]
type: article},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Quantitative Biology - Neurons and Cognition, ⛔ No INSPIRE recid found},
}

@article{yarbus_eye_1961,
	title = {Eye movements during the examination of complicated objects},
	volume = {6(2)},
	issn = {0006-3029},
	journal = {Biofizika},
	author = {Yarbus, A},
	year = {1961},
	pmid = {14040367},
	keywords = {EYE, Eye, Eye Movements, Humans, ⛔ No INSPIRE recid found},
	pages = {52--56},
}

@article{delorme_ultra-rapid_2000,
	title = {Ultra-rapid categorisation of natural scenes does not rely on colour cues: a study in monkeys and humans},
	volume = {40},
	issn = {0042-6989},
	shorttitle = {Ultra-rapid categorisation of natural scenes does not rely on colour cues},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698900000833},
	doi = {10.1016/S0042-6989(00)00083-3},
	abstract = {In a rapid categorisation task, monkeys and humans had to detect a target (animal or food) in briefly flashed (32 ms) and previously unseen natural images. Removing colour cues had very little effect on average performance. Impairments were restricted to a mild accuracy drop (in some human subjects) and a small reaction time mean increase (10–15 ms) observed both in monkeys and humans but only in the detection of food targets. In both tasks, accuracy and latency of the fastest behavioural responses were unaffected, suggesting that such ultra-rapid categorisations could depend on feed-forward processing of early coarse achromatic magnocellular information.},
	language = {en},
	number = {16},
	urldate = {2022-09-21},
	journal = {Vision Research},
	author = {Delorme, A and Richard, G and Fabre-Thorpe, M},
	month = jul,
	year = {2000},
	keywords = {Categorisation, Colour, Natural scenes, Primate, Visual processing, ⛔ No INSPIRE recid found},
	pages = {2187--2200},
}

@techreport{bernert_fully_2017,
	title = {Fully unsupervised online spike sorting based on an artificial spiking neural network},
	copyright = {© 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/236224v1},
	abstract = {Spike sorting is a crucial step of neural data processing widely used in neuroscience and neuroprosthetics. However, current methods remain not fully automatic and require heavy computations making them not embeddable in implantable devices. To overcome these limitations, we propose a novel method based on an artificial spiking neural network designed to process neural data online and completely automatically. An input layer continuously encodes the data stream into artificial spike trains, which are then processed by two further layers to output artificial trains of spikes reproducing the real spiking activity present in the input signal. The proposed method can be adapted to process several channels simultaneously in the case of tetrode recordings. It outperforms two existing algorithms at low SNR and has the advantage to be compatible with neuromorphic computing and the perspective of being embedded in very low-power analog systems for future implantable devices serving neurorehabilitation applications.},
	language = {en},
	urldate = {2022-04-08},
	institution = {bioRxiv},
	author = {Bernert, Marie and Yvert, Blaise},
	month = dec,
	year = {2017},
	doi = {10.1101/236224},
	note = {tex.ids= Bernert2017a
section: New Results
type: article},
	keywords = {⛔ No INSPIRE recid found},
	pages = {236224},
}

@article{bernert_attention-based_2018,
	title = {An {Attention}-{Based} {Spiking} {Neural} {Network} for {Unsupervised} {Spike}-{Sorting}},
	volume = {29},
	issn = {0129-0657},
	url = {https://www.worldscientific.com/doi/10.1142/S0129065718500594},
	doi = {10.1142/s0129065718500594},
	abstract = {Bio-inspired computing using artificial spiking neural networks promises performances outperforming currently available computational approaches. Yet, the number of applications of such networks remains limited due to the absence of generic training procedures for complex pattern recognition, which require the design of dedicated architectures for each situation. We developed a spike-timing-dependent plasticity (STDP) spiking neural network (SSN) to address spike-sorting, a central pattern recognition problem in neuroscience. This network is designed to process an extracellular neural signal in an online and unsupervised fashion. The signal stream is continuously fed to the network and processed through several layers to output spike trains matching the truth after a short learning period requiring only few data. The network features an attention mechanism to handle the scarcity of action potential occurrences in the signal, and a threshold adaptation mechanism to handle patterns with different sizes. This method outperforms two existing spike-sorting algorithms at low signal-to-noise ratio (SNR) and can be adapted to process several channels simultaneously in the case of tetrode recordings. Such attention-based STDP network applied to spike-sorting opens perspectives to embed neuromorphic processing of neural data in future brain implants.},
	number = {08},
	urldate = {2021-01-26},
	journal = {International Journal of Neural Systems},
	author = {Bernert, Marie and Yvert, Blaise},
	month = dec,
	year = {2018},
	note = {00016
tex.ids= Bernert2019, Bernert2019a
publisher: World Scientific Publishing Co.},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1850059},
}

@article{madadi_asl_delay-dependent_2022,
	title = {Delay-dependent transitions of phase synchronization and coupling symmetry between neurons shaped by spike-timing-dependent plasticity},
	issn = {1871-4099},
	url = {https://doi.org/10.1007/s11571-022-09850-x},
	doi = {10.1007/s11571-022-09850-x},
	abstract = {Synchronization plays a key role in learning and memory by facilitating the communication between neurons promoted by synaptic plasticity. Spike-timing-dependent plasticity (STDP) is a form of synaptic plasticity that modifies the strength of synaptic connections between neurons based on the coincidence of pre- and postsynaptic spikes. In this way, STDP simultaneously shapes the neuronal activity and synaptic connectivity in a feedback loop. However, transmission delays due to the physical distance between neurons affect neuronal synchronization and the symmetry of synaptic coupling. To address the question that how transmission delays and STDP can jointly determine the emergent pairwise activity-connectivity patterns, we studied phase synchronization properties and coupling symmetry between two bidirectionally coupled neurons using both phase oscillator and conductance-based neuron models. We show that depending on the range of transmission delays, the activity of the two-neuron motif can achieve an in-phase/anti-phase synchronized state and its connectivity can attain a symmetric/asymmetric coupling regime. The coevolutionary dynamics of the neuronal system and the synaptic weights due to STDP stabilizes the motif in either one of these states by transitions between in-phase/anti-phase synchronization states and symmetric/asymmetric coupling regimes at particular transmission delays. These transitions crucially depend on the phase response curve (PRC) of the neurons, but they are relatively robust to the heterogeneity of transmission delays and potentiation-depression imbalance of the STDP profile.},
	language = {en},
	urldate = {2022-09-18},
	journal = {Cognitive Neurodynamics},
	author = {Madadi Asl, Mojtaba and Ramezani Akbarabadi, Saeideh},
	month = jul,
	year = {2022},
	keywords = {Coupling symmetry, Spike-timing-dependent plasticity, Synaptic plasticity, Synchronization, Transmission delay, ⛔ No INSPIRE recid found},
}
